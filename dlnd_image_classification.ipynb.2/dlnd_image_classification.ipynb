{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f27f5c8cc88>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return x/255\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    a = np.zeros((len(x), 10)) #known label range: 0-9  \n",
    "    for i, j in enumerate(x):\n",
    "        a[i, j] = 1\n",
    "    \n",
    "    return a\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    input = tf.placeholder(tf.float32, shape=[None, image_shape[0], image_shape[1], image_shape[2]], name='x')\n",
    "\n",
    "    return input\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    label_input = tf.placeholder(tf.float32, shape=[None, n_classes], name='y')\n",
    "\n",
    "    return label_input\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return keep_prob\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    # Store layers weight & bias\n",
    "    W = tf.Variable(tf.truncated_normal([conv_ksize[0],\n",
    "                                         conv_ksize[1],\n",
    "                                         x_tensor.get_shape().as_list()[-1],\n",
    "                                         conv_num_outputs], mean=0.0, stddev=0.05, dtype=tf.float32))\n",
    "\n",
    "    b = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "\n",
    "    conv2d = tf.nn.conv2d(\n",
    "        x_tensor, \n",
    "        W, \n",
    "        strides=[1, conv_strides[0], conv_strides[1], 1],\n",
    "        padding='SAME')\n",
    "\n",
    "    conv2d = tf.nn.bias_add(conv2d, b)\n",
    "\n",
    "    conv2d = tf.nn.relu(conv2d)\n",
    "\n",
    "    maxpool = tf.nn.max_pool(\n",
    "        conv2d, \n",
    "        ksize=[1, pool_ksize[0], pool_ksize[1], 1],\n",
    "        strides=[1, pool_strides[0], pool_strides[1], 1],\n",
    "        padding='SAME')\n",
    "    \n",
    "    return maxpool \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    import numpy as np\n",
    "    \n",
    "    Four_D = x_tensor.get_shape()\n",
    "    Two_D = np.prod([x for x in Four_D[1:]])\n",
    "    \n",
    "    return tf.reshape(x_tensor, [-1, Two_D.value])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function    \n",
    "    \n",
    "    return tf.layers.dense(inputs=x_tensor, units=num_outputs, activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(x_tensor,num_outputs, activation_fn=None)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    #conv = conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    x = conv2d_maxpool(x, 64, (2, 2), (1, 1), (2, 2), (2, 2))\n",
    "    x = tf.nn.dropout(x, keep_prob)\n",
    "    x = conv2d_maxpool(x, 128, (2, 2), (1, 1), (2, 2), (2, 2))\n",
    "    x = tf.nn.dropout(x, keep_prob)\n",
    "    x = conv2d_maxpool(x, 128, (2, 2), (1, 1), (2, 2), (2, 2))\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flattened = flatten(x)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fully_connected = fully_conn(flattened, num_outputs=256)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = output(fully_connected, num_outputs=10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function  \n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "    print('Loss: {} Validation Accuracy: {}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "keep_probability = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.195788621902466 Validation Accuracy: 0.2555999755859375\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.038031578063965 Validation Accuracy: 0.3357999920845032\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 1.8319427967071533 Validation Accuracy: 0.3938000202178955\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.7097821235656738 Validation Accuracy: 0.4253999888896942\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.5916354656219482 Validation Accuracy: 0.45379993319511414\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.466933012008667 Validation Accuracy: 0.48799994587898254\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.3538624048233032 Validation Accuracy: 0.509399950504303\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.207889437675476 Validation Accuracy: 0.5331999659538269\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.1447120904922485 Validation Accuracy: 0.5259999632835388\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.012130856513977 Validation Accuracy: 0.5435999035835266\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 0.933547854423523 Validation Accuracy: 0.5519999265670776\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 0.8098767995834351 Validation Accuracy: 0.5571998953819275\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 0.7164173126220703 Validation Accuracy: 0.568199872970581\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 0.6658921241760254 Validation Accuracy: 0.5735998749732971\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 0.5903255939483643 Validation Accuracy: 0.578999936580658\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 0.5120422840118408 Validation Accuracy: 0.5839998722076416\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 0.4527197480201721 Validation Accuracy: 0.5763999223709106\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 0.4266364872455597 Validation Accuracy: 0.5755999088287354\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 0.34916648268699646 Validation Accuracy: 0.5805999636650085\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 0.3122505843639374 Validation Accuracy: 0.6063998937606812\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 0.27889400720596313 Validation Accuracy: 0.6013999581336975\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 0.28161683678627014 Validation Accuracy: 0.5987999439239502\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 0.20232710242271423 Validation Accuracy: 0.6119999289512634\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 0.18568792939186096 Validation Accuracy: 0.6053999662399292\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 0.18451236188411713 Validation Accuracy: 0.6059998869895935\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 0.13166578114032745 Validation Accuracy: 0.6041998863220215\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 0.12429870665073395 Validation Accuracy: 0.6055998802185059\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 0.14024432003498077 Validation Accuracy: 0.6003999710083008\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 0.09356145560741425 Validation Accuracy: 0.6037999391555786\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 0.0893905982375145 Validation Accuracy: 0.6037998795509338\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 0.09622206538915634 Validation Accuracy: 0.6019998788833618\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 0.07519417256116867 Validation Accuracy: 0.6081998944282532\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.06579075753688812 Validation Accuracy: 0.6111998558044434\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.06782995164394379 Validation Accuracy: 0.6133999824523926\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.0761067196726799 Validation Accuracy: 0.5941998958587646\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 0.05565490573644638 Validation Accuracy: 0.6007999181747437\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 0.045824289321899414 Validation Accuracy: 0.6059999465942383\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 0.03666209056973457 Validation Accuracy: 0.6093999147415161\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 0.029686644673347473 Validation Accuracy: 0.6061999201774597\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 0.028485223650932312 Validation Accuracy: 0.6059999465942383\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 0.0490928590297699 Validation Accuracy: 0.593999981880188\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 0.04115232825279236 Validation Accuracy: 0.5901999473571777\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 0.030841587111353874 Validation Accuracy: 0.579399824142456\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 0.03250334411859512 Validation Accuracy: 0.5921999216079712\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 0.036923158913850784 Validation Accuracy: 0.5731999278068542\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 0.02311868779361248 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 0.026104478165507317 Validation Accuracy: 0.5823999643325806\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.024286629632115364 Validation Accuracy: 0.5813999772071838\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.028310175985097885 Validation Accuracy: 0.5979998707771301\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.022683685645461082 Validation Accuracy: 0.5983998775482178\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.1794562339782715 Validation Accuracy: 0.27000001072883606\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 1.902108907699585 Validation Accuracy: 0.3515999913215637\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 1.4594286680221558 Validation Accuracy: 0.40299996733665466\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 1.6433265209197998 Validation Accuracy: 0.41920000314712524\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 1.565744161605835 Validation Accuracy: 0.4617999792098999\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 1.685106635093689 Validation Accuracy: 0.48499995470046997\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 1.3074380159378052 Validation Accuracy: 0.481999933719635\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 1.1009202003479004 Validation Accuracy: 0.5015999674797058\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 1.167429804801941 Validation Accuracy: 0.5267999768257141\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 1.2067433595657349 Validation Accuracy: 0.545199990272522\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 1.3405829668045044 Validation Accuracy: 0.5667999386787415\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 1.1236361265182495 Validation Accuracy: 0.5511999130249023\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 0.9105467796325684 Validation Accuracy: 0.5607999563217163\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 0.9600019454956055 Validation Accuracy: 0.5773999691009521\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 1.0341317653656006 Validation Accuracy: 0.5939999222755432\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.154127836227417 Validation Accuracy: 0.6055998802185059\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 0.9656099081039429 Validation Accuracy: 0.6007999777793884\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 0.7179384231567383 Validation Accuracy: 0.6097999215126038\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 0.8372526168823242 Validation Accuracy: 0.6105998754501343\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 0.8884987235069275 Validation Accuracy: 0.6125999093055725\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.0285632610321045 Validation Accuracy: 0.6303999423980713\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 0.8243048191070557 Validation Accuracy: 0.6289999485015869\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 0.5906589031219482 Validation Accuracy: 0.6375998854637146\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 0.7108739614486694 Validation Accuracy: 0.6345998644828796\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 0.723511815071106 Validation Accuracy: 0.6375998854637146\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 0.8950231075286865 Validation Accuracy: 0.6517999172210693\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 0.7245849370956421 Validation Accuracy: 0.6409999132156372\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 0.46861013770103455 Validation Accuracy: 0.653999924659729\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 0.6488640308380127 Validation Accuracy: 0.6499998569488525\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 0.6483244895935059 Validation Accuracy: 0.6529998779296875\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 0.7683156132698059 Validation Accuracy: 0.6663998961448669\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 0.6075423359870911 Validation Accuracy: 0.6547999382019043\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 0.4043564796447754 Validation Accuracy: 0.6661999225616455\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 0.5942548513412476 Validation Accuracy: 0.654999852180481\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 0.5112737417221069 Validation Accuracy: 0.6715998649597168\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 0.6105679869651794 Validation Accuracy: 0.6701998710632324\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 0.5066770315170288 Validation Accuracy: 0.6679999232292175\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 0.33862701058387756 Validation Accuracy: 0.6781998872756958\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 0.5520573258399963 Validation Accuracy: 0.6673998236656189\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 0.4366815686225891 Validation Accuracy: 0.6803998947143555\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 0.5323965549468994 Validation Accuracy: 0.6729998588562012\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 0.4230906069278717 Validation Accuracy: 0.6791998744010925\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 0.296903520822525 Validation Accuracy: 0.6873998641967773\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 0.4986099898815155 Validation Accuracy: 0.6781998872756958\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 0.3594709634780884 Validation Accuracy: 0.6933998465538025\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 0.4456017017364502 Validation Accuracy: 0.6889998316764832\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 0.350840300321579 Validation Accuracy: 0.6893998980522156\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 0.2744470536708832 Validation Accuracy: 0.6871998310089111\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 0.4360584020614624 Validation Accuracy: 0.6891999244689941\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 0.30593740940093994 Validation Accuracy: 0.6883998513221741\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 0.36674511432647705 Validation Accuracy: 0.6883999109268188\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 0.2959211766719818 Validation Accuracy: 0.6981998085975647\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 0.23588359355926514 Validation Accuracy: 0.6979998350143433\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 0.3651898503303528 Validation Accuracy: 0.7041998505592346\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 0.26197540760040283 Validation Accuracy: 0.7131998538970947\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 0.297345370054245 Validation Accuracy: 0.6945998668670654\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 0.22650113701820374 Validation Accuracy: 0.6889998912811279\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 0.19916917383670807 Validation Accuracy: 0.6993998885154724\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 0.29891446232795715 Validation Accuracy: 0.7095999121665955\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 0.2206965833902359 Validation Accuracy: 0.7125998735427856\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 0.2685648202896118 Validation Accuracy: 0.7071998119354248\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 0.21003004908561707 Validation Accuracy: 0.7023999094963074\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 0.20930618047714233 Validation Accuracy: 0.6909998655319214\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 0.27930748462677 Validation Accuracy: 0.7101998925209045\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 0.18107867240905762 Validation Accuracy: 0.7143998742103577\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 0.2200082689523697 Validation Accuracy: 0.7091999053955078\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 0.17232823371887207 Validation Accuracy: 0.7063998579978943\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 0.2058170884847641 Validation Accuracy: 0.6903998255729675\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 0.22497202455997467 Validation Accuracy: 0.71399986743927\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 0.1708301305770874 Validation Accuracy: 0.7201998233795166\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 0.2015771120786667 Validation Accuracy: 0.7131998538970947\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 0.15139354765415192 Validation Accuracy: 0.71399986743927\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 0.13962224125862122 Validation Accuracy: 0.7173998355865479\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 0.18067163228988647 Validation Accuracy: 0.7293998599052429\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 0.12988877296447754 Validation Accuracy: 0.7327998280525208\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 0.14151696860790253 Validation Accuracy: 0.7195997834205627\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 0.12745308876037598 Validation Accuracy: 0.7147998213768005\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 0.13769182562828064 Validation Accuracy: 0.7175998687744141\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 0.15175005793571472 Validation Accuracy: 0.7273998260498047\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 0.12248566001653671 Validation Accuracy: 0.726399838924408\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 0.15978342294692993 Validation Accuracy: 0.7223998308181763\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 0.1106860339641571 Validation Accuracy: 0.720599889755249\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 0.09041427075862885 Validation Accuracy: 0.7271998524665833\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 0.15140308439731598 Validation Accuracy: 0.7221998572349548\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 0.1058865562081337 Validation Accuracy: 0.7319998741149902\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 0.11903398483991623 Validation Accuracy: 0.7257997989654541\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 0.08321353793144226 Validation Accuracy: 0.7241997718811035\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 0.09586528688669205 Validation Accuracy: 0.7267999053001404\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 0.134905606508255 Validation Accuracy: 0.7297998666763306\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 0.09103706479072571 Validation Accuracy: 0.7323998808860779\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 0.09970376640558243 Validation Accuracy: 0.7297998666763306\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 0.07469635456800461 Validation Accuracy: 0.7179998159408569\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 0.07226434350013733 Validation Accuracy: 0.7373998761177063\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 0.1077013686299324 Validation Accuracy: 0.7347998023033142\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 0.07039375603199005 Validation Accuracy: 0.7389997839927673\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 0.0857054591178894 Validation Accuracy: 0.7307998538017273\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 0.08656502515077591 Validation Accuracy: 0.7133998274803162\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 0.07531696557998657 Validation Accuracy: 0.7309998273849487\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 0.10756118595600128 Validation Accuracy: 0.7245998978614807\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 0.06479770690202713 Validation Accuracy: 0.7301998138427734\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 0.0668189525604248 Validation Accuracy: 0.725399911403656\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 0.06726986914873123 Validation Accuracy: 0.721599817276001\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 0.06191181018948555 Validation Accuracy: 0.7345998883247375\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 0.08541325479745865 Validation Accuracy: 0.7337998747825623\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 0.06133967265486717 Validation Accuracy: 0.738399863243103\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 0.06794997304677963 Validation Accuracy: 0.7225998044013977\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 0.059916574507951736 Validation Accuracy: 0.7235998511314392\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 0.058911021798849106 Validation Accuracy: 0.738399863243103\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 0.07790067791938782 Validation Accuracy: 0.7211998105049133\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 0.052886493504047394 Validation Accuracy: 0.7389998435974121\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 0.061629749834537506 Validation Accuracy: 0.7307998538017273\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 0.06173151358962059 Validation Accuracy: 0.7235998511314392\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 0.04924836754798889 Validation Accuracy: 0.7381998300552368\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 0.08778649568557739 Validation Accuracy: 0.7215998768806458\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 0.04289697855710983 Validation Accuracy: 0.7447998523712158\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 0.06474695354700089 Validation Accuracy: 0.7165998220443726\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 0.05533400923013687 Validation Accuracy: 0.7175998687744141\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 0.04777894914150238 Validation Accuracy: 0.7351998686790466\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 0.052240658551454544 Validation Accuracy: 0.7307998538017273\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 0.041868921369314194 Validation Accuracy: 0.74319988489151\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 0.0460001602768898 Validation Accuracy: 0.7253997921943665\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 0.04102272540330887 Validation Accuracy: 0.7199998497962952\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 0.03719770908355713 Validation Accuracy: 0.7273998260498047\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 0.06922489404678345 Validation Accuracy: 0.7129998207092285\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 0.05022665113210678 Validation Accuracy: 0.7331998348236084\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 0.03605067729949951 Validation Accuracy: 0.7293998003005981\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 0.039584413170814514 Validation Accuracy: 0.7303998470306396\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 0.03995753079652786 Validation Accuracy: 0.7217997908592224\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 0.06297552585601807 Validation Accuracy: 0.7109998464584351\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 0.030475586652755737 Validation Accuracy: 0.7445998191833496\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 0.03668280690908432 Validation Accuracy: 0.734799861907959\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 0.04926912486553192 Validation Accuracy: 0.7263997793197632\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 0.026593666523694992 Validation Accuracy: 0.7319998741149902\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 0.06387220323085785 Validation Accuracy: 0.7127998471260071\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 0.022921495139598846 Validation Accuracy: 0.7311998605728149\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 0.030876249074935913 Validation Accuracy: 0.7295998334884644\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 0.0358300618827343 Validation Accuracy: 0.7263998985290527\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 0.022231796756386757 Validation Accuracy: 0.726399838924408\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 0.031646978110075 Validation Accuracy: 0.7265998125076294\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 0.02275077998638153 Validation Accuracy: 0.7465998530387878\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 0.019020777195692062 Validation Accuracy: 0.7343998551368713\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 0.0316307507455349 Validation Accuracy: 0.7287998795509338\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 0.030420485883951187 Validation Accuracy: 0.7259998321533203\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 0.03101094625890255 Validation Accuracy: 0.7247998714447021\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 0.027604199945926666 Validation Accuracy: 0.7331998348236084\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 0.02161543071269989 Validation Accuracy: 0.737599790096283\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 0.024301769211888313 Validation Accuracy: 0.7173998355865479\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 0.03575887531042099 Validation Accuracy: 0.7205998301506042\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 0.03127468377351761 Validation Accuracy: 0.7201998829841614\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 0.019652513787150383 Validation Accuracy: 0.7395998239517212\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 0.020307185128331184 Validation Accuracy: 0.7299997806549072\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 0.014652733691036701 Validation Accuracy: 0.7291998267173767\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 0.02729080244898796 Validation Accuracy: 0.7283998727798462\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 0.02817522920668125 Validation Accuracy: 0.7303997874259949\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 0.016987651586532593 Validation Accuracy: 0.7361999154090881\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 0.02837562933564186 Validation Accuracy: 0.7317997813224792\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 0.01694626733660698 Validation Accuracy: 0.7213998436927795\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 0.015477849170565605 Validation Accuracy: 0.7299998998641968\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 0.01886840909719467 Validation Accuracy: 0.7321997880935669\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 0.013970211148262024 Validation Accuracy: 0.7437998652458191\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.023928161710500717 Validation Accuracy: 0.7301998138427734\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 0.016216475516557693 Validation Accuracy: 0.7253998517990112\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 0.015134645625948906 Validation Accuracy: 0.7337998151779175\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 0.01612575352191925 Validation Accuracy: 0.7403998374938965\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 0.01285513211041689 Validation Accuracy: 0.7421998977661133\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.01721792295575142 Validation Accuracy: 0.7379998564720154\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 0.016385896131396294 Validation Accuracy: 0.721599817276001\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 0.013801250606775284 Validation Accuracy: 0.7307999134063721\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 0.0278756245970726 Validation Accuracy: 0.7261998653411865\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 0.012975210323929787 Validation Accuracy: 0.730199933052063\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.022658811882138252 Validation Accuracy: 0.7301998734474182\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 0.016796298325061798 Validation Accuracy: 0.7297999262809753\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 0.01346661988645792 Validation Accuracy: 0.7353997826576233\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 0.022386077791452408 Validation Accuracy: 0.7313998937606812\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 0.012159658595919609 Validation Accuracy: 0.7369998693466187\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 0.01946905255317688 Validation Accuracy: 0.7277997732162476\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss: 0.014774041250348091 Validation Accuracy: 0.7175997495651245\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss: 0.01496855914592743 Validation Accuracy: 0.7307998538017273\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss: 0.01726257987320423 Validation Accuracy: 0.7271998524665833\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss: 0.007948515936732292 Validation Accuracy: 0.7199998497962952\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 0.011198000982403755 Validation Accuracy: 0.7315998673439026\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss: 0.008061622269451618 Validation Accuracy: 0.716799795627594\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss: 0.027235765010118484 Validation Accuracy: 0.7223998308181763\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss: 0.01701366901397705 Validation Accuracy: 0.7283998727798462\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss: 0.021167941391468048 Validation Accuracy: 0.7161998748779297\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 0.021133562549948692 Validation Accuracy: 0.7081997990608215\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss: 0.013924814760684967 Validation Accuracy: 0.7193998694419861\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss: 0.01881220005452633 Validation Accuracy: 0.7193998098373413\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss: 0.012054278515279293 Validation Accuracy: 0.7327998280525208\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss: 0.00861369352787733 Validation Accuracy: 0.710399866104126\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 0.011176403611898422 Validation Accuracy: 0.7019999027252197\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss: 0.006315463222563267 Validation Accuracy: 0.718799889087677\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss: 0.014983992092311382 Validation Accuracy: 0.7113998532295227\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss: 0.011210953816771507 Validation Accuracy: 0.7325999140739441\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss: 0.012211319990456104 Validation Accuracy: 0.703799843788147\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 0.009008866734802723 Validation Accuracy: 0.7105998396873474\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss: 0.013316742144525051 Validation Accuracy: 0.7145998477935791\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss: 0.015397144481539726 Validation Accuracy: 0.7179998755455017\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 0.014568411745131016 Validation Accuracy: 0.72819983959198\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss: 0.013614353723824024 Validation Accuracy: 0.7011998295783997\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 0.009506631642580032 Validation Accuracy: 0.7191998958587646\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss: 0.009697547182440758 Validation Accuracy: 0.7079998850822449\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss: 0.008859297260642052 Validation Accuracy: 0.7193998098373413\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss: 0.00678451731801033 Validation Accuracy: 0.7259997725486755\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss: 0.01521525252610445 Validation Accuracy: 0.6955998539924622\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 0.010567565448582172 Validation Accuracy: 0.7263998985290527\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss: 0.008380547165870667 Validation Accuracy: 0.7163999080657959\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss: 0.008775095455348492 Validation Accuracy: 0.7217998504638672\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss: 0.011517632752656937 Validation Accuracy: 0.7295998334884644\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss: 0.007694563828408718 Validation Accuracy: 0.7093998193740845\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 0.012548528611660004 Validation Accuracy: 0.7179998159408569\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss: 0.005040677264332771 Validation Accuracy: 0.7219998240470886\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss: 0.008653046563267708 Validation Accuracy: 0.7149998545646667\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss: 0.012635357677936554 Validation Accuracy: 0.72819983959198\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss: 0.017469285055994987 Validation Accuracy: 0.7175998687744141\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 0.00809108279645443 Validation Accuracy: 0.7161998748779297\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss: 0.003435675986111164 Validation Accuracy: 0.7261998653411865\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss: 0.007737749721854925 Validation Accuracy: 0.7177998423576355\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss: 0.010161279700696468 Validation Accuracy: 0.7239998579025269\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss: 0.009620457887649536 Validation Accuracy: 0.7235998511314392\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 0.007354246452450752 Validation Accuracy: 0.7151999473571777\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss: 0.00569501705467701 Validation Accuracy: 0.7245998978614807\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss: 0.005958446301519871 Validation Accuracy: 0.7367998361587524\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss: 0.005628648214042187 Validation Accuracy: 0.7301998138427734\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss: 0.008847532793879509 Validation Accuracy: 0.7261998653411865\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 0.004715684801340103 Validation Accuracy: 0.7119998335838318\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss: 0.004231190774589777 Validation Accuracy: 0.7177998423576355\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss: 0.0033907771576195955 Validation Accuracy: 0.7295998930931091\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss: 0.007770232856273651 Validation Accuracy: 0.7257998585700989\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss: 0.006196147296577692 Validation Accuracy: 0.7191998362541199\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 0.005101105198264122 Validation Accuracy: 0.6949998736381531\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss: 0.0022357148118317127 Validation Accuracy: 0.7173998355865479\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss: 0.005379104055464268 Validation Accuracy: 0.7325997948646545\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss: 0.0074000428430736065 Validation Accuracy: 0.7247998714447021\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss: 0.003514528274536133 Validation Accuracy: 0.7147998809814453\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.0026004717219620943 Validation Accuracy: 0.7131998538970947\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss: 0.002913807751610875 Validation Accuracy: 0.721599817276001\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss: 0.0028963014483451843 Validation Accuracy: 0.7303998470306396\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss: 0.006805293262004852 Validation Accuracy: 0.723399817943573\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss: 0.0034592505544424057 Validation Accuracy: 0.730999767780304\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.005669131875038147 Validation Accuracy: 0.7107998132705688\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss: 0.005602519027888775 Validation Accuracy: 0.7231998443603516\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss: 0.004744412377476692 Validation Accuracy: 0.7245998978614807\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss: 0.006536140572279692 Validation Accuracy: 0.7299998998641968\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss: 0.003616451285779476 Validation Accuracy: 0.7229998707771301\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.0022828783839941025 Validation Accuracy: 0.7235998511314392\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss: 0.0034096103627234697 Validation Accuracy: 0.7181997299194336\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss: 0.005882409401237965 Validation Accuracy: 0.7327998280525208\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss: 0.009004820138216019 Validation Accuracy: 0.7221998572349548\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss: 0.0015188799006864429 Validation Accuracy: 0.7241998910903931\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.7208984375\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsUAAAJ/CAYAAACQmq4LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f27e009ee48>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 354
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
