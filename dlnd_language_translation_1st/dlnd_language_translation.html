<!DOCTYPE html>
<!-- saved from url=(0067)http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    

    <title>dlnd_language_translation</title>
    <link rel="shortcut icon" type="image/x-icon" href="http://35.158.40.136:8888/static/base/images/favicon.ico?v=97c6417ed01bdc0ae3ef32ae4894fd03">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link rel="stylesheet" href="./dlnd_language_translation_files/jquery-ui.min.css" type="text/css">
    <link rel="stylesheet" href="./dlnd_language_translation_files/jquery.typeahead.min.css" type="text/css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    


<script type="text/javascript" src="./dlnd_language_translation_files/MathJax.js" charset="utf-8"></script>

<script type="text/javascript">
// MathJax disabled, set as null to distingish from *missing* MathJax,
// where it will be undefined, and should prompt a dialog later.
window.mathjax_url = "/static/components/MathJax/MathJax.js";
</script>

<link rel="stylesheet" href="./dlnd_language_translation_files/bootstrap-tour.min.css" type="text/css">
<link rel="stylesheet" href="./dlnd_language_translation_files/codemirror.css">


    <link rel="stylesheet" href="./dlnd_language_translation_files/style.min.css" type="text/css">
    

<link rel="stylesheet" href="./dlnd_language_translation_files/override.css" type="text/css">
<link rel="stylesheet" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb" id="kernel-css" type="text/css">


    <link rel="stylesheet" href="./dlnd_language_translation_files/custom.css" type="text/css">
    <script src="./dlnd_language_translation_files/promise.min.js" type="text/javascript" charset="utf-8"></script>
    <script src="./dlnd_language_translation_files/require.js" type="text/javascript" charset="utf-8"></script>
    <script>
      require.config({
          
          urlArgs: "v=20170418164528",
          
          baseUrl: '/static/',
          paths: {
            'auth/js/main': 'auth/js/main.min',
            custom : '/custom',
            nbextensions : '/nbextensions',
            kernelspecs : '/kernelspecs',
            underscore : 'components/underscore/underscore-min',
            backbone : 'components/backbone/backbone-min',
            jquery: 'components/jquery/jquery.min',
            bootstrap: 'components/bootstrap/js/bootstrap.min',
            bootstraptour: 'components/bootstrap-tour/build/js/bootstrap-tour.min',
            'jquery-ui': 'components/jquery-ui/ui/minified/jquery-ui.min',
            moment: 'components/moment/moment',
            codemirror: 'components/codemirror',
            termjs: 'components/xterm.js/dist/xterm',
            typeahead: 'components/jquery-typeahead/dist/jquery.typeahead.min',
          },
	  map: { // for backward compatibility
	    "*": {
		"jqueryui": "jquery-ui",
	    }
	  },
          shim: {
            typeahead: {
              deps: ["jquery"],
              exports: "typeahead"
            },
            underscore: {
              exports: '_'
            },
            backbone: {
              deps: ["underscore", "jquery"],
              exports: "Backbone"
            },
            bootstrap: {
              deps: ["jquery"],
              exports: "bootstrap"
            },
            bootstraptour: {
              deps: ["bootstrap"],
              exports: "Tour"
            },
            "jquery-ui": {
              deps: ["jquery"],
              exports: "$"
            }
          },
          waitSeconds: 30,
      });

      require.config({
          map: {
              '*':{
                'contents': 'services/contents',
              }
          }
      });

      define("bootstrap", function () {
          return window.$;
      });

      define("jquery", function () {
          return window.$;
      });

      define("jqueryui", function () {
          return window.$;
      });

      define("jquery-ui", function () {
          return window.$;
      });
      // error-catching custom.js shim.
      define("custom", function (require, exports, module) {
          try {
              var custom = require('custom/custom');
              console.debug('loaded custom.js');
              return custom;
          } catch (e) {
              console.error("error loading custom.js", e);
              return {};
          }
      })
    </script>

    
    

<script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/contents" src="./dlnd_language_translation_files/contents.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="custom/custom" src="./dlnd_language_translation_files/custom.js"></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="nbextensions/jupyter-js-widgets/extension" src="./dlnd_language_translation_files/extension.js"></script><style type="text/css">.MathJax_Display {text-align: center; margin: 0; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Blank; src: url('about:blank')}
.MathJax .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">.widget-modal-backdrop{position:absolute;left:0;top:0;width:100%;height:100%;background:#000;z-index:999;opacity:.5;display:flex;align-items:center;justify-content:center;flex-direction:column}.widget-modal-backdrop.widget-modal-hidden{display:none}.widget-modal-backdrop.widget-modal-hide{animation:fadeout .25s}.widget-modal-backdrop.widget-modal-show{animation:fadein .25s}@keyframes fadein{from{opacity:0}to{opacity:.5}}@keyframes fadeout{from{opacity:.5}to{opacity:0}}.widget-modal-text{color:#fff;font-size:x-large;font-weight:700}.widget-modal-text div,.widget-modal-text i{display:inline}.widget-modal-text div{padding-left:1ex}.widget-modal-progress{width:300px}.jupyter-widgets{margin:2px}.jupyter-widgets.widget-container{margin:0}.widget-area{page-break-inside:avoid;-webkit-box-orient:horizontal;-webkit-box-align:stretch;-moz-box-orient:horizontal;-moz-box-align:stretch;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch}.widget-area .widget-subarea{padding:.4em 0;box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box;-webkit-box-flex:2;-moz-box-flex:2;box-flex:2;flex:2;-webkit-box-orient:vertical;-webkit-box-align:stretch;-moz-box-orient:vertical;-moz-box-align:stretch;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch}.widget-area.connection-problems .prompt:after{content:"\F127";font-family:FontAwesome;color:#d9534f;top:3px;padding:3px}.slide-track{border:1px solid #CCC;background:#FFF;border-radius:2px}.widget-hslider{width:300px}.widget-hslider .slider-container{padding-left:8px;padding-right:2px;overflow:visible;flex-grow:1;height:5px;max-height:5px;margin-top:15px;margin-bottom:12px;border:1px solid #CCC;background:#FFF;border-radius:2px;-webkit-box-orient:horizontal;-webkit-box-align:stretch;-moz-box-orient:horizontal;-moz-box-align:stretch;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch}.widget-hslider .slider-container .ui-slider{-webkit-box-orient:horizontal;-webkit-box-align:stretch;-moz-box-orient:horizontal;-moz-box-align:stretch;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch;-webkit-box-flex:1;-moz-box-flex:1;box-flex:1;flex:1;border:0;background:0 0}.widget-hslider .slider-container .ui-slider .ui-slider-handle{width:12px;height:28px;margin-top:-8px;border-radius:2px}.widget-hslider .slider-container .ui-slider .ui-slider-range{height:12px;margin-top:-4px}.widget-vslider{width:50px;height:250px}.widget-vslider .slider-container{padding-bottom:5px;overflow:visible;flex-grow:1;width:5px;max-width:5px;margin-left:auto;margin-right:auto;border:1px solid #CCC;background:#FFF;border-radius:2px;-webkit-box-orient:vertical;-webkit-box-align:stretch;-moz-box-orient:vertical;-moz-box-align:stretch;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch}.widget-vslider .slider-container .ui-slider{-webkit-box-orient:vertical;-webkit-box-align:stretch;-moz-box-orient:vertical;-moz-box-align:stretch;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch;-webkit-box-flex:1;-moz-box-flex:1;box-flex:1;flex:1;border:0;background:0 0;margin-left:-4px;margin-top:5px}.widget-vslider .slider-container .ui-slider .ui-slider-handle{width:28px;height:12px;margin-left:-9px;border-radius:2px}.widget-vslider .slider-container .ui-slider .ui-slider-range{width:12px;margin-left:-1px}.widget-colorpicker{width:300px;display:flex}.widget-colorpicker.short{width:148px}.widget-colorpicker .input-group{flex-grow:1}.widget-button{width:148px;box-shadow:0 2px 2px 0 rgba(0,0,0,.14),0 3px 1px -2px rgba(0,0,0,.2),0 1px 5px 0 rgba(0,0,0,.12)}.widget-button.btn,.widget-button.btn.hover,.widget-button.btn:active,.widget-button.btn:focus{outline:0!important}.widget-button.btn:active{box-shadow:0 4px 5px 0 rgba(0,0,0,.14),0 1px 10px 0 rgba(0,0,0,.12),0 2px 4px -1px rgba(0,0,0,.2)}.widget-checkbox{width:148px}.widget-toggle-button{width:148px;box-shadow:0 2px 2px 0 rgba(0,0,0,.14),0 3px 1px -2px rgba(0,0,0,.2),0 1px 5px 0 rgba(0,0,0,.12)}.widget-toggle-button.btn,.widget-toggle-button.btn.hover,.widget-toggle-button.btn:active,.widget-toggle-button.btn:focus,.widget-toggle-buttons .btn,.widget-toggle-buttons .btn.hover,.widget-toggle-buttons .btn:active,.widget-toggle-buttons .btn:focus{outline:0!important}.widget-toggle-buttons .btn.active{box-shadow:none!important}.widget-toggle-buttons .btn-group{box-shadow:0 2px 2px 0 rgba(0,0,0,.14),0 3px 1px -2px rgba(0,0,0,.2),0 1px 5px 0 rgba(0,0,0,.12)}.widget-text{width:300px}.widget-textarea{width:300px}.widget-listbox{width:300px}.widget-select-multiple{width:300px}.widget-select-multiple select.form-control{margin-left:0;margin-right:0}.widget-dropdown{width:300px}.widget-dropdown .widget_item{display:flex;flex-grow:1}.widget-dropdown .widget-combo-btn{flex-grow:1;min-width:10px}.widget-dropdown .dropdown-menu{max-height:200px;overflow:hidden;overflow-y:auto;width:calc(275px)}.widget-hprogress{width:300px;height:32px}.widget-hprogress .progress{flex-grow:1;margin-top:auto;margin-bottom:auto}.widget-hprogress .progress-bar{-webkit-transition:none;-moz-transition:none;-ms-transition:none;-o-transition:none;transition:none}.widget-vprogress{height:250px;width:50px}.widget-vprogress .progress{flex-grow:1;width:12px;margin-left:auto;margin-right:auto;margin-bottom:0}.widget-vprogress .progress-bar{-webkit-transition:none;-moz-transition:none;-ms-transition:none;-o-transition:none;transition:none}.widget-combo-btn{min-width:123px}.widget_item .dropdown-menu li a{color:inherit}.widget-valid{margin:8px 5px 16px}.widget-hbox{-webkit-box-orient:horizontal;-webkit-box-align:stretch;-moz-box-orient:horizontal;-moz-box-align:stretch;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch}.widget-hbox input[type=checkbox]{margin-top:10px;margin-bottom:10px}.widget-hbox input[type=color]{height:32px;width:28px;padding:1px}.widget-hbox .widget-label{min-width:10ex;max-width:10ex;padding-right:8px;padding-top:5px;text-align:right;vertical-align:text-top;word-wrap:break-word}.widget-hbox .widget-readout{padding-left:4px;padding-top:5px;height:32px;text-align:center;vertical-align:text-top;min-width:7em;max-width:7em;margin-left:3px;overflow:hidden;white-space:nowrap}.widget-hbox .widget-readout.overflow{-webkit-box-shadow:0 0 0 1px rgba(77,0,0,.15);-moz-box-shadow:0 0 0 1px rgba(77,0,0,.15);box-shadow:0 0 0 1px rgba(77,0,0,.15)}.widget-vbox{-webkit-box-orient:vertical;-webkit-box-align:stretch;-moz-box-orient:vertical;-moz-box-align:stretch;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch}.widget-vbox input[type=color]{height:32px;padding:1px}.widget-vbox .widget-label{padding-bottom:5px;text-align:center;vertical-align:text-bottom}.widget-vbox .widget-readout{padding-top:5px;white-space:nowrap;text-align:center;vertical-align:text-top;margin-top:4px;overflow:hidden}.widget-vbox .widget-readout.overflow{-webkit-box-shadow:0 0 0 1px rgba(77,0,0,.15);-moz-box-shadow:0 0 0 1px rgba(77,0,0,.15);box-shadow:0 0 0 1px rgba(77,0,0,.15)}.widget-box{box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box;-webkit-box-align:start;-moz-box-align:start;box-align:start;align-items:flex-start}.widget-radio-box{-webkit-box-orient:vertical;-webkit-box-align:stretch;-moz-box-orient:vertical;-moz-box-align:stretch;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch;box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box;padding-top:4px}.widget-radio-box label{margin-top:2px;margin-bottom:2px;margin-left:22px}/*# sourceMappingURL=widgets.min.css.map */</style></head>

<body class="notebook_app  command_mode" data-base-url="/" data-ws-url="" data-notebook-name="dlnd_language_translation.ipynb" data-notebook-path="dlnd_language_translation.ipynb"><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>

<noscript>
    &lt;div id='noscript'&gt;
      Jupyter Notebook requires JavaScript.&lt;br&gt;
      Please enable it to proceed.
  &lt;/div&gt;
</noscript>

<div id="header" style="display: block;">
  <div id="header-container" class="container">
  <div id="ipython_notebook" class="nav navbar-brand pull-left"><a href="http://35.158.40.136:8888/tree" title="dashboard"><img src="./dlnd_language_translation_files/logo.png" alt="Jupyter Notebook"></a></div>

  
  
  

    <span id="login_widget">
      
    </span>

  

  

  


<span id="save_widget" class="pull-left save_widget">
    <span id="notebook_name" class="filename">dlnd_language_translation</span>
    <span class="checkpoint_status" title="Tue, Apr 18, 2017 6:50 PM">Last Checkpoint: a minute ago</span>
    <span class="autosave_status">(autosaved)</span>
</span>

<span id="kernel_logo_widget">
  
  <img class="current_kernel_logo" src="./dlnd_language_translation_files/logo-64x64.png" style="display: inline;">
  
</span>


  </div>
  <div class="header-bar"></div>

  
<div id="menubar-container" class="container">
<div id="menubar">
    <div id="menus" class="navbar navbar-default" role="navigation">
        <div class="container-fluid">
            <button type="button" class="btn btn-default navbar-btn navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <i class="fa fa-bars"></i>
              <span class="navbar-text">Menu</span>
            </button>
            <p id="kernel_indicator" class="navbar-text indicator_area">
              <span class="kernel_indicator_name">Python 3</span>
              <i id="kernel_indicator_icon" class="kernel_idle_icon" title="Kernel Idle"></i>
            </p>
            <i id="readonly-indicator" class="navbar-text" title="This notebook is read-only" style="display: none;">
                <span class="fa-stack">
                    <i class="fa fa-save fa-stack-1x"></i>
                    <i class="fa fa-ban fa-stack-2x text-danger"></i>
                </span>
            </i>
            <i id="modal_indicator" class="navbar-text modal_indicator" title="Command Mode"></i>
            <span id="notification_area"><div id="notification_kernel" class="notification_widget btn btn-xs navbar-btn undefined info" style="display: none;"><span></span></div><div id="notification_notebook" class="notification_widget btn btn-xs navbar-btn" style="display: none;"><span></span></div><div id="notification_widgets" class="notification_widget btn btn-xs navbar-btn" style="display: none;"><span></span></div></span>
            <div class="navbar-collapse collapse">
              <ul class="nav navbar-nav">
                <li class="dropdown"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#" class="dropdown-toggle" data-toggle="dropdown">File</a>
                    <ul id="file_menu" class="dropdown-menu">
                        <li id="new_notebook" class="dropdown-submenu">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">New Notebook</a>
                            <ul class="dropdown-menu" id="menu-new-notebook-submenu"><li id="new-notebook-submenu-python3"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Python 3</a></li></ul>
                        </li>
                        <li id="open_notebook" title="Opens a new window with the Dashboard view">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Open...</a></li>
                        <!-- <hr/> -->
                        <li class="divider"></li>
                        <li id="copy_notebook" title="Open a copy of this notebook&#39;s contents and start a new kernel">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Make a Copy...</a></li>
                        <li id="rename_notebook"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Rename...</a></li>
                        <li id="save_checkpoint"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Save and Checkpoint</a></li>
                        <!-- <hr/> -->
                        <li class="divider"></li>
                        <li id="restore_checkpoint" class="dropdown-submenu"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Revert to Checkpoint</a>
                          <ul class="dropdown-menu"><li><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Tuesday, April 18, 2017 6:50 PM</a></li></ul>
                        </li>
                        <li class="divider"></li>
                        <li id="print_preview"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Print Preview</a></li>
                        <li class="dropdown-submenu"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Download as</a>
                            <ul class="dropdown-menu">
                                <li id="download_ipynb"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Notebook (.ipynb)</a></li>
                                <li id="download_script"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Python (.py)</a></li>
                                <li id="download_html"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">HTML (.html)</a></li>
                                <li id="download_markdown"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Markdown (.md)</a></li>
                                <li id="download_rst"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">reST (.rst)</a></li>
                                <li id="download_pdf"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">PDF via LaTeX (.pdf)</a></li>
                            </ul>
                        </li>
                        <li class="divider"></li>
                        <li id="trust_notebook" title="Trust the output of this notebook" class="disabled">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Trusted Notebook</a></li>
                        <li class="divider"></li>
                        <li id="kill_and_exit" title="Shutdown this notebook&#39;s kernel, and close this window">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Close and Halt</a></li>
                    </ul>
                </li>
                <li class="dropdown"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Edit</a>
                    <ul id="edit_menu" class="dropdown-menu">
                        <li id="cut_cell"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Cut Cells</a></li>
                        <li id="copy_cell"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Copy Cells</a></li>
                        <li id="paste_cell_above" class="disabled"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Paste Cells Above</a></li>
                        <li id="paste_cell_below" class="disabled"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Paste Cells Below</a></li>
                        <li id="paste_cell_replace" class="disabled"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Paste Cells &amp; Replace</a></li>
                        <li id="delete_cell"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Delete Cells</a></li>
                        <li id="undelete_cell" class="disabled"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Undo Delete Cells</a></li>
                        <li class="divider"></li>
                        <li id="split_cell"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Split Cell</a></li>
                        <li id="merge_cell_above"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Merge Cell Above</a></li>
                        <li id="merge_cell_below"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Merge Cell Below</a></li>
                        <li class="divider"></li>
                        <li id="move_cell_up"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Move Cell Up</a></li>
                        <li id="move_cell_down"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Move Cell Down</a></li>
                        <li class="divider"></li>
                        <li id="edit_nb_metadata"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Edit Notebook Metadata</a></li>
                        <li class="divider"></li>
                        <li id="find_and_replace"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#"> Find and Replace </a></li>
                    </ul>
                </li>
                <li class="dropdown"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#" class="dropdown-toggle" data-toggle="dropdown">View</a>
                    <ul id="view_menu" class="dropdown-menu">
                        <li id="toggle_header" title="Show/Hide the logo and notebook title (above menu bar)">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Toggle Header</a></li>
                        <li id="toggle_toolbar" title="Show/Hide the action icons (below menu bar)">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Toggle Toolbar</a></li>
                        <li id="menu-cell-toolbar" class="dropdown-submenu">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Cell Toolbar</a>
                            <ul class="dropdown-menu" id="menu-cell-toolbar-submenu"><li data-name="None"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">None</a></li><li data-name="Edit%20Metadata"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Edit Metadata</a></li><li data-name="Raw%20Cell%20Format"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Raw Cell Format</a></li><li data-name="Slideshow"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Slideshow</a></li></ul>
                        </li>
                    </ul>
                </li>
                <li class="dropdown"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Insert</a>
                    <ul id="insert_menu" class="dropdown-menu">
                        <li id="insert_cell_above" title="Insert an empty Code cell above the currently active cell">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Insert Cell Above</a></li>
                        <li id="insert_cell_below" title="Insert an empty Code cell below the currently active cell">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Insert Cell Below</a></li>
                    </ul>
                </li>
                <li class="dropdown"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Cell</a>
                    <ul id="cell_menu" class="dropdown-menu">
                        <li id="run_cell" title="Run this cell, and move cursor to the next one">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Run Cells</a></li>
                        <li id="run_cell_select_below" title="Run this cell, select below">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Run Cells and Select Below</a></li>
                        <li id="run_cell_insert_below" title="Run this cell, insert below">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Run Cells and Insert Below</a></li>
                        <li id="run_all_cells" title="Run all cells in the notebook">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Run All</a></li>
                        <li id="run_all_cells_above" title="Run all cells above (but not including) this cell">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Run All Above</a></li>
                        <li id="run_all_cells_below" title="Run this cell and all cells below it">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Run All Below</a></li>
                        <li class="divider"></li>
                        <li id="change_cell_type" class="dropdown-submenu" title="All cells in the notebook have a cell type. By default, new cells are created as &#39;Code&#39; cells">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Cell Type</a>
                            <ul class="dropdown-menu">
                              <li id="to_code" title="Contents will be sent to the kernel for execution, and output will display in the footer of cell">
                                  <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Code</a></li>
                              <li id="to_markdown" title="Contents will be rendered as HTML and serve as explanatory text">
                                  <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Markdown</a></li>
                              <li id="to_raw" title="Contents will pass through nbconvert unmodified">
                                  <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Raw NBConvert</a></li>
                            </ul>
                        </li>
                        <li class="divider"></li>
                        <li id="current_outputs" class="dropdown-submenu"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Current Outputs</a>
                            <ul class="dropdown-menu">
                                <li id="toggle_current_output" title="Hide/Show the output of the current cell">
                                    <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Toggle</a>
                                </li>
                                <li id="toggle_current_output_scroll" title="Scroll the output of the current cell">
                                    <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Toggle Scrolling</a>
                                </li>
                                <li id="clear_current_output" title="Clear the output of the current cell">
                                    <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Clear</a>
                                </li>
                            </ul>
                        </li>
                        <li id="all_outputs" class="dropdown-submenu"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">All Output</a>
                            <ul class="dropdown-menu">
                                <li id="toggle_all_output" title="Hide/Show the output of all cells">
                                    <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Toggle</a>
                                </li>
                                <li id="toggle_all_output_scroll" title="Scroll the output of all cells">
                                    <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Toggle Scrolling</a>
                                </li>
                                <li id="clear_all_output" title="Clear the output of all cells">
                                    <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Clear</a>
                                </li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li class="dropdown"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Kernel</a>
                    <ul id="kernel_menu" class="dropdown-menu">
                        <li id="int_kernel" title="Send KeyboardInterrupt (CTRL-C) to the Kernel">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Interrupt</a>
                        </li>
                        <li id="restart_kernel" title="Restart the Kernel">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Restart</a>
                        </li>
                        <li id="restart_clear_output" title="Restart the Kernel and clear all output">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Restart &amp; Clear Output</a>
                        </li>
                        <li id="restart_run_all" title="Restart the Kernel and re-run the notebook">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Restart &amp; Run All</a>
                        </li>
                        <li id="reconnect_kernel" title="Reconnect to the Kernel">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Reconnect</a>
                        </li>
                        <li class="divider"></li>
                        <li id="menu-change-kernel" class="dropdown-submenu">
                            <a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Change kernel</a>
                            <ul class="dropdown-menu" id="menu-change-kernel-submenu"><li id="kernel-submenu-python3"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Python 3</a></li></ul>
                        </li>
                    </ul>
                </li>
                <li class="dropdown"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#" data-toggle="dropdown" class="dropdown-toggle">Widgets</a><ul id="widget-submenu" class="dropdown-menu"><li title="Rasterizes the current state of the widgets to the notebook as PNG images."><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Save notebook with snapshots</a></li><li title="Download the widget state as a JSON file"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Download widget state</a></li><li title="Embed interactive widgets"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Embed widgets</a></li></ul></li><li class="dropdown"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Help</a>
                    <ul id="help_menu" class="dropdown-menu">
                        
                        <li id="notebook_tour" title="A quick tour of the notebook user interface"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">User Interface Tour</a></li>
                        <li id="keyboard_shortcuts" title="Opens a tooltip with all keyboard shortcuts"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">Keyboard Shortcuts</a></li>
                        <li class="divider"></li>
                        

                        
                            
                                <li><a rel="noreferrer" href="http://nbviewer.ipython.org/github/ipython/ipython/blob/3.x/examples/Notebook/Index.ipynb" target="_blank" title="Opens in a new window">
                                
                                    <i class="fa fa-external-link menu-icon pull-right"></i>
                                

                                Notebook Help
                                </a></li>
                            
                                <li><a rel="noreferrer" href="https://help.github.com/articles/markdown-basics/" target="_blank" title="Opens in a new window">
                                
                                    <i class="fa fa-external-link menu-icon pull-right"></i>
                                

                                Markdown
                                </a></li>
                            
                            
                        
                        <li id="kernel-help-links" class="divider"></li><li><a target="_blank" title="Opens in a new window" href="http://docs.python.org/3.5?v=20170418164528"><i class="fa fa-external-link menu-icon pull-right"></i><span>Python</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://ipython.org/documentation.html?v=20170418164528"><i class="fa fa-external-link menu-icon pull-right"></i><span>IPython</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://docs.scipy.org/doc/numpy/reference/?v=20170418164528"><i class="fa fa-external-link menu-icon pull-right"></i><span>NumPy</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://docs.scipy.org/doc/scipy/reference/?v=20170418164528"><i class="fa fa-external-link menu-icon pull-right"></i><span>SciPy</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://matplotlib.org/contents.html?v=20170418164528"><i class="fa fa-external-link menu-icon pull-right"></i><span>Matplotlib</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://docs.sympy.org/latest/index.html?v=20170418164528"><i class="fa fa-external-link menu-icon pull-right"></i><span>SymPy</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://pandas.pydata.org/pandas-docs/stable/?v=20170418164528"><i class="fa fa-external-link menu-icon pull-right"></i><span>pandas</span></a></li><li class="divider"></li>
                        <li title="About Jupyter Notebook"><a id="notebook_about" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#">About</a></li>
                        
                    </ul>
                </li>
              </ul>
            </div>
        </div>
    </div>
</div>

<div id="maintoolbar" class="navbar">
  <div class="toolbar-inner navbar-inner navbar-nobg">
    <div id="maintoolbar-container" class="container toolbar"><div class="btn-group" id="save-notbook"><button class="btn btn-default" title="Save and Checkpoint" data-jupyter-action="jupyter-notebook:save-notebook"><i class="fa-save fa"></i></button></div><div class="btn-group" id="insert_above_below"><button class="btn btn-default" title="insert cell below" data-jupyter-action="jupyter-notebook:insert-cell-below"><i class="fa-plus fa"></i></button></div><div class="btn-group" id="cut_copy_paste"><button class="btn btn-default" title="cut selected cells" data-jupyter-action="jupyter-notebook:cut-cell"><i class="fa-cut fa"></i></button><button class="btn btn-default" title="copy selected cells" data-jupyter-action="jupyter-notebook:copy-cell"><i class="fa-copy fa"></i></button><button class="btn btn-default" title="paste cells below" data-jupyter-action="jupyter-notebook:paste-cell-below"><i class="fa-paste fa"></i></button></div><div class="btn-group" id="move_up_down"><button class="btn btn-default" title="move selected cells up" data-jupyter-action="jupyter-notebook:move-cell-up"><i class="fa-arrow-up fa"></i></button><button class="btn btn-default" title="move selected cells down" data-jupyter-action="jupyter-notebook:move-cell-down"><i class="fa-arrow-down fa"></i></button></div><div class="btn-group" id="run_int"><button class="btn btn-default" title="run cell, select below" data-jupyter-action="jupyter-notebook:run-cell-and-select-next"><i class="fa-step-forward fa"></i></button><button class="btn btn-default" title="interrupt kernel" data-jupyter-action="jupyter-notebook:interrupt-kernel"><i class="fa-stop fa"></i></button><button class="btn btn-default" title="restart the kernel (with dialog)" data-jupyter-action="jupyter-notebook:confirm-restart-kernel"><i class="fa-repeat fa"></i></button></div><select id="cell_type" class="form-control select-xs"><option value="code">Code</option><option value="markdown">Markdown</option><option value="raw">Raw NBConvert</option><option value="heading">Heading</option><option value="multiselect" disabled="disabled" style="display: none;">-</option></select><div class="btn-group"><button class="btn btn-default" title="open the command palette" data-jupyter-action="jupyter-notebook:show-command-palette"><i class="fa-keyboard-o fa"></i></button></div><div class="btn-group"><button title="show new celltoolbar selector location" class="btn btn-default">CellToolbar</button></div></div>
  </div>
</div>
</div>

<div class="lower-header-bar"></div>

</div>

<div id="site" style="height: 1174px; display: block;">


<div id="ipython-main-app">
    <div id="notebook_panel">
        <div id="notebook" tabindex="-1"><div class="container" id="notebook-container"><div class="cell text_cell rendered selected" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 137px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 21px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-1"># Language Translation</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">In this project, youre going to take a peek into the realm of neural network machine translation.  Youll be training a sequence to sequence model on a dataset of English and French sentences that can translate new sentences from English to French.</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Get the Data</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Since translating the whole language of English to French will take lots of time to train, we have provided you with a small portion of the English corpus.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 137px;"></div><div class="CodeMirror-gutters" style="display: none; height: 152px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h1 id="Language-Translation">Language Translation<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Language-Translation"></a></h1>
<p>In this project, youre going to take a peek into the realm of neural network machine translation.  Youll be training a sequence to sequence model on a dataset of English and French sentences that can translate new sentences from English to French.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Get-the-Data"></a></h2>
<p>Since translating the whole language of English to French will take lots of time to train, we have provided you with a small portion of the English corpus.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[1]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 347px; margin-bottom: -15px; border-right-width: 15px; min-height: 181px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><span><span></span>x</span></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">helper</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">problem_unittests</span> <span class="cm-keyword">as</span> <span class="cm-variable">tests</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">source_path</span> = <span class="cm-string">'data/small_vocab_en'</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">target_path</span> = <span class="cm-string">'data/small_vocab_fr'</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">source_text</span> = <span class="cm-variable">helper</span>.<span class="cm-property">load_data</span>(<span class="cm-variable">source_path</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">target_text</span> = <span class="cm-variable">helper</span>.<span class="cm-property">load_data</span>(<span class="cm-variable">target_path</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 181px;"></div><div class="CodeMirror-gutters" style="display: none; height: 196px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 48px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Explore the Data</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Play around with view_sentence_range to view different parts of the data.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 48px;"></div><div class="CodeMirror-gutters" style="display: none; height: 63px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Explore-the-Data"></a></h2>
<p>Play around with view_sentence_range to view different parts of the data.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[2]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 843px; margin-bottom: -15px; border-right-width: 15px; min-height: 368px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">view_sentence_range</span> = (<span class="cm-number">0</span>, <span class="cm-number">10</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">numpy</span> <span class="cm-keyword">as</span> <span class="cm-variable">np</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'Dataset Stats'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'Roughly the number of unique words: {}'</span>.<span class="cm-property">format</span>(<span class="cm-builtin">len</span>({<span class="cm-variable">word</span>: <span class="cm-keyword">None</span> <span class="cm-keyword">for</span> <span class="cm-variable">word</span> <span class="cm-keyword">in</span> <span class="cm-variable">source_text</span>.<span class="cm-property">split</span>()})))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">sentences</span> = <span class="cm-variable">source_text</span>.<span class="cm-property">split</span>(<span class="cm-string">'\n'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">word_counts</span> = [<span class="cm-builtin">len</span>(<span class="cm-variable">sentence</span>.<span class="cm-property">split</span>()) <span class="cm-keyword">for</span> <span class="cm-variable">sentence</span> <span class="cm-keyword">in</span> <span class="cm-variable">sentences</span>]</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'Number of sentences: {}'</span>.<span class="cm-property">format</span>(<span class="cm-builtin">len</span>(<span class="cm-variable">sentences</span>)))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'Average number of words in a sentence: {}'</span>.<span class="cm-property">format</span>(<span class="cm-variable">np</span>.<span class="cm-property">average</span>(<span class="cm-variable">word_counts</span>)))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>()</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'English sentences {} to {}:'</span>.<span class="cm-property">format</span>(<span class="cm-operator">*</span><span class="cm-variable">view_sentence_range</span>))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'\n'</span>.<span class="cm-property">join</span>(<span class="cm-variable">source_text</span>.<span class="cm-property">split</span>(<span class="cm-string">'\n'</span>)[<span class="cm-variable">view_sentence_range</span>[<span class="cm-number">0</span>]:<span class="cm-variable">view_sentence_range</span>[<span class="cm-number">1</span>]]))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>()</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'French sentences {} to {}:'</span>.<span class="cm-property">format</span>(<span class="cm-operator">*</span><span class="cm-variable">view_sentence_range</span>))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'\n'</span>.<span class="cm-property">join</span>(<span class="cm-variable">target_text</span>.<span class="cm-property">split</span>(<span class="cm-string">'\n'</span>)[<span class="cm-variable">view_sentence_range</span>[<span class="cm-number">0</span>]:<span class="cm-variable">view_sentence_range</span>[<span class="cm-number">1</span>]]))</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 368px;"></div><div class="CodeMirror-gutters" style="display: none; height: 383px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""><div class="output_area"><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>Dataset Stats
Roughly the number of unique words: 227
Number of sentences: 137861
Average number of words in a sentence: 13.225277634719028

English sentences 0 to 10:
new jersey is sometimes quiet during autumn , and it is snowy in april .
the united states is usually chilly during july , and it is usually freezing in november .
california is usually quiet during march , and it is usually hot in june .
the united states is sometimes mild during june , and it is cold in september .
your least liked fruit is the grape , but my least liked is the apple .
his favorite fruit is the orange , but my favorite is the grape .
paris is relaxing during december , but it is usually chilly in july .
new jersey is busy during spring , and it is never hot in march .
our least liked fruit is the lemon , but my least liked is the grape .
the united states is sometimes busy during january , and it is sometimes warm in november .

French sentences 0 to 10:
new jersey est parfois calme pendant l' automne , et il est neigeux en avril .
les tats-unis est gnralement froid en juillet , et il gle habituellement en novembre .
california est gnralement calme en mars , et il est gnralement chaud en juin .
les tats-unis est parfois lgre en juin , et il fait froid en septembre .
votre moins aim fruit est le raisin , mais mon moins aim est la pomme .
son fruit prfr est l'orange , mais mon prfr est le raisin .
paris est relaxant en dcembre , mais il est gnralement froid en juillet .
new jersey est occup au printemps , et il est jamais chaude en mars .
notre fruit est moins aim le citron , mais mon moins aim est le raisin .
les tats-unis est parfois occup en janvier , et il est parfois chaud en novembre .
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 219px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Implement Preprocessing Function</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Text to Word Ids</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">As you did with other RNNs, you must turn the text into a number so the computer can understand it. In the function <span class="cm-comment">`text_to_ids()`</span>, you'll turn <span class="cm-comment">`source_text`</span> and <span class="cm-comment">`target_text`</span> from words to ids.  However, you need to add the <span class="cm-comment">`&lt;EOS&gt;`</span> word id at the end of each sentence from <span class="cm-comment">`target_text`</span>.  This will help the neural network predict when the sentence should end.</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">You can get the <span class="cm-comment">`&lt;EOS&gt;`</span> word id by doing:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-comment">```python</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">target_vocab_to_int</span>[<span class="cm-string">'&lt;EOS&gt;'</span>]</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-comment">```</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">You can get other word ids using <span class="cm-comment">`source_vocab_to_int`</span> and <span class="cm-comment">`target_vocab_to_int`</span>.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 219px;"></div><div class="CodeMirror-gutters" style="display: none; height: 234px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Implement-Preprocessing-Function">Implement Preprocessing Function<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Implement-Preprocessing-Function"></a></h2>
<h3 id="Text-to-Word-Ids">Text to Word Ids<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Text-to-Word-Ids"></a></h3>
<p>As you did with other RNNs, you must turn the text into a number so the computer can understand it. In the function <code>text_to_ids()</code>, you'll turn <code>source_text</code> and <code>target_text</code> from words to ids.  However, you need to add the <code>&lt;EOS&gt;</code> word id at the end of each sentence from <code>target_text</code>.  This will help the neural network predict when the sentence should end.</p>
<p>You can get the <code>&lt;EOS&gt;</code> word id by doing:</p>
<pre><code class="cm-s-ipython language-python"><span class="cm-variable">target_vocab_to_int</span>[<span class="cm-string">'&lt;EOS&gt;'</span>]
</code></pre>
<p>You can get other word ids using <code>source_vocab_to_int</code> and <code>target_vocab_to_int</code>.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[3]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 675px; margin-bottom: -15px; border-right-width: 15px; min-height: 572px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">text_to_ids</span>(<span class="cm-variable">source_text</span>, <span class="cm-variable">target_text</span>, <span class="cm-variable">source_vocab_to_int</span>, <span class="cm-variable">target_vocab_to_int</span>):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    Convert source and target text to proper word ids</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param source_text: String that contains all the source text.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param target_text: String that contains all the target text.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param source_vocab_to_int: Dictionary to go from the source words to an id</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :return: A tuple of lists (source_id_text, target_id_text)</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># TODO: Implement Function</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">source_id_text</span> = []</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">target_id_text</span> = []</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">for</span> <span class="cm-variable">sentence</span> <span class="cm-keyword">in</span> <span class="cm-variable">source_text</span>.<span class="cm-property">split</span>(<span class="cm-string">"\n"</span>):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">line</span> = []</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-keyword">for</span> <span class="cm-variable">word</span> <span class="cm-keyword">in</span> <span class="cm-variable">sentence</span>.<span class="cm-property">split</span>():</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">line</span>.<span class="cm-property">append</span>(<span class="cm-variable">source_vocab_to_int</span>[<span class="cm-variable">word</span>])</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">source_id_text</span>.<span class="cm-property">append</span>(<span class="cm-variable">line</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">for</span> <span class="cm-variable">sentence</span> <span class="cm-keyword">in</span> <span class="cm-variable">target_text</span>.<span class="cm-property">split</span>(<span class="cm-string">"\n"</span>):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">line</span> = []</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-keyword">for</span> <span class="cm-variable">word</span> <span class="cm-keyword">in</span> <span class="cm-variable">sentence</span>.<span class="cm-property">split</span>():</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">line</span>.<span class="cm-property">append</span>(<span class="cm-variable">target_vocab_to_int</span>[<span class="cm-variable">word</span>])</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">line</span>.<span class="cm-property">append</span>(<span class="cm-variable">target_vocab_to_int</span>[<span class="cm-string">'&lt;EOS&gt;'</span>])   </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">target_id_text</span>.<span class="cm-property">append</span>(<span class="cm-variable">line</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> (<span class="cm-variable">source_id_text</span>, <span class="cm-variable">target_id_text</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">tests</span>.<span class="cm-property">test_text_to_ids</span>(<span class="cm-variable">text_to_ids</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 572px;"></div><div class="CodeMirror-gutters" style="display: none; height: 587px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""><div class="output_area"><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>Tests Passed
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 46px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 18px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Preprocess all the data and save it</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Running the code cell below will preprocess all the data and save it to file.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 46px;"></div><div class="CodeMirror-gutters" style="display: none; height: 61px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Preprocess-all-the-data-and-save-it"></a></h3>
<p>Running the code cell below will preprocess all the data and save it to file.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[4]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 563px; margin-bottom: -15px; border-right-width: 15px; min-height: 79px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">helper</span>.<span class="cm-property">preprocess_and_save_data</span>(<span class="cm-variable">source_path</span>, <span class="cm-variable">target_path</span>, <span class="cm-variable">text_to_ids</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 79px;"></div><div class="CodeMirror-gutters" style="display: none; height: 94px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 66px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 21px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-1"># Check Point</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 66px;"></div><div class="CodeMirror-gutters" style="display: none; height: 81px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h1 id="Check-Point">Check Point<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Check-Point"></a></h1>
<p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[5]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 867px; margin-bottom: -15px; border-right-width: 15px; min-height: 130px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">numpy</span> <span class="cm-keyword">as</span> <span class="cm-variable">np</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">helper</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">(<span class="cm-variable">source_int_text</span>, <span class="cm-variable">target_int_text</span>), (<span class="cm-variable">source_vocab_to_int</span>, <span class="cm-variable">target_vocab_to_int</span>), <span class="cm-variable">_</span> = <span class="cm-variable">helper</span>.<span class="cm-property">load_preprocess</span>()</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 130px;"></div><div class="CodeMirror-gutters" style="display: none; height: 145px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 46px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 18px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Check the Version of TensorFlow and Access to GPU</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">This will check to make sure you have the correct version of TensorFlow and access to a GPU</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 46px;"></div><div class="CodeMirror-gutters" style="display: none; height: 61px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Check-the-Version-of-TensorFlow-and-Access-to-GPU"></a></h3>
<p>This will check to make sure you have the correct version of TensorFlow and access to a GPU</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[6]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 835px; margin-bottom: -15px; border-right-width: 15px; min-height: 283px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">distutils</span>.<span class="cm-property">version</span> <span class="cm-keyword">import</span> <span class="cm-variable">LooseVersion</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">warnings</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">tensorflow</span> <span class="cm-keyword">as</span> <span class="cm-variable">tf</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-comment"># Check TensorFlow Version</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">assert</span> <span class="cm-variable">LooseVersion</span>(<span class="cm-variable">tf</span>.<span class="cm-property">__version__</span>) <span class="cm-operator">&gt;</span>= <span class="cm-variable">LooseVersion</span>(<span class="cm-string">'1.0'</span>), <span class="cm-string">'Please use TensorFlow version 1.0 or newer'</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'TensorFlow Version: {}'</span>.<span class="cm-property">format</span>(<span class="cm-variable">tf</span>.<span class="cm-property">__version__</span>))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-comment"># Check for a GPU</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">if</span> <span class="cm-keyword">not</span> <span class="cm-variable">tf</span>.<span class="cm-property">test</span>.<span class="cm-property">gpu_device_name</span>():</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">warnings</span>.<span class="cm-property">warn</span>(<span class="cm-string">'No GPU found. Please use a GPU to train your neural network.'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">else</span>:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-builtin">print</span>(<span class="cm-string">'Default GPU Device: {}'</span>.<span class="cm-property">format</span>(<span class="cm-variable">tf</span>.<span class="cm-property">test</span>.<span class="cm-property">gpu_device_name</span>()))</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 283px;"></div><div class="CodeMirror-gutters" style="display: none; height: 298px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""><div class="output_area"><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>TensorFlow Version: 1.0.0
Default GPU Device: /gpu:0
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 372px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Build the Neural Network</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">You'll build the components necessary to build a Sequence-to-Sequence model by implementing the following functions below:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-comment cm-variable-2">`model_inputs`</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-comment cm-variable-2">`process_encoding_input`</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-comment cm-variable-2">`encoding_layer`</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-comment cm-variable-2">`decoding_layer_train`</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-comment cm-variable-2">`decoding_layer_infer`</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-comment cm-variable-2">`decoding_layer`</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-comment cm-variable-2">`seq2seq_model`</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Input</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Implement the <span class="cm-comment">`model_inputs()`</span> function to create TF Placeholders for the Neural Network. It should create the following placeholders:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Targets placeholder with rank 2.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Learning rate placeholder with rank 0.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Return the placeholders in the following the tuple (Input, Targets, Learing Rate, Keep Probability)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 372px;"></div><div class="CodeMirror-gutters" style="display: none; height: 387px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Build-the-Neural-Network"></a></h2>
<p>You'll build the components necessary to build a Sequence-to-Sequence model by implementing the following functions below:</p>
<ul>
<li><code>model_inputs</code></li>
<li><code>process_encoding_input</code></li>
<li><code>encoding_layer</code></li>
<li><code>decoding_layer_train</code></li>
<li><code>decoding_layer_infer</code></li>
<li><code>decoding_layer</code></li>
<li><code>seq2seq_model</code></li>
</ul>
<h3 id="Input">Input<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Input"></a></h3>
<p>Implement the <code>model_inputs()</code> function to create TF Placeholders for the Neural Network. It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</li>
<li>Targets placeholder with rank 2.</li>
<li>Learning rate placeholder with rank 0.</li>
<li>Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</li>
</ul>
<p>Return the placeholders in the following the tuple (Input, Targets, Learing Rate, Keep Probability)</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[7]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 547px; margin-bottom: -15px; border-right-width: 15px; min-height: 317px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">model_inputs</span>():</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    Create TF Placeholders for input, targets, and learning rate.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :return: Tuple (input, targets, learning rate, keep probability)</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># TODO: Implement Function</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-builtin">input</span> = <span class="cm-variable">tf</span>.<span class="cm-property">placeholder</span>(<span class="cm-variable">tf</span>.<span class="cm-property">int32</span>, [<span class="cm-keyword">None</span>, <span class="cm-keyword">None</span>], <span class="cm-variable">name</span>=<span class="cm-string">'input'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">targets</span> = <span class="cm-variable">tf</span>.<span class="cm-property">placeholder</span>(<span class="cm-variable">tf</span>.<span class="cm-property">int32</span>, [<span class="cm-keyword">None</span>, <span class="cm-keyword">None</span>], <span class="cm-variable">name</span>=<span class="cm-string">'targets'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">learning_rate</span> = <span class="cm-variable">tf</span>.<span class="cm-property">placeholder</span>(<span class="cm-variable">tf</span>.<span class="cm-property">float32</span>, <span class="cm-variable">name</span>=<span class="cm-string">'learning_rate'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">keep_prob</span> = <span class="cm-variable">tf</span>.<span class="cm-property">placeholder</span>(<span class="cm-variable">tf</span>.<span class="cm-property">float32</span>, <span class="cm-variable">name</span>=<span class="cm-string">'keep_prob'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-builtin">input</span>, <span class="cm-variable">targets</span>, <span class="cm-variable">learning_rate</span>, <span class="cm-variable">keep_prob</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">tests</span>.<span class="cm-property">test_model_inputs</span>(<span class="cm-variable">model_inputs</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 317px;"></div><div class="CodeMirror-gutters" style="display: none; height: 332px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""><div class="output_area"><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>Tests Passed
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 63px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 18px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Process Decoding Input</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Implement <span class="cm-comment">`process_decoding_input`</span> using TensorFlow to remove the last word id from each batch in <span class="cm-comment">`target_data`</span> and concat the GO ID to the begining of each batch.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 63px;"></div><div class="CodeMirror-gutters" style="display: none; height: 78px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Process-Decoding-Input">Process Decoding Input<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Process-Decoding-Input"></a></h3>
<p>Implement <code>process_decoding_input</code> using TensorFlow to remove the last word id from each batch in <code>target_data</code> and concat the GO ID to the begining of each batch.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[8]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 747px; margin-bottom: -15px; border-right-width: 15px; min-height: 300px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">process_decoding_input</span>(<span class="cm-variable">target_data</span>, <span class="cm-variable">target_vocab_to_int</span>, <span class="cm-variable">batch_size</span>):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    Preprocess target data for dencoding</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param target_data: Target Placehoder</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param batch_size: Batch Size</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :return: Preprocessed target data</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># TODO: Implement Function</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">ending</span> = <span class="cm-variable">tf</span>.<span class="cm-property">strided_slice</span>(<span class="cm-variable">target_data</span>, [<span class="cm-number">0</span>, <span class="cm-number">0</span>], [<span class="cm-variable">batch_size</span>, <span class="cm-operator">-</span><span class="cm-number">1</span>], [<span class="cm-number">1</span>, <span class="cm-number">1</span>])</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">dec_input</span> = <span class="cm-variable">tf</span>.<span class="cm-property">concat</span>([<span class="cm-variable">tf</span>.<span class="cm-property">fill</span>([<span class="cm-variable">batch_size</span>, <span class="cm-number">1</span>], <span class="cm-variable">target_vocab_to_int</span>[<span class="cm-string">'&lt;GO&gt;'</span>]), <span class="cm-variable">ending</span>], <span class="cm-number">1</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-variable">dec_input</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">tests</span>.<span class="cm-property">test_process_decoding_input</span>(<span class="cm-variable">process_decoding_input</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 300px;"></div><div class="CodeMirror-gutters" style="display: none; height: 315px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""><div class="output_area"><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>Tests Passed
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 63px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 18px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Encoding</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Implement <span class="cm-comment">`encoding_layer()`</span> to create a Encoder RNN layer using <span class="cm-link">[</span><span class="cm-link cm-comment">`tf.nn.dynamic_rnn()`</span><span class="cm-link">]</span><span class="cm-string cm-url">(https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn)</span>.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 63px;"></div><div class="CodeMirror-gutters" style="display: none; height: 78px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Encoding">Encoding<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Encoding"></a></h3>
<p>Implement <code>encoding_layer()</code> to create a Encoder RNN layer using <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn" target="_blank"><code>tf.nn.dynamic_rnn()</code></a>.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[9]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 651px; margin-bottom: -15px; border-right-width: 15px; min-height: 351px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">encoding_layer</span>(<span class="cm-variable">rnn_inputs</span>, <span class="cm-variable">rnn_size</span>, <span class="cm-variable">num_layers</span>, <span class="cm-variable">keep_prob</span>):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    Create encoding layer</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param rnn_inputs: Inputs for the RNN</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param rnn_size: RNN Size</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param num_layers: Number of layers</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param keep_prob: Dropout keep probability</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :return: RNN state</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># TODO: Implement Function</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">LSTM</span> = <span class="cm-variable">tf</span>.<span class="cm-property">contrib</span>.<span class="cm-property">rnn</span>.<span class="cm-property">BasicLSTMCell</span>(<span class="cm-variable">rnn_size</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">cell</span> = <span class="cm-variable">tf</span>.<span class="cm-property">contrib</span>.<span class="cm-property">rnn</span>.<span class="cm-property">MultiRNNCell</span>([<span class="cm-variable">LSTM</span>]<span class="cm-operator">*</span><span class="cm-variable">num_layers</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">cell</span> = <span class="cm-variable">tf</span>.<span class="cm-property">contrib</span>.<span class="cm-property">rnn</span>.<span class="cm-property">DropoutWrapper</span>(<span class="cm-variable">cell</span>, <span class="cm-variable">output_keep_prob</span>=<span class="cm-variable">keep_prob</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">RNN_output</span>, <span class="cm-variable">RNN_state</span> = <span class="cm-variable">tf</span>.<span class="cm-property">nn</span>.<span class="cm-property">dynamic_rnn</span>(<span class="cm-variable">cell</span>, <span class="cm-variable">rnn_inputs</span>, <span class="cm-variable">dtype</span>=<span class="cm-variable">tf</span>.<span class="cm-property">float32</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-variable">RNN_state</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">tests</span>.<span class="cm-property">test_encoding_layer</span>(<span class="cm-variable">encoding_layer</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 351px;"></div><div class="CodeMirror-gutters" style="display: none; height: 366px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""><div class="output_area"><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>Tests Passed
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 131px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 18px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Decoding - Training</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Create training logits using <span class="cm-link">[</span><span class="cm-link cm-comment">`tf.contrib.seq2seq.simple_decoder_fn_train()`</span><span class="cm-link">]</span><span class="cm-string cm-url">(https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_train)</span> and <span class="cm-link">[</span><span class="cm-link cm-comment">`tf.contrib.seq2seq.dynamic_rnn_decoder()`</span><span class="cm-link">]</span><span class="cm-string cm-url">(https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder)</span>.  Apply the <span class="cm-comment">`output_fn`</span> to the <span class="cm-link">[</span><span class="cm-link cm-comment">`tf.contrib.seq2seq.dynamic_rnn_decoder()`</span><span class="cm-link">]</span><span class="cm-string cm-url">(https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder)</span> outputs.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 131px;"></div><div class="CodeMirror-gutters" style="display: none; height: 146px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Decoding---Training">Decoding - Training<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Decoding---Training"></a></h3>
<p>Create training logits using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_train" target="_blank"><code>tf.contrib.seq2seq.simple_decoder_fn_train()</code></a> and <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder" target="_blank"><code>tf.contrib.seq2seq.dynamic_rnn_decoder()</code></a>.  Apply the <code>output_fn</code> to the <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder" target="_blank"><code>tf.contrib.seq2seq.dynamic_rnn_decoder()</code></a> outputs.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[10]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1163px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1163px; margin-bottom: -15px; border-right-width: 15px; min-height: 470px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">decoding_layer_train</span>(<span class="cm-variable">encoder_state</span>, <span class="cm-variable">dec_cell</span>, <span class="cm-variable">dec_embed_input</span>, <span class="cm-variable">sequence_length</span>, <span class="cm-variable">decoding_scope</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                         <span class="cm-variable">output_fn</span>, <span class="cm-variable">keep_prob</span>):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    Create a decoding layer for training</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param encoder_state: Encoder State</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param dec_cell: Decoder RNN Cell</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param dec_embed_input: Decoder embedded input</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param sequence_length: Sequence Length</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param decoding_scope: TenorFlow Variable Scope for decoding</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param output_fn: Function to apply the output layer</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param keep_prob: Dropout keep probability</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :return: Train Logits</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># TODO: Implement Function</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">train_decoder_fn</span> = <span class="cm-variable">tf</span>.<span class="cm-property">contrib</span>.<span class="cm-property">seq2seq</span>.<span class="cm-property">simple_decoder_fn_train</span>(<span class="cm-variable">encoder_state</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">train_pred</span>, <span class="cm-variable">_</span>, <span class="cm-variable">_</span> = <span class="cm-variable">tf</span>.<span class="cm-property">contrib</span>.<span class="cm-property">seq2seq</span>.<span class="cm-property">dynamic_rnn_decoder</span>(<span class="cm-variable">dec_cell</span>, <span class="cm-variable">train_decoder_fn</span>, <span class="cm-variable">dec_embed_input</span>, <span class="cm-variable">sequence_length</span>, <span class="cm-variable">scope</span>=<span class="cm-variable">decoding_scope</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># Apply output function</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">train_logits</span> =  <span class="cm-variable">output_fn</span>(<span class="cm-variable">train_pred</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">train_logits</span> = <span class="cm-variable">tf</span>.<span class="cm-property">nn</span>.<span class="cm-property">dropout</span>(<span class="cm-variable">train_logits</span>, <span class="cm-variable">keep_prob</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-variable">train_logits</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">tests</span>.<span class="cm-property">test_decoding_layer_train</span>(<span class="cm-variable">decoding_layer_train</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 470px;"></div><div class="CodeMirror-gutters" style="display: none; height: 500px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""><div class="output_area"><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>Tests Passed
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 97px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 18px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Decoding - Inference</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Create inference logits using <span class="cm-link">[</span><span class="cm-link cm-comment">`tf.contrib.seq2seq.simple_decoder_fn_inference()`</span><span class="cm-link">]</span><span class="cm-string cm-url">(https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference)</span> and <span class="cm-link">[</span><span class="cm-link cm-comment">`tf.contrib.seq2seq.dynamic_rnn_decoder()`</span><span class="cm-link">]</span><span class="cm-string cm-url">(https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder)</span>. </span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 97px;"></div><div class="CodeMirror-gutters" style="display: none; height: 112px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Decoding---Inference">Decoding - Inference<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Decoding---Inference"></a></h3>
<p>Create inference logits using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference" target="_blank"><code>tf.contrib.seq2seq.simple_decoder_fn_inference()</code></a> and <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder" target="_blank"><code>tf.contrib.seq2seq.dynamic_rnn_decoder()</code></a>. </p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[11]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 859px; margin-bottom: -15px; border-right-width: 15px; min-height: 708px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">decoding_layer_infer</span>(<span class="cm-variable">encoder_state</span>, <span class="cm-variable">dec_cell</span>, <span class="cm-variable">dec_embeddings</span>, <span class="cm-variable">start_of_sequence_id</span>, <span class="cm-variable">end_of_sequence_id</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                         <span class="cm-variable">maximum_length</span>, <span class="cm-variable">vocab_size</span>, <span class="cm-variable">decoding_scope</span>, <span class="cm-variable">output_fn</span>, <span class="cm-variable">keep_prob</span>):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    Create a decoding layer for inference</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param encoder_state: Encoder state</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param dec_cell: Decoder RNN Cell</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param dec_embeddings: Decoder embeddings</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param start_of_sequence_id: GO ID</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param end_of_sequence_id: EOS Id</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param maximum_length: Maximum length of </span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param vocab_size: Size of vocabulary</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param decoding_scope: TensorFlow Variable Scope for decoding</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param output_fn: Function to apply the output layer</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param keep_prob: Dropout keep probability</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :return: Inference Logits</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># TODO: Implement Function</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">decoder_fn</span> = <span class="cm-variable">tf</span>.<span class="cm-property">contrib</span>.<span class="cm-property">seq2seq</span>.<span class="cm-property">simple_decoder_fn_inference</span>(</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                                          <span class="cm-variable">output_fn</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                                          <span class="cm-variable">encoder_state</span>, </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                                          <span class="cm-variable">dec_embeddings</span>, </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                                          <span class="cm-variable">start_of_sequence_id</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                                          <span class="cm-variable">end_of_sequence_id</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                                          <span class="cm-variable">maximum_length</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                                          <span class="cm-variable">vocab_size</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                                          <span class="cm-variable">dtype</span>=<span class="cm-variable">tf</span>.<span class="cm-property">int32</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">outputs</span>, <span class="cm-variable">final_state</span>, <span class="cm-variable">final_context_state</span> = <span class="cm-variable">tf</span>.<span class="cm-property">contrib</span>.<span class="cm-property">seq2seq</span>.<span class="cm-property">dynamic_rnn_decoder</span>(</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                                                         <span class="cm-variable">dec_cell</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                                                         <span class="cm-variable">decoder_fn</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                                                         <span class="cm-variable">scope</span>=<span class="cm-variable">decoding_scope</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">inf_logits</span> = <span class="cm-variable">outputs</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-variable">inf_logits</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">tests</span>.<span class="cm-property">test_decoding_layer_infer</span>(<span class="cm-variable">decoding_layer_infer</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 708px;"></div><div class="CodeMirror-gutters" style="display: none; height: 723px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""><div class="output_area"><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>Tests Passed
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 233px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 18px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Build the Decoding Layer</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Implement <span class="cm-comment">`decoding_layer()`</span> to create a Decoder RNN layer.</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Create RNN cell for decoding using </span><span class="cm-comment cm-variable-2">`rnn_size`</span><span class="cm-variable-2"> and </span><span class="cm-comment cm-variable-2">`num_layers`</span><span class="cm-variable-2">.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Create the output fuction using </span><span class="cm-link cm-variable-2">[</span><span class="cm-link cm-comment cm-variable-2">`lambda`</span><span class="cm-link cm-variable-2">]</span><span class="cm-string cm-url cm-variable-2">(https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions)</span><span class="cm-variable-2"> to transform it's input, logits, to class logits.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Use the your </span><span class="cm-comment cm-variable-2">`decoding_layer_train(encoder_state, dec_cell, dec_embed_input, sequence_length, decoding_scope, output_fn, keep_prob)`</span><span class="cm-variable-2"> function to get the training logits.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Use your </span><span class="cm-comment cm-variable-2">`decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, maximum_length, vocab_size, decoding_scope, output_fn, keep_prob)`</span><span class="cm-variable-2"> function to get the inference logits.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Note: You'll need to use <span class="cm-link">[tf.variable_scope]</span><span class="cm-string cm-url">(https://www.tensorflow.org/api_docs/python/tf/variable_scope)</span> to share variables between training and inference.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 233px;"></div><div class="CodeMirror-gutters" style="display: none; height: 248px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Build-the-Decoding-Layer">Build the Decoding Layer<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Build-the-Decoding-Layer"></a></h3>
<p>Implement <code>decoding_layer()</code> to create a Decoder RNN layer.</p>
<ul>
<li>Create RNN cell for decoding using <code>rnn_size</code> and <code>num_layers</code>.</li>
<li>Create the output fuction using <a href="https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions" target="_blank"><code>lambda</code></a> to transform it's input, logits, to class logits.</li>
<li>Use the your <code>decoding_layer_train(encoder_state, dec_cell, dec_embed_input, sequence_length, decoding_scope, output_fn, keep_prob)</code> function to get the training logits.</li>
<li>Use your <code>decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, maximum_length, vocab_size, decoding_scope, output_fn, keep_prob)</code> function to get the inference logits.</li>
</ul>
<p>Note: You'll need to use <a href="https://www.tensorflow.org/api_docs/python/tf/variable_scope" target="_blank">tf.variable_scope</a> to share variables between training and inference.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[12]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1123px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1123px; margin-bottom: -15px; border-right-width: 15px; min-height: 793px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">decoding_layer</span>(<span class="cm-variable">dec_embed_input</span>, <span class="cm-variable">dec_embeddings</span>, <span class="cm-variable">encoder_state</span>, <span class="cm-variable">vocab_size</span>, <span class="cm-variable">sequence_length</span>, <span class="cm-variable">rnn_size</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                   <span class="cm-variable">num_layers</span>, <span class="cm-variable">target_vocab_to_int</span>, <span class="cm-variable">keep_prob</span>):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    Create decoding layer</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param dec_embed_input: Decoder embedded input</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param dec_embeddings: Decoder embeddings</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param encoder_state: The encoded state</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param vocab_size: Size of vocabulary</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param sequence_length: Sequence Length</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param rnn_size: RNN Size</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param num_layers: Number of layers</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param keep_prob: Dropout keep probability</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :return: Tuple of (Training Logits, Inference Logits)</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># TODO: Implement Function</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">start_of_sequence_id</span> = <span class="cm-variable">target_vocab_to_int</span>[<span class="cm-string">'&lt;GO&gt;'</span>]</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">end_of_sequence_id</span> = <span class="cm-variable">target_vocab_to_int</span>[<span class="cm-string">'&lt;EOS&gt;'</span>]</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># 1. Create RNN cell for decoding using rnn_size and num_layers.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">lstm</span> = <span class="cm-variable">tf</span>.<span class="cm-property">contrib</span>.<span class="cm-property">rnn</span>.<span class="cm-property">BasicLSTMCell</span>(<span class="cm-variable">rnn_size</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">cell</span> = <span class="cm-variable">tf</span>.<span class="cm-property">contrib</span>.<span class="cm-property">rnn</span>.<span class="cm-property">MultiRNNCell</span>([<span class="cm-variable">lstm</span>]<span class="cm-operator">*</span><span class="cm-variable">num_layers</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">cell</span> = <span class="cm-variable">tf</span>.<span class="cm-property">contrib</span>.<span class="cm-property">rnn</span>.<span class="cm-property">DropoutWrapper</span>(<span class="cm-variable">cell</span>, <span class="cm-variable">output_keep_prob</span>=<span class="cm-variable">keep_prob</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># 2. Create the output fuction using lambda to transform it's input, logits, to class logits.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">output_fn</span> = <span class="cm-keyword">lambda</span> <span class="cm-variable">x</span>: <span class="cm-variable">tf</span>.<span class="cm-property">contrib</span>.<span class="cm-property">layers</span>.<span class="cm-property">fully_connected</span>(<span class="cm-variable">x</span>, <span class="cm-variable">vocab_size</span>, <span class="cm-keyword">None</span>, <span class="cm-variable">scope</span>=<span class="cm-variable">decoding_scope</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># 3. Use the your decoding_layer_train(encoder_state, dec_cell, dec_embed_input, </span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">with</span> <span class="cm-variable">tf</span>.<span class="cm-property">variable_scope</span>(<span class="cm-string">'decoding'</span>) <span class="cm-keyword">as</span> <span class="cm-variable">decoding_scope</span>:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">train_logits</span> = <span class="cm-variable">decoding_layer_train</span>(<span class="cm-variable">encoder_state</span>, <span class="cm-variable">cell</span>, <span class="cm-variable">dec_embed_input</span>, <span class="cm-variable">sequence_length</span>,<span class="cm-variable">decoding_scope</span>, </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                          <span class="cm-variable">output_fn</span>, <span class="cm-variable">keep_prob</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># 4. Use your decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, </span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-comment">#end_of_sequence_id, maximum_length, vocab_size, decoding_scope, output_fn, keep_prob) function to get the inference logits.        </span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">with</span> <span class="cm-variable">tf</span>.<span class="cm-property">variable_scope</span>(<span class="cm-string">'decoding'</span>, <span class="cm-variable">reuse</span>=<span class="cm-keyword">True</span>) <span class="cm-keyword">as</span> <span class="cm-variable">decoding_scope</span>:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">infer_logits</span> = <span class="cm-variable">decoding_layer_infer</span>(<span class="cm-variable">encoder_state</span>, <span class="cm-variable">cell</span>, <span class="cm-variable">dec_embeddings</span>, <span class="cm-variable">start_of_sequence_id</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                        <span class="cm-variable">end_of_sequence_id</span>, <span class="cm-variable">sequence_length</span>, <span class="cm-variable">vocab_size</span>, <span class="cm-variable">decoding_scope</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                                        <span class="cm-variable">output_fn</span>, <span class="cm-variable">keep_prob</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-variable">train_logits</span>, <span class="cm-variable">infer_logits</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">tests</span>.<span class="cm-property">test_decoding_layer</span>(<span class="cm-variable">decoding_layer</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 793px;"></div><div class="CodeMirror-gutters" style="display: none; height: 823px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""><div class="output_area"><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>Tests Passed
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 165px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 18px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Build the Neural Network</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Apply the functions you implemented above to:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Apply embedding to the input data for the encoder.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Encode the input using your </span><span class="cm-comment cm-variable-2">`encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob)`</span><span class="cm-variable-2">.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Process target data using your </span><span class="cm-comment cm-variable-2">`process_encoding_input(target_data, target_vocab_to_int, batch_size)`</span><span class="cm-variable-2"> function.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Apply embedding to the target data for the decoder.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Decode the encoded input using your </span><span class="cm-comment cm-variable-2">`decoding_layer(dec_embed_input, dec_embeddings, encoder_state, vocab_size, sequence_length, rnn_size, num_layers, target_vocab_to_int, keep_prob)`</span><span class="cm-variable-2">.</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 165px;"></div><div class="CodeMirror-gutters" style="display: none; height: 180px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Build-the-Neural-Network"></a></h3>
<p>Apply the functions you implemented above to:</p>
<ul>
<li>Apply embedding to the input data for the encoder.</li>
<li>Encode the input using your <code>encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob)</code>.</li>
<li>Process target data using your <code>process_encoding_input(target_data, target_vocab_to_int, batch_size)</code> function.</li>
<li>Apply embedding to the target data for the decoder.</li>
<li>Decode the encoded input using your <code>decoding_layer(dec_embed_input, dec_embeddings, encoder_state, vocab_size, sequence_length, rnn_size, num_layers, target_vocab_to_int, keep_prob)</code>.</li>
</ul>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[13]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1187px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1187px; margin-bottom: -15px; border-right-width: 15px; min-height: 555px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">seq2seq_model</span>(<span class="cm-variable">input_data</span>, <span class="cm-variable">target_data</span>, <span class="cm-variable">keep_prob</span>, <span class="cm-variable">batch_size</span>, <span class="cm-variable">sequence_length</span>, <span class="cm-variable">source_vocab_size</span>, <span class="cm-variable">target_vocab_size</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                  <span class="cm-variable">enc_embedding_size</span>, <span class="cm-variable">dec_embedding_size</span>, <span class="cm-variable">rnn_size</span>, <span class="cm-variable">num_layers</span>, <span class="cm-variable">target_vocab_to_int</span>):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    Build the Sequence-to-Sequence part of the neural network</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param input_data: Input placeholder</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param target_data: Target placeholder</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param keep_prob: Dropout keep probability placeholder</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param batch_size: Batch Size</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param sequence_length: Sequence Length</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param source_vocab_size: Source vocabulary size</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param target_vocab_size: Target vocabulary size</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param enc_embedding_size: Decoder embedding size</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param dec_embedding_size: Encoder embedding size</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param rnn_size: RNN Size</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param num_layers: Number of layers</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :return: Tuple of (Training Logits, Inference Logits)</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># TODO: Implement Function</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">enc_embed_input</span> = <span class="cm-variable">tf</span>.<span class="cm-property">contrib</span>.<span class="cm-property">layers</span>.<span class="cm-property">embed_sequence</span>(<span class="cm-variable">input_data</span>, <span class="cm-variable">source_vocab_size</span>, <span class="cm-variable">enc_embedding_size</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">encoder_state</span> = <span class="cm-variable">encoding_layer</span>(<span class="cm-variable">enc_embed_input</span>, <span class="cm-variable">rnn_size</span>, <span class="cm-variable">num_layers</span>, <span class="cm-variable">keep_prob</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">dec_embed_input</span> = <span class="cm-variable">process_decoding_input</span>(<span class="cm-variable">target_data</span>, <span class="cm-variable">target_vocab_to_int</span>, <span class="cm-variable">batch_size</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">dec_embeddings</span> = <span class="cm-variable">tf</span>.<span class="cm-property">Variable</span>(<span class="cm-variable">tf</span>.<span class="cm-property">random_uniform</span>([<span class="cm-variable">target_vocab_size</span>, <span class="cm-variable">dec_embedding_size</span>]))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">dec_embed_input</span> = <span class="cm-variable">tf</span>.<span class="cm-property">nn</span>.<span class="cm-property">embedding_lookup</span>(<span class="cm-variable">dec_embeddings</span>, <span class="cm-variable">dec_embed_input</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">training_logits</span>, <span class="cm-variable">inference_logits</span> = <span class="cm-variable">decoding_layer</span>(<span class="cm-variable">dec_embed_input</span>, <span class="cm-variable">dec_embeddings</span>, <span class="cm-variable">encoder_state</span>, <span class="cm-variable">target_vocab_size</span>, <span class="cm-variable">sequence_length</span>, <span class="cm-variable">rnn_size</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                   <span class="cm-variable">num_layers</span>, <span class="cm-variable">target_vocab_to_int</span>, <span class="cm-variable">keep_prob</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> (<span class="cm-variable">training_logits</span>, <span class="cm-variable">inference_logits</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">tests</span>.<span class="cm-property">test_seq2seq_model</span>(<span class="cm-variable">seq2seq_model</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 555px;"></div><div class="CodeMirror-gutters" style="display: none; height: 585px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""><div class="output_area"><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>Tests Passed
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 219px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Neural Network Training</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Hyperparameters</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Tune the following parameters:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Set </span><span class="cm-comment cm-variable-2">`epochs`</span><span class="cm-variable-2"> to the number of epochs.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Set </span><span class="cm-comment cm-variable-2">`batch_size`</span><span class="cm-variable-2"> to the batch size.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Set </span><span class="cm-comment cm-variable-2">`rnn_size`</span><span class="cm-variable-2"> to the size of the RNNs.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Set </span><span class="cm-comment cm-variable-2">`num_layers`</span><span class="cm-variable-2"> to the number of layers.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Set </span><span class="cm-comment cm-variable-2">`encoding_embedding_size`</span><span class="cm-variable-2"> to the size of the embedding for the encoder.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Set </span><span class="cm-comment cm-variable-2">`decoding_embedding_size`</span><span class="cm-variable-2"> to the size of the embedding for the decoder.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Set </span><span class="cm-comment cm-variable-2">`learning_rate`</span><span class="cm-variable-2"> to the learning rate.</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Set </span><span class="cm-comment cm-variable-2">`keep_probability`</span><span class="cm-variable-2"> to the Dropout keep probability</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 219px;"></div><div class="CodeMirror-gutters" style="display: none; height: 234px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Neural-Network-Training"></a></h2>
<h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Hyperparameters"></a></h3>
<p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>num_layers</code> to the number of layers.</li>
<li>Set <code>encoding_embedding_size</code> to the size of the embedding for the encoder.</li>
<li>Set <code>decoding_embedding_size</code> to the size of the embedding for the decoder.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>keep_probability</code> to the Dropout keep probability</li>
</ul>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[14]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 235px; margin-bottom: -15px; border-right-width: 15px; min-height: 266px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-comment"># Number of Epochs</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">epochs</span> = <span class="cm-number">25</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-comment"># Batch Size</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">batch_size</span> = <span class="cm-number">896</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-comment"># RNN Size</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">rnn_size</span> = <span class="cm-number">1024</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-comment"># Number of Layers</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">num_layers</span> = <span class="cm-number">2</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-comment"># Embedding Size</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">encoding_embedding_size</span> = <span class="cm-number">250</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">decoding_embedding_size</span> = <span class="cm-number">250</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-comment"># Learning Rate</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">learning_rate</span> = <span class="cm-number">0.001</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-comment"># Dropout Keep Probability</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">keep_probability</span> = <span class="cm-number">0.8</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 266px;"></div><div class="CodeMirror-gutters" style="display: none; height: 281px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 46px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 18px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Build the Graph</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Build the graph using the neural network you implemented.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 46px;"></div><div class="CodeMirror-gutters" style="display: none; height: 61px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Build-the-Graph"></a></h3>
<p>Build the graph using the neural network you implemented.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[15]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 15px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true" style="display: block; right: 0px; left: 0px;"><div style="height: 100%; min-height: 1px; width: 1107px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true" style="height: 15px; width: 15px;"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 1107px; margin-bottom: -15px; border-right-width: 15px; min-height: 555px; padding-right: 0px; padding-bottom: 15px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">save_path</span> = <span class="cm-string">'checkpoints/dev'</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">(<span class="cm-variable">source_int_text</span>, <span class="cm-variable">target_int_text</span>), (<span class="cm-variable">source_vocab_to_int</span>, <span class="cm-variable">target_vocab_to_int</span>), <span class="cm-variable">_</span> = <span class="cm-variable">helper</span>.<span class="cm-property">load_preprocess</span>()</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">max_target_sentence_length</span> = <span class="cm-builtin">max</span>([<span class="cm-builtin">len</span>(<span class="cm-variable">sentence</span>) <span class="cm-keyword">for</span> <span class="cm-variable">sentence</span> <span class="cm-keyword">in</span> <span class="cm-variable">source_int_text</span>])</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">train_graph</span> = <span class="cm-variable">tf</span>.<span class="cm-property">Graph</span>()</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">with</span> <span class="cm-variable">train_graph</span>.<span class="cm-property">as_default</span>():</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">input_data</span>, <span class="cm-variable">targets</span>, <span class="cm-variable">lr</span>, <span class="cm-variable">keep_prob</span> = <span class="cm-variable">model_inputs</span>()</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">sequence_length</span> = <span class="cm-variable">tf</span>.<span class="cm-property">placeholder_with_default</span>(<span class="cm-variable">max_target_sentence_length</span>, <span class="cm-keyword">None</span>, <span class="cm-variable">name</span>=<span class="cm-string">'sequence_length'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">input_shape</span> = <span class="cm-variable">tf</span>.<span class="cm-property">shape</span>(<span class="cm-variable">input_data</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">train_logits</span>, <span class="cm-variable">inference_logits</span> = <span class="cm-variable">seq2seq_model</span>(</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">tf</span>.<span class="cm-property">reverse</span>(<span class="cm-variable">input_data</span>, [<span class="cm-operator">-</span><span class="cm-number">1</span>]), <span class="cm-variable">targets</span>, <span class="cm-variable">keep_prob</span>, <span class="cm-variable">batch_size</span>, <span class="cm-variable">sequence_length</span>, <span class="cm-builtin">len</span>(<span class="cm-variable">source_vocab_to_int</span>), <span class="cm-builtin">len</span>(<span class="cm-variable">target_vocab_to_int</span>),</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">encoding_embedding_size</span>, <span class="cm-variable">decoding_embedding_size</span>, <span class="cm-variable">rnn_size</span>, <span class="cm-variable">num_layers</span>, <span class="cm-variable">target_vocab_to_int</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">tf</span>.<span class="cm-property">identity</span>(<span class="cm-variable">inference_logits</span>, <span class="cm-string">'logits'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">with</span> <span class="cm-variable">tf</span>.<span class="cm-property">name_scope</span>(<span class="cm-string">"optimization"</span>):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-comment"># Loss function</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">cost</span> = <span class="cm-variable">tf</span>.<span class="cm-property">contrib</span>.<span class="cm-property">seq2seq</span>.<span class="cm-property">sequence_loss</span>(</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">train_logits</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">targets</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">tf</span>.<span class="cm-property">ones</span>([<span class="cm-variable">input_shape</span>[<span class="cm-number">0</span>], <span class="cm-variable">sequence_length</span>]))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-comment"># Optimizer</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">optimizer</span> = <span class="cm-variable">tf</span>.<span class="cm-property">train</span>.<span class="cm-property">AdamOptimizer</span>(<span class="cm-variable">lr</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-comment"># Gradient Clipping</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">gradients</span> = <span class="cm-variable">optimizer</span>.<span class="cm-property">compute_gradients</span>(<span class="cm-variable">cost</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">capped_gradients</span> = [(<span class="cm-variable">tf</span>.<span class="cm-property">clip_by_value</span>(<span class="cm-variable">grad</span>, <span class="cm-operator">-</span><span class="cm-number">1.</span>, <span class="cm-number">1.</span>), <span class="cm-variable">var</span>) <span class="cm-keyword">for</span> <span class="cm-variable">grad</span>, <span class="cm-variable">var</span> <span class="cm-keyword">in</span> <span class="cm-variable">gradients</span> <span class="cm-keyword">if</span> <span class="cm-variable">grad</span> <span class="cm-keyword">is</span> <span class="cm-keyword">not</span> <span class="cm-keyword">None</span>]</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">train_op</span> = <span class="cm-variable">optimizer</span>.<span class="cm-property">apply_gradients</span>(<span class="cm-variable">capped_gradients</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 15px solid transparent; top: 555px;"></div><div class="CodeMirror-gutters" style="display: none; height: 585px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 63px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 18px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Train</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 63px;"></div><div class="CodeMirror-gutters" style="display: none; height: 78px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Train">Train<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Train"></a></h3>
<p>Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[16]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 963px; margin-bottom: -15px; border-right-width: 15px; min-height: 1065px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">time</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">get_accuracy</span>(<span class="cm-variable">target</span>, <span class="cm-variable">logits</span>):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    Calculate accuracy</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">max_seq</span> = <span class="cm-builtin">max</span>(<span class="cm-variable">target</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>], <span class="cm-variable">logits</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>])</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">if</span> <span class="cm-variable">max_seq</span> <span class="cm-operator">-</span> <span class="cm-variable">target</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>]:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">target</span> = <span class="cm-variable">np</span>.<span class="cm-property">pad</span>(</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">target_batch</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            [(<span class="cm-number">0</span>,<span class="cm-number">0</span>),(<span class="cm-number">0</span>,<span class="cm-variable">max_seq</span> <span class="cm-operator">-</span> <span class="cm-variable">target_batch</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>]), (<span class="cm-number">0</span>,<span class="cm-number">0</span>)],</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-string">'constant'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">if</span> <span class="cm-variable">max_seq</span> <span class="cm-operator">-</span> <span class="cm-variable">batch_train_logits</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>]:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-variable">logits</span> = <span class="cm-variable">np</span>.<span class="cm-property">pad</span>(</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">logits</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            [(<span class="cm-number">0</span>,<span class="cm-number">0</span>),(<span class="cm-number">0</span>,<span class="cm-variable">max_seq</span> <span class="cm-operator">-</span> <span class="cm-variable">logits</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>]), (<span class="cm-number">0</span>,<span class="cm-number">0</span>)],</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-string">'constant'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-variable">np</span>.<span class="cm-property">mean</span>(<span class="cm-variable">np</span>.<span class="cm-property">equal</span>(<span class="cm-variable">target</span>, <span class="cm-variable">np</span>.<span class="cm-property">argmax</span>(<span class="cm-variable">logits</span>, <span class="cm-number">2</span>)))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">train_source</span> = <span class="cm-variable">source_int_text</span>[<span class="cm-variable">batch_size</span>:]</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">train_target</span> = <span class="cm-variable">target_int_text</span>[<span class="cm-variable">batch_size</span>:]</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">valid_source</span> = <span class="cm-variable">helper</span>.<span class="cm-property">pad_sentence_batch</span>(<span class="cm-variable">source_int_text</span>[:<span class="cm-variable">batch_size</span>])</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">valid_target</span> = <span class="cm-variable">helper</span>.<span class="cm-property">pad_sentence_batch</span>(<span class="cm-variable">target_int_text</span>[:<span class="cm-variable">batch_size</span>])</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">with</span> <span class="cm-variable">tf</span>.<span class="cm-property">Session</span>(<span class="cm-variable">graph</span>=<span class="cm-variable">train_graph</span>) <span class="cm-keyword">as</span> <span class="cm-variable">sess</span>:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">sess</span>.<span class="cm-property">run</span>(<span class="cm-variable">tf</span>.<span class="cm-property">global_variables_initializer</span>())</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">for</span> <span class="cm-variable">epoch_i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-variable">epochs</span>):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-keyword">for</span> <span class="cm-variable">batch_i</span>, (<span class="cm-variable">source_batch</span>, <span class="cm-variable">target_batch</span>) <span class="cm-keyword">in</span> <span class="cm-builtin">enumerate</span>(</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                <span class="cm-variable">helper</span>.<span class="cm-property">batch_data</span>(<span class="cm-variable">train_source</span>, <span class="cm-variable">train_target</span>, <span class="cm-variable">batch_size</span>)):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">start_time</span> = <span class="cm-variable">time</span>.<span class="cm-property">time</span>()</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">_</span>, <span class="cm-variable">loss</span> = <span class="cm-variable">sess</span>.<span class="cm-property">run</span>(</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                [<span class="cm-variable">train_op</span>, <span class="cm-variable">cost</span>],</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                {<span class="cm-variable">input_data</span>: <span class="cm-variable">source_batch</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                 <span class="cm-variable">targets</span>: <span class="cm-variable">target_batch</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                 <span class="cm-variable">lr</span>: <span class="cm-variable">learning_rate</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                 <span class="cm-variable">sequence_length</span>: <span class="cm-variable">target_batch</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>],</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                 <span class="cm-variable">keep_prob</span>: <span class="cm-variable">keep_probability</span>})</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">batch_train_logits</span> = <span class="cm-variable">sess</span>.<span class="cm-property">run</span>(</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                <span class="cm-variable">inference_logits</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                {<span class="cm-variable">input_data</span>: <span class="cm-variable">source_batch</span>, <span class="cm-variable">keep_prob</span>: <span class="cm-number">1.0</span>})</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">batch_valid_logits</span> = <span class="cm-variable">sess</span>.<span class="cm-property">run</span>(</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                <span class="cm-variable">inference_logits</span>,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                {<span class="cm-variable">input_data</span>: <span class="cm-variable">valid_source</span>, <span class="cm-variable">keep_prob</span>: <span class="cm-number">1.0</span>})</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">train_acc</span> = <span class="cm-variable">get_accuracy</span>(<span class="cm-variable">target_batch</span>, <span class="cm-variable">batch_train_logits</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">valid_acc</span> = <span class="cm-variable">get_accuracy</span>(<span class="cm-variable">np</span>.<span class="cm-property">array</span>(<span class="cm-variable">valid_target</span>), <span class="cm-variable">batch_valid_logits</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">end_time</span> = <span class="cm-variable">time</span>.<span class="cm-property">time</span>()</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-builtin">print</span>(<span class="cm-string">'Epoch {:&gt;3} Batch {:&gt;4}/{} - Train Accuracy: {:&gt;6.3f}, Validation Accuracy: {:&gt;6.3f}, Loss: {:&gt;6.3f}'</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">                  .<span class="cm-property">format</span>(<span class="cm-variable">epoch_i</span>, <span class="cm-variable">batch_i</span>, <span class="cm-builtin">len</span>(<span class="cm-variable">source_int_text</span>) <span class="cm-operator">//</span> <span class="cm-variable">batch_size</span>, <span class="cm-variable">train_acc</span>, <span class="cm-variable">valid_acc</span>, <span class="cm-variable">loss</span>))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># Save Model</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">saver</span> = <span class="cm-variable">tf</span>.<span class="cm-property">train</span>.<span class="cm-property">Saver</span>()</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">saver</span>.<span class="cm-property">save</span>(<span class="cm-variable">sess</span>, <span class="cm-variable">save_path</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-builtin">print</span>(<span class="cm-string">'Model Trained and Saved'</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 1065px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1080px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide" style=""></div><div class="output" style=""><div class="output_area"><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>Epoch   0 Batch    0/153 - Train Accuracy:  0.269, Validation Accuracy:  0.310, Loss:  5.883
Epoch   0 Batch    1/153 - Train Accuracy:  0.219, Validation Accuracy:  0.255, Loss:  5.414
Epoch   0 Batch    2/153 - Train Accuracy:  0.263, Validation Accuracy:  0.336, Loss:  6.250
Epoch   0 Batch    3/153 - Train Accuracy:  0.317, Validation Accuracy:  0.347, Loss:  5.548
Epoch   0 Batch    4/153 - Train Accuracy:  0.266, Validation Accuracy:  0.337, Loss:  4.762
Epoch   0 Batch    5/153 - Train Accuracy:  0.284, Validation Accuracy:  0.322, Loss:  4.095
Epoch   0 Batch    6/153 - Train Accuracy:  0.292, Validation Accuracy:  0.326, Loss:  4.297
Epoch   0 Batch    7/153 - Train Accuracy:  0.347, Validation Accuracy:  0.350, Loss:  3.823
Epoch   0 Batch    8/153 - Train Accuracy:  0.313, Validation Accuracy:  0.350, Loss:  3.951
Epoch   0 Batch    9/153 - Train Accuracy:  0.322, Validation Accuracy:  0.355, Loss:  3.878
Epoch   0 Batch   10/153 - Train Accuracy:  0.341, Validation Accuracy:  0.347, Loss:  3.688
Epoch   0 Batch   11/153 - Train Accuracy:  0.313, Validation Accuracy:  0.374, Loss:  3.777
Epoch   0 Batch   12/153 - Train Accuracy:  0.349, Validation Accuracy:  0.377, Loss:  3.651
Epoch   0 Batch   13/153 - Train Accuracy:  0.355, Validation Accuracy:  0.385, Loss:  3.576
Epoch   0 Batch   14/153 - Train Accuracy:  0.397, Validation Accuracy:  0.395, Loss:  3.429
Epoch   0 Batch   15/153 - Train Accuracy:  0.366, Validation Accuracy:  0.403, Loss:  3.502
Epoch   0 Batch   16/153 - Train Accuracy:  0.354, Validation Accuracy:  0.415, Loss:  3.543
Epoch   0 Batch   17/153 - Train Accuracy:  0.373, Validation Accuracy:  0.406, Loss:  3.413
Epoch   0 Batch   18/153 - Train Accuracy:  0.385, Validation Accuracy:  0.415, Loss:  3.342
Epoch   0 Batch   19/153 - Train Accuracy:  0.396, Validation Accuracy:  0.423, Loss:  3.287
Epoch   0 Batch   20/153 - Train Accuracy:  0.408, Validation Accuracy:  0.435, Loss:  3.259
Epoch   0 Batch   21/153 - Train Accuracy:  0.402, Validation Accuracy:  0.432, Loss:  3.241
Epoch   0 Batch   22/153 - Train Accuracy:  0.387, Validation Accuracy:  0.444, Loss:  3.279
Epoch   0 Batch   23/153 - Train Accuracy:  0.371, Validation Accuracy:  0.378, Loss:  3.116
Epoch   0 Batch   24/153 - Train Accuracy:  0.382, Validation Accuracy:  0.429, Loss:  3.608
Epoch   0 Batch   25/153 - Train Accuracy:  0.355, Validation Accuracy:  0.384, Loss:  3.181
Epoch   0 Batch   26/153 - Train Accuracy:  0.436, Validation Accuracy:  0.436, Loss:  3.164
Epoch   0 Batch   27/153 - Train Accuracy:  0.392, Validation Accuracy:  0.419, Loss:  3.066
Epoch   0 Batch   28/153 - Train Accuracy:  0.390, Validation Accuracy:  0.419, Loss:  3.189
Epoch   0 Batch   29/153 - Train Accuracy:  0.371, Validation Accuracy:  0.406, Loss:  3.175
Epoch   0 Batch   30/153 - Train Accuracy:  0.359, Validation Accuracy:  0.410, Loss:  3.322
Epoch   0 Batch   31/153 - Train Accuracy:  0.371, Validation Accuracy:  0.401, Loss:  3.265
Epoch   0 Batch   32/153 - Train Accuracy:  0.377, Validation Accuracy:  0.404, Loss:  3.273
Epoch   0 Batch   33/153 - Train Accuracy:  0.385, Validation Accuracy:  0.417, Loss:  3.175
Epoch   0 Batch   34/153 - Train Accuracy:  0.428, Validation Accuracy:  0.433, Loss:  3.067
Epoch   0 Batch   35/153 - Train Accuracy:  0.426, Validation Accuracy:  0.435, Loss:  3.022
Epoch   0 Batch   36/153 - Train Accuracy:  0.399, Validation Accuracy:  0.429, Loss:  3.101
Epoch   0 Batch   37/153 - Train Accuracy:  0.438, Validation Accuracy:  0.443, Loss:  3.015
Epoch   0 Batch   38/153 - Train Accuracy:  0.406, Validation Accuracy:  0.439, Loss:  3.036
Epoch   0 Batch   39/153 - Train Accuracy:  0.413, Validation Accuracy:  0.437, Loss:  3.030
Epoch   0 Batch   40/153 - Train Accuracy:  0.428, Validation Accuracy:  0.452, Loss:  2.995
Epoch   0 Batch   41/153 - Train Accuracy:  0.446, Validation Accuracy:  0.452, Loss:  2.838
Epoch   0 Batch   42/153 - Train Accuracy:  0.437, Validation Accuracy:  0.463, Loss:  2.930
Epoch   0 Batch   43/153 - Train Accuracy:  0.427, Validation Accuracy:  0.455, Loss:  2.914
Epoch   0 Batch   44/153 - Train Accuracy:  0.428, Validation Accuracy:  0.454, Loss:  2.898
Epoch   0 Batch   45/153 - Train Accuracy:  0.443, Validation Accuracy:  0.466, Loss:  2.840
Epoch   0 Batch   46/153 - Train Accuracy:  0.438, Validation Accuracy:  0.463, Loss:  2.827
Epoch   0 Batch   47/153 - Train Accuracy:  0.444, Validation Accuracy:  0.466, Loss:  2.773
Epoch   0 Batch   48/153 - Train Accuracy:  0.444, Validation Accuracy:  0.470, Loss:  2.808
Epoch   0 Batch   49/153 - Train Accuracy:  0.431, Validation Accuracy:  0.470, Loss:  2.817
Epoch   0 Batch   50/153 - Train Accuracy:  0.454, Validation Accuracy:  0.469, Loss:  2.737
Epoch   0 Batch   51/153 - Train Accuracy:  0.449, Validation Accuracy:  0.481, Loss:  2.754
Epoch   0 Batch   52/153 - Train Accuracy:  0.473, Validation Accuracy:  0.477, Loss:  2.681
Epoch   0 Batch   53/153 - Train Accuracy:  0.453, Validation Accuracy:  0.482, Loss:  2.721
Epoch   0 Batch   54/153 - Train Accuracy:  0.460, Validation Accuracy:  0.485, Loss:  2.707
Epoch   0 Batch   55/153 - Train Accuracy:  0.446, Validation Accuracy:  0.466, Loss:  2.677
Epoch   0 Batch   56/153 - Train Accuracy:  0.465, Validation Accuracy:  0.484, Loss:  2.672
Epoch   0 Batch   57/153 - Train Accuracy:  0.460, Validation Accuracy:  0.476, Loss:  2.620
Epoch   0 Batch   58/153 - Train Accuracy:  0.443, Validation Accuracy:  0.464, Loss:  2.608
Epoch   0 Batch   59/153 - Train Accuracy:  0.455, Validation Accuracy:  0.485, Loss:  2.631
Epoch   0 Batch   60/153 - Train Accuracy:  0.447, Validation Accuracy:  0.483, Loss:  2.614
Epoch   0 Batch   61/153 - Train Accuracy:  0.423, Validation Accuracy:  0.461, Loss:  2.571
Epoch   0 Batch   62/153 - Train Accuracy:  0.457, Validation Accuracy:  0.489, Loss:  2.565
Epoch   0 Batch   63/153 - Train Accuracy:  0.409, Validation Accuracy:  0.445, Loss:  2.652
Epoch   0 Batch   64/153 - Train Accuracy:  0.455, Validation Accuracy:  0.457, Loss:  2.622
Epoch   0 Batch   65/153 - Train Accuracy:  0.446, Validation Accuracy:  0.458, Loss:  2.607
Epoch   0 Batch   66/153 - Train Accuracy:  0.428, Validation Accuracy:  0.451, Loss:  2.582
Epoch   0 Batch   67/153 - Train Accuracy:  0.457, Validation Accuracy:  0.473, Loss:  2.536
Epoch   0 Batch   68/153 - Train Accuracy:  0.431, Validation Accuracy:  0.478, Loss:  2.598
Epoch   0 Batch   69/153 - Train Accuracy:  0.456, Validation Accuracy:  0.487, Loss:  2.466
Epoch   0 Batch   70/153 - Train Accuracy:  0.430, Validation Accuracy:  0.461, Loss:  2.444
Epoch   0 Batch   71/153 - Train Accuracy:  0.430, Validation Accuracy:  0.459, Loss:  2.392
Epoch   0 Batch   72/153 - Train Accuracy:  0.459, Validation Accuracy:  0.479, Loss:  2.417
Epoch   0 Batch   73/153 - Train Accuracy:  0.441, Validation Accuracy:  0.471, Loss:  2.379
Epoch   0 Batch   74/153 - Train Accuracy:  0.423, Validation Accuracy:  0.475, Loss:  2.455
Epoch   0 Batch   75/153 - Train Accuracy:  0.454, Validation Accuracy:  0.480, Loss:  2.357
Epoch   0 Batch   76/153 - Train Accuracy:  0.457, Validation Accuracy:  0.485, Loss:  2.322
Epoch   0 Batch   77/153 - Train Accuracy:  0.429, Validation Accuracy:  0.487, Loss:  2.425
Epoch   0 Batch   78/153 - Train Accuracy:  0.416, Validation Accuracy:  0.461, Loss:  2.332
Epoch   0 Batch   79/153 - Train Accuracy:  0.432, Validation Accuracy:  0.458, Loss:  2.258
Epoch   0 Batch   80/153 - Train Accuracy:  0.425, Validation Accuracy:  0.446, Loss:  2.205
Epoch   0 Batch   81/153 - Train Accuracy:  0.429, Validation Accuracy:  0.456, Loss:  2.214
Epoch   0 Batch   82/153 - Train Accuracy:  0.443, Validation Accuracy:  0.475, Loss:  2.230
Epoch   0 Batch   83/153 - Train Accuracy:  0.463, Validation Accuracy:  0.468, Loss:  2.166
Epoch   0 Batch   84/153 - Train Accuracy:  0.423, Validation Accuracy:  0.460, Loss:  2.235
Epoch   0 Batch   85/153 - Train Accuracy:  0.472, Validation Accuracy:  0.471, Loss:  2.129
Epoch   0 Batch   86/153 - Train Accuracy:  0.468, Validation Accuracy:  0.499, Loss:  2.176
Epoch   0 Batch   87/153 - Train Accuracy:  0.435, Validation Accuracy:  0.466, Loss:  2.148
Epoch   0 Batch   88/153 - Train Accuracy:  0.456, Validation Accuracy:  0.461, Loss:  2.069
Epoch   0 Batch   89/153 - Train Accuracy:  0.460, Validation Accuracy:  0.480, Loss:  2.136
Epoch   0 Batch   90/153 - Train Accuracy:  0.467, Validation Accuracy:  0.487, Loss:  2.108
Epoch   0 Batch   91/153 - Train Accuracy:  0.447, Validation Accuracy:  0.475, Loss:  2.118
Epoch   0 Batch   92/153 - Train Accuracy:  0.450, Validation Accuracy:  0.472, Loss:  2.082
Epoch   0 Batch   93/153 - Train Accuracy:  0.467, Validation Accuracy:  0.485, Loss:  2.098
Epoch   0 Batch   94/153 - Train Accuracy:  0.496, Validation Accuracy:  0.488, Loss:  1.990
Epoch   0 Batch   95/153 - Train Accuracy:  0.457, Validation Accuracy:  0.478, Loss:  2.055
Epoch   0 Batch   96/153 - Train Accuracy:  0.487, Validation Accuracy:  0.506, Loss:  2.039
Epoch   0 Batch   97/153 - Train Accuracy:  0.491, Validation Accuracy:  0.504, Loss:  2.032
Epoch   0 Batch   98/153 - Train Accuracy:  0.453, Validation Accuracy:  0.482, Loss:  2.027
Epoch   0 Batch   99/153 - Train Accuracy:  0.470, Validation Accuracy:  0.490, Loss:  2.039
Epoch   0 Batch  100/153 - Train Accuracy:  0.481, Validation Accuracy:  0.500, Loss:  2.017
Epoch   0 Batch  101/153 - Train Accuracy:  0.499, Validation Accuracy:  0.497, Loss:  1.936
Epoch   0 Batch  102/153 - Train Accuracy:  0.463, Validation Accuracy:  0.486, Loss:  1.937
Epoch   0 Batch  103/153 - Train Accuracy:  0.475, Validation Accuracy:  0.494, Loss:  1.969
Epoch   0 Batch  104/153 - Train Accuracy:  0.557, Validation Accuracy:  0.506, Loss:  1.821
Epoch   0 Batch  105/153 - Train Accuracy:  0.483, Validation Accuracy:  0.507, Loss:  1.938
Epoch   0 Batch  106/153 - Train Accuracy:  0.507, Validation Accuracy:  0.519, Loss:  1.916
Epoch   0 Batch  107/153 - Train Accuracy:  0.508, Validation Accuracy:  0.511, Loss:  1.924
Epoch   0 Batch  108/153 - Train Accuracy:  0.494, Validation Accuracy:  0.515, Loss:  1.905
Epoch   0 Batch  109/153 - Train Accuracy:  0.497, Validation Accuracy:  0.520, Loss:  1.919
Epoch   0 Batch  110/153 - Train Accuracy:  0.492, Validation Accuracy:  0.509, Loss:  1.890
Epoch   0 Batch  111/153 - Train Accuracy:  0.515, Validation Accuracy:  0.524, Loss:  1.863
Epoch   0 Batch  112/153 - Train Accuracy:  0.482, Validation Accuracy:  0.526, Loss:  1.929
Epoch   0 Batch  113/153 - Train Accuracy:  0.490, Validation Accuracy:  0.504, Loss:  1.848
Epoch   0 Batch  114/153 - Train Accuracy:  0.515, Validation Accuracy:  0.526, Loss:  1.833
Epoch   0 Batch  115/153 - Train Accuracy:  0.508, Validation Accuracy:  0.528, Loss:  1.856
Epoch   0 Batch  116/153 - Train Accuracy:  0.517, Validation Accuracy:  0.542, Loss:  1.826
Epoch   0 Batch  117/153 - Train Accuracy:  0.501, Validation Accuracy:  0.525, Loss:  1.831
Epoch   0 Batch  118/153 - Train Accuracy:  0.530, Validation Accuracy:  0.530, Loss:  1.741
Epoch   0 Batch  119/153 - Train Accuracy:  0.538, Validation Accuracy:  0.541, Loss:  1.799
Epoch   0 Batch  120/153 - Train Accuracy:  0.540, Validation Accuracy:  0.546, Loss:  1.804
Epoch   0 Batch  121/153 - Train Accuracy:  0.549, Validation Accuracy:  0.545, Loss:  1.770
Epoch   0 Batch  122/153 - Train Accuracy:  0.541, Validation Accuracy:  0.534, Loss:  1.724
Epoch   0 Batch  123/153 - Train Accuracy:  0.516, Validation Accuracy:  0.550, Loss:  1.807
Epoch   0 Batch  124/153 - Train Accuracy:  0.533, Validation Accuracy:  0.550, Loss:  1.802
Epoch   0 Batch  125/153 - Train Accuracy:  0.555, Validation Accuracy:  0.549, Loss:  1.721
Epoch   0 Batch  126/153 - Train Accuracy:  0.547, Validation Accuracy:  0.550, Loss:  1.722
Epoch   0 Batch  127/153 - Train Accuracy:  0.551, Validation Accuracy:  0.558, Loss:  1.720
Epoch   0 Batch  128/153 - Train Accuracy:  0.556, Validation Accuracy:  0.560, Loss:  1.725
Epoch   0 Batch  129/153 - Train Accuracy:  0.602, Validation Accuracy:  0.560, Loss:  1.602
Epoch   0 Batch  130/153 - Train Accuracy:  0.540, Validation Accuracy:  0.549, Loss:  1.727
Epoch   0 Batch  131/153 - Train Accuracy:  0.536, Validation Accuracy:  0.557, Loss:  1.705
Epoch   0 Batch  132/153 - Train Accuracy:  0.530, Validation Accuracy:  0.547, Loss:  1.702
Epoch   0 Batch  133/153 - Train Accuracy:  0.554, Validation Accuracy:  0.558, Loss:  1.700
Epoch   0 Batch  134/153 - Train Accuracy:  0.545, Validation Accuracy:  0.555, Loss:  1.686
Epoch   0 Batch  135/153 - Train Accuracy:  0.542, Validation Accuracy:  0.553, Loss:  1.678
Epoch   0 Batch  136/153 - Train Accuracy:  0.538, Validation Accuracy:  0.538, Loss:  1.701
Epoch   0 Batch  137/153 - Train Accuracy:  0.577, Validation Accuracy:  0.545, Loss:  1.636
Epoch   0 Batch  138/153 - Train Accuracy:  0.535, Validation Accuracy:  0.534, Loss:  1.702
Epoch   0 Batch  139/153 - Train Accuracy:  0.557, Validation Accuracy:  0.558, Loss:  1.682
Epoch   0 Batch  140/153 - Train Accuracy:  0.546, Validation Accuracy:  0.564, Loss:  1.670
Epoch   0 Batch  141/153 - Train Accuracy:  0.537, Validation Accuracy:  0.542, Loss:  1.666
Epoch   0 Batch  142/153 - Train Accuracy:  0.574, Validation Accuracy:  0.563, Loss:  1.611
Epoch   0 Batch  143/153 - Train Accuracy:  0.549, Validation Accuracy:  0.556, Loss:  1.641
Epoch   0 Batch  144/153 - Train Accuracy:  0.527, Validation Accuracy:  0.544, Loss:  1.666
Epoch   0 Batch  145/153 - Train Accuracy:  0.572, Validation Accuracy:  0.556, Loss:  1.610
Epoch   0 Batch  146/153 - Train Accuracy:  0.535, Validation Accuracy:  0.561, Loss:  1.653
Epoch   0 Batch  147/153 - Train Accuracy:  0.554, Validation Accuracy:  0.562, Loss:  1.638
Epoch   0 Batch  148/153 - Train Accuracy:  0.525, Validation Accuracy:  0.553, Loss:  1.690
Epoch   0 Batch  149/153 - Train Accuracy:  0.551, Validation Accuracy:  0.555, Loss:  1.642
Epoch   0 Batch  150/153 - Train Accuracy:  0.544, Validation Accuracy:  0.578, Loss:  1.667
Epoch   0 Batch  151/153 - Train Accuracy:  0.564, Validation Accuracy:  0.565, Loss:  1.611
Epoch   1 Batch    0/153 - Train Accuracy:  0.550, Validation Accuracy:  0.557, Loss:  1.627
Epoch   1 Batch    1/153 - Train Accuracy:  0.568, Validation Accuracy:  0.563, Loss:  1.610
Epoch   1 Batch    2/153 - Train Accuracy:  0.519, Validation Accuracy:  0.564, Loss:  1.654
Epoch   1 Batch    3/153 - Train Accuracy:  0.563, Validation Accuracy:  0.576, Loss:  1.599
Epoch   1 Batch    4/153 - Train Accuracy:  0.550, Validation Accuracy:  0.577, Loss:  1.665
Epoch   1 Batch    5/153 - Train Accuracy:  0.565, Validation Accuracy:  0.573, Loss:  1.597
Epoch   1 Batch    6/153 - Train Accuracy:  0.555, Validation Accuracy:  0.569, Loss:  1.595
Epoch   1 Batch    7/153 - Train Accuracy:  0.570, Validation Accuracy:  0.567, Loss:  1.577
Epoch   1 Batch    8/153 - Train Accuracy:  0.570, Validation Accuracy:  0.575, Loss:  1.590
Epoch   1 Batch    9/153 - Train Accuracy:  0.568, Validation Accuracy:  0.579, Loss:  1.600
Epoch   1 Batch   10/153 - Train Accuracy:  0.587, Validation Accuracy:  0.567, Loss:  1.540
Epoch   1 Batch   11/153 - Train Accuracy:  0.553, Validation Accuracy:  0.570, Loss:  1.645
Epoch   1 Batch   12/153 - Train Accuracy:  0.574, Validation Accuracy:  0.588, Loss:  1.587
Epoch   1 Batch   13/153 - Train Accuracy:  0.581, Validation Accuracy:  0.590, Loss:  1.590
Epoch   1 Batch   14/153 - Train Accuracy:  0.589, Validation Accuracy:  0.582, Loss:  1.542
Epoch   1 Batch   15/153 - Train Accuracy:  0.554, Validation Accuracy:  0.582, Loss:  1.592
Epoch   1 Batch   16/153 - Train Accuracy:  0.561, Validation Accuracy:  0.588, Loss:  1.589
Epoch   1 Batch   17/153 - Train Accuracy:  0.577, Validation Accuracy:  0.588, Loss:  1.550
Epoch   1 Batch   18/153 - Train Accuracy:  0.573, Validation Accuracy:  0.578, Loss:  1.529
Epoch   1 Batch   19/153 - Train Accuracy:  0.570, Validation Accuracy:  0.580, Loss:  1.556
Epoch   1 Batch   20/153 - Train Accuracy:  0.578, Validation Accuracy:  0.585, Loss:  1.549
Epoch   1 Batch   21/153 - Train Accuracy:  0.579, Validation Accuracy:  0.589, Loss:  1.543
Epoch   1 Batch   22/153 - Train Accuracy:  0.565, Validation Accuracy:  0.596, Loss:  1.581
Epoch   1 Batch   23/153 - Train Accuracy:  0.591, Validation Accuracy:  0.593, Loss:  1.520
Epoch   1 Batch   24/153 - Train Accuracy:  0.573, Validation Accuracy:  0.593, Loss:  1.582
Epoch   1 Batch   25/153 - Train Accuracy:  0.585, Validation Accuracy:  0.593, Loss:  1.555
Epoch   1 Batch   26/153 - Train Accuracy:  0.607, Validation Accuracy:  0.592, Loss:  1.488
Epoch   1 Batch   27/153 - Train Accuracy:  0.568, Validation Accuracy:  0.586, Loss:  1.523
Epoch   1 Batch   28/153 - Train Accuracy:  0.568, Validation Accuracy:  0.590, Loss:  1.533
Epoch   1 Batch   29/153 - Train Accuracy:  0.581, Validation Accuracy:  0.589, Loss:  1.542
Epoch   1 Batch   30/153 - Train Accuracy:  0.575, Validation Accuracy:  0.591, Loss:  1.562
Epoch   1 Batch   31/153 - Train Accuracy:  0.589, Validation Accuracy:  0.594, Loss:  1.550
Epoch   1 Batch   32/153 - Train Accuracy:  0.587, Validation Accuracy:  0.592, Loss:  1.560
Epoch   1 Batch   33/153 - Train Accuracy:  0.586, Validation Accuracy:  0.599, Loss:  1.514
Epoch   1 Batch   34/153 - Train Accuracy:  0.608, Validation Accuracy:  0.602, Loss:  1.480
Epoch   1 Batch   35/153 - Train Accuracy:  0.594, Validation Accuracy:  0.591, Loss:  1.515
Epoch   1 Batch   36/153 - Train Accuracy:  0.576, Validation Accuracy:  0.587, Loss:  1.508
Epoch   1 Batch   37/153 - Train Accuracy:  0.568, Validation Accuracy:  0.554, Loss:  1.476
Epoch   1 Batch   38/153 - Train Accuracy:  0.564, Validation Accuracy:  0.570, Loss:  1.552
Epoch   1 Batch   39/153 - Train Accuracy:  0.570, Validation Accuracy:  0.573, Loss:  1.550
Epoch   1 Batch   40/153 - Train Accuracy:  0.595, Validation Accuracy:  0.591, Loss:  1.520
Epoch   1 Batch   41/153 - Train Accuracy:  0.577, Validation Accuracy:  0.572, Loss:  1.506
Epoch   1 Batch   42/153 - Train Accuracy:  0.565, Validation Accuracy:  0.576, Loss:  1.539
Epoch   1 Batch   43/153 - Train Accuracy:  0.578, Validation Accuracy:  0.583, Loss:  1.509
Epoch   1 Batch   44/153 - Train Accuracy:  0.594, Validation Accuracy:  0.585, Loss:  1.531
Epoch   1 Batch   45/153 - Train Accuracy:  0.585, Validation Accuracy:  0.584, Loss:  1.515
Epoch   1 Batch   46/153 - Train Accuracy:  0.574, Validation Accuracy:  0.575, Loss:  1.520
Epoch   1 Batch   47/153 - Train Accuracy:  0.569, Validation Accuracy:  0.571, Loss:  1.513
Epoch   1 Batch   48/153 - Train Accuracy:  0.577, Validation Accuracy:  0.612, Loss:  1.517
Epoch   1 Batch   49/153 - Train Accuracy:  0.561, Validation Accuracy:  0.591, Loss:  1.498
Epoch   1 Batch   50/153 - Train Accuracy:  0.590, Validation Accuracy:  0.596, Loss:  1.501
Epoch   1 Batch   51/153 - Train Accuracy:  0.589, Validation Accuracy:  0.602, Loss:  1.524
Epoch   1 Batch   52/153 - Train Accuracy:  0.606, Validation Accuracy:  0.603, Loss:  1.469
Epoch   1 Batch   53/153 - Train Accuracy:  0.591, Validation Accuracy:  0.608, Loss:  1.513
Epoch   1 Batch   54/153 - Train Accuracy:  0.589, Validation Accuracy:  0.597, Loss:  1.488
Epoch   1 Batch   55/153 - Train Accuracy:  0.582, Validation Accuracy:  0.592, Loss:  1.474
Epoch   1 Batch   56/153 - Train Accuracy:  0.598, Validation Accuracy:  0.602, Loss:  1.506
Epoch   1 Batch   57/153 - Train Accuracy:  0.599, Validation Accuracy:  0.609, Loss:  1.518
Epoch   1 Batch   58/153 - Train Accuracy:  0.598, Validation Accuracy:  0.609, Loss:  1.509
Epoch   1 Batch   59/153 - Train Accuracy:  0.582, Validation Accuracy:  0.602, Loss:  1.491
Epoch   1 Batch   60/153 - Train Accuracy:  0.592, Validation Accuracy:  0.605, Loss:  1.486
Epoch   1 Batch   61/153 - Train Accuracy:  0.593, Validation Accuracy:  0.609, Loss:  1.467
Epoch   1 Batch   62/153 - Train Accuracy:  0.582, Validation Accuracy:  0.607, Loss:  1.480
Epoch   1 Batch   63/153 - Train Accuracy:  0.592, Validation Accuracy:  0.608, Loss:  1.495
Epoch   1 Batch   64/153 - Train Accuracy:  0.610, Validation Accuracy:  0.615, Loss:  1.460
Epoch   1 Batch   65/153 - Train Accuracy:  0.614, Validation Accuracy:  0.617, Loss:  1.488
Epoch   1 Batch   66/153 - Train Accuracy:  0.589, Validation Accuracy:  0.617, Loss:  1.493
Epoch   1 Batch   67/153 - Train Accuracy:  0.621, Validation Accuracy:  0.619, Loss:  1.467
Epoch   1 Batch   68/153 - Train Accuracy:  0.591, Validation Accuracy:  0.619, Loss:  1.515
Epoch   1 Batch   69/153 - Train Accuracy:  0.596, Validation Accuracy:  0.612, Loss:  1.481
Epoch   1 Batch   70/153 - Train Accuracy:  0.600, Validation Accuracy:  0.614, Loss:  1.485
Epoch   1 Batch   71/153 - Train Accuracy:  0.608, Validation Accuracy:  0.615, Loss:  1.485
Epoch   1 Batch   72/153 - Train Accuracy:  0.610, Validation Accuracy:  0.613, Loss:  1.461
Epoch   1 Batch   73/153 - Train Accuracy:  0.603, Validation Accuracy:  0.608, Loss:  1.475
Epoch   1 Batch   74/153 - Train Accuracy:  0.587, Validation Accuracy:  0.615, Loss:  1.491
Epoch   1 Batch   75/153 - Train Accuracy:  0.599, Validation Accuracy:  0.614, Loss:  1.460
Epoch   1 Batch   76/153 - Train Accuracy:  0.595, Validation Accuracy:  0.607, Loss:  1.474
Epoch   1 Batch   77/153 - Train Accuracy:  0.568, Validation Accuracy:  0.599, Loss:  1.516
Epoch   1 Batch   78/153 - Train Accuracy:  0.598, Validation Accuracy:  0.614, Loss:  1.480
Epoch   1 Batch   79/153 - Train Accuracy:  0.619, Validation Accuracy:  0.622, Loss:  1.458
Epoch   1 Batch   80/153 - Train Accuracy:  0.618, Validation Accuracy:  0.620, Loss:  1.457
Epoch   1 Batch   81/153 - Train Accuracy:  0.610, Validation Accuracy:  0.617, Loss:  1.454
Epoch   1 Batch   82/153 - Train Accuracy:  0.610, Validation Accuracy:  0.615, Loss:  1.467
Epoch   1 Batch   83/153 - Train Accuracy:  0.620, Validation Accuracy:  0.600, Loss:  1.436
Epoch   1 Batch   84/153 - Train Accuracy:  0.602, Validation Accuracy:  0.598, Loss:  1.459
Epoch   1 Batch   85/153 - Train Accuracy:  0.631, Validation Accuracy:  0.608, Loss:  1.433
Epoch   1 Batch   86/153 - Train Accuracy:  0.609, Validation Accuracy:  0.621, Loss:  1.460
Epoch   1 Batch   87/153 - Train Accuracy:  0.617, Validation Accuracy:  0.622, Loss:  1.442
Epoch   1 Batch   88/153 - Train Accuracy:  0.634, Validation Accuracy:  0.620, Loss:  1.429
Epoch   1 Batch   89/153 - Train Accuracy:  0.603, Validation Accuracy:  0.622, Loss:  1.460
Epoch   1 Batch   90/153 - Train Accuracy:  0.609, Validation Accuracy:  0.624, Loss:  1.478
Epoch   1 Batch   91/153 - Train Accuracy:  0.606, Validation Accuracy:  0.619, Loss:  1.456
Epoch   1 Batch   92/153 - Train Accuracy:  0.607, Validation Accuracy:  0.620, Loss:  1.465
Epoch   1 Batch   93/153 - Train Accuracy:  0.621, Validation Accuracy:  0.622, Loss:  1.430
Epoch   1 Batch   94/153 - Train Accuracy:  0.629, Validation Accuracy:  0.619, Loss:  1.425
Epoch   1 Batch   95/153 - Train Accuracy:  0.600, Validation Accuracy:  0.607, Loss:  1.436
Epoch   1 Batch   96/153 - Train Accuracy:  0.605, Validation Accuracy:  0.618, Loss:  1.447
Epoch   1 Batch   97/153 - Train Accuracy:  0.618, Validation Accuracy:  0.629, Loss:  1.448
Epoch   1 Batch   98/153 - Train Accuracy:  0.607, Validation Accuracy:  0.617, Loss:  1.433
Epoch   1 Batch   99/153 - Train Accuracy:  0.607, Validation Accuracy:  0.616, Loss:  1.456
Epoch   1 Batch  100/153 - Train Accuracy:  0.613, Validation Accuracy:  0.619, Loss:  1.439
Epoch   1 Batch  101/153 - Train Accuracy:  0.627, Validation Accuracy:  0.625, Loss:  1.389
Epoch   1 Batch  102/153 - Train Accuracy:  0.608, Validation Accuracy:  0.619, Loss:  1.470
Epoch   1 Batch  103/153 - Train Accuracy:  0.603, Validation Accuracy:  0.619, Loss:  1.463
Epoch   1 Batch  104/153 - Train Accuracy:  0.669, Validation Accuracy:  0.628, Loss:  1.381
Epoch   1 Batch  105/153 - Train Accuracy:  0.605, Validation Accuracy:  0.618, Loss:  1.432
Epoch   1 Batch  106/153 - Train Accuracy:  0.601, Validation Accuracy:  0.619, Loss:  1.491
Epoch   1 Batch  107/153 - Train Accuracy:  0.609, Validation Accuracy:  0.612, Loss:  1.456
Epoch   1 Batch  108/153 - Train Accuracy:  0.616, Validation Accuracy:  0.624, Loss:  1.458
Epoch   1 Batch  109/153 - Train Accuracy:  0.608, Validation Accuracy:  0.607, Loss:  1.475
Epoch   1 Batch  110/153 - Train Accuracy:  0.591, Validation Accuracy:  0.604, Loss:  1.464
Epoch   1 Batch  111/153 - Train Accuracy:  0.593, Validation Accuracy:  0.608, Loss:  1.446
Epoch   1 Batch  112/153 - Train Accuracy:  0.573, Validation Accuracy:  0.611, Loss:  1.494
Epoch   1 Batch  113/153 - Train Accuracy:  0.596, Validation Accuracy:  0.619, Loss:  1.457
Epoch   1 Batch  114/153 - Train Accuracy:  0.615, Validation Accuracy:  0.624, Loss:  1.432
Epoch   1 Batch  115/153 - Train Accuracy:  0.604, Validation Accuracy:  0.614, Loss:  1.429
Epoch   1 Batch  116/153 - Train Accuracy:  0.587, Validation Accuracy:  0.615, Loss:  1.477
Epoch   1 Batch  117/153 - Train Accuracy:  0.604, Validation Accuracy:  0.613, Loss:  1.442
Epoch   1 Batch  118/153 - Train Accuracy:  0.623, Validation Accuracy:  0.614, Loss:  1.446
Epoch   1 Batch  119/153 - Train Accuracy:  0.614, Validation Accuracy:  0.621, Loss:  1.421
Epoch   1 Batch  120/153 - Train Accuracy:  0.618, Validation Accuracy:  0.625, Loss:  1.438
Epoch   1 Batch  121/153 - Train Accuracy:  0.635, Validation Accuracy:  0.626, Loss:  1.462
Epoch   1 Batch  122/153 - Train Accuracy:  0.645, Validation Accuracy:  0.625, Loss:  1.387
Epoch   1 Batch  123/153 - Train Accuracy:  0.584, Validation Accuracy:  0.620, Loss:  1.467
Epoch   1 Batch  124/153 - Train Accuracy:  0.595, Validation Accuracy:  0.619, Loss:  1.457
Epoch   1 Batch  125/153 - Train Accuracy:  0.627, Validation Accuracy:  0.620, Loss:  1.421
Epoch   1 Batch  126/153 - Train Accuracy:  0.631, Validation Accuracy:  0.618, Loss:  1.424
Epoch   1 Batch  127/153 - Train Accuracy:  0.614, Validation Accuracy:  0.610, Loss:  1.413
Epoch   1 Batch  128/153 - Train Accuracy:  0.617, Validation Accuracy:  0.618, Loss:  1.420
Epoch   1 Batch  129/153 - Train Accuracy:  0.668, Validation Accuracy:  0.627, Loss:  1.338
Epoch   1 Batch  130/153 - Train Accuracy:  0.615, Validation Accuracy:  0.624, Loss:  1.431
Epoch   1 Batch  131/153 - Train Accuracy:  0.606, Validation Accuracy:  0.619, Loss:  1.421
Epoch   1 Batch  132/153 - Train Accuracy:  0.597, Validation Accuracy:  0.611, Loss:  1.425
Epoch   1 Batch  133/153 - Train Accuracy:  0.616, Validation Accuracy:  0.617, Loss:  1.425
Epoch   1 Batch  134/153 - Train Accuracy:  0.618, Validation Accuracy:  0.630, Loss:  1.416
Epoch   1 Batch  135/153 - Train Accuracy:  0.629, Validation Accuracy:  0.635, Loss:  1.417
Epoch   1 Batch  136/153 - Train Accuracy:  0.631, Validation Accuracy:  0.635, Loss:  1.399
Epoch   1 Batch  137/153 - Train Accuracy:  0.649, Validation Accuracy:  0.635, Loss:  1.385
Epoch   1 Batch  138/153 - Train Accuracy:  0.627, Validation Accuracy:  0.636, Loss:  1.415
Epoch   1 Batch  139/153 - Train Accuracy:  0.619, Validation Accuracy:  0.627, Loss:  1.421
Epoch   1 Batch  140/153 - Train Accuracy:  0.619, Validation Accuracy:  0.635, Loss:  1.409
Epoch   1 Batch  141/153 - Train Accuracy:  0.634, Validation Accuracy:  0.637, Loss:  1.383
Epoch   1 Batch  142/153 - Train Accuracy:  0.637, Validation Accuracy:  0.625, Loss:  1.370
Epoch   1 Batch  143/153 - Train Accuracy:  0.639, Validation Accuracy:  0.630, Loss:  1.388
Epoch   1 Batch  144/153 - Train Accuracy:  0.609, Validation Accuracy:  0.619, Loss:  1.412
Epoch   1 Batch  145/153 - Train Accuracy:  0.629, Validation Accuracy:  0.627, Loss:  1.376
Epoch   1 Batch  146/153 - Train Accuracy:  0.606, Validation Accuracy:  0.631, Loss:  1.402
Epoch   1 Batch  147/153 - Train Accuracy:  0.622, Validation Accuracy:  0.628, Loss:  1.391
Epoch   1 Batch  148/153 - Train Accuracy:  0.611, Validation Accuracy:  0.634, Loss:  1.449
Epoch   1 Batch  149/153 - Train Accuracy:  0.616, Validation Accuracy:  0.629, Loss:  1.417
Epoch   1 Batch  150/153 - Train Accuracy:  0.595, Validation Accuracy:  0.620, Loss:  1.455
Epoch   1 Batch  151/153 - Train Accuracy:  0.589, Validation Accuracy:  0.611, Loss:  1.424
Epoch   2 Batch    0/153 - Train Accuracy:  0.593, Validation Accuracy:  0.611, Loss:  1.460
Epoch   2 Batch    1/153 - Train Accuracy:  0.588, Validation Accuracy:  0.595, Loss:  1.399
Epoch   2 Batch    2/153 - Train Accuracy:  0.577, Validation Accuracy:  0.617, Loss:  1.493
Epoch   2 Batch    3/153 - Train Accuracy:  0.596, Validation Accuracy:  0.597, Loss:  1.420
Epoch   2 Batch    4/153 - Train Accuracy:  0.589, Validation Accuracy:  0.622, Loss:  1.472
Epoch   2 Batch    5/153 - Train Accuracy:  0.601, Validation Accuracy:  0.609, Loss:  1.430
Epoch   2 Batch    6/153 - Train Accuracy:  0.589, Validation Accuracy:  0.606, Loss:  1.441
Epoch   2 Batch    7/153 - Train Accuracy:  0.622, Validation Accuracy:  0.609, Loss:  1.410
Epoch   2 Batch    8/153 - Train Accuracy:  0.603, Validation Accuracy:  0.608, Loss:  1.399
Epoch   2 Batch    9/153 - Train Accuracy:  0.616, Validation Accuracy:  0.617, Loss:  1.419
Epoch   2 Batch   10/153 - Train Accuracy:  0.639, Validation Accuracy:  0.625, Loss:  1.382
Epoch   2 Batch   11/153 - Train Accuracy:  0.599, Validation Accuracy:  0.617, Loss:  1.409
Epoch   2 Batch   12/153 - Train Accuracy:  0.603, Validation Accuracy:  0.615, Loss:  1.381
Epoch   2 Batch   13/153 - Train Accuracy:  0.622, Validation Accuracy:  0.619, Loss:  1.404
Epoch   2 Batch   14/153 - Train Accuracy:  0.643, Validation Accuracy:  0.635, Loss:  1.347
Epoch   2 Batch   15/153 - Train Accuracy:  0.607, Validation Accuracy:  0.636, Loss:  1.414
Epoch   2 Batch   16/153 - Train Accuracy:  0.604, Validation Accuracy:  0.635, Loss:  1.439
Epoch   2 Batch   17/153 - Train Accuracy:  0.621, Validation Accuracy:  0.628, Loss:  1.379
Epoch   2 Batch   18/153 - Train Accuracy:  0.623, Validation Accuracy:  0.629, Loss:  1.382
Epoch   2 Batch   19/153 - Train Accuracy:  0.611, Validation Accuracy:  0.623, Loss:  1.405
Epoch   2 Batch   20/153 - Train Accuracy:  0.618, Validation Accuracy:  0.624, Loss:  1.409
Epoch   2 Batch   21/153 - Train Accuracy:  0.614, Validation Accuracy:  0.627, Loss:  1.405
Epoch   2 Batch   22/153 - Train Accuracy:  0.607, Validation Accuracy:  0.637, Loss:  1.429
Epoch   2 Batch   23/153 - Train Accuracy:  0.640, Validation Accuracy:  0.635, Loss:  1.369
Epoch   2 Batch   24/153 - Train Accuracy:  0.627, Validation Accuracy:  0.637, Loss:  1.393
Epoch   2 Batch   25/153 - Train Accuracy:  0.630, Validation Accuracy:  0.635, Loss:  1.387
Epoch   2 Batch   26/153 - Train Accuracy:  0.655, Validation Accuracy:  0.636, Loss:  1.360
Epoch   2 Batch   27/153 - Train Accuracy:  0.625, Validation Accuracy:  0.640, Loss:  1.382
Epoch   2 Batch   28/153 - Train Accuracy:  0.626, Validation Accuracy:  0.639, Loss:  1.354
Epoch   2 Batch   29/153 - Train Accuracy:  0.630, Validation Accuracy:  0.642, Loss:  1.372
Epoch   2 Batch   30/153 - Train Accuracy:  0.630, Validation Accuracy:  0.645, Loss:  1.397
Epoch   2 Batch   31/153 - Train Accuracy:  0.648, Validation Accuracy:  0.648, Loss:  1.373
Epoch   2 Batch   32/153 - Train Accuracy:  0.642, Validation Accuracy:  0.648, Loss:  1.366
Epoch   2 Batch   33/153 - Train Accuracy:  0.638, Validation Accuracy:  0.649, Loss:  1.373
Epoch   2 Batch   34/153 - Train Accuracy:  0.656, Validation Accuracy:  0.652, Loss:  1.344
Epoch   2 Batch   35/153 - Train Accuracy:  0.650, Validation Accuracy:  0.649, Loss:  1.355
Epoch   2 Batch   36/153 - Train Accuracy:  0.625, Validation Accuracy:  0.644, Loss:  1.370
Epoch   2 Batch   37/153 - Train Accuracy:  0.637, Validation Accuracy:  0.643, Loss:  1.355
Epoch   2 Batch   38/153 - Train Accuracy:  0.617, Validation Accuracy:  0.635, Loss:  1.387
Epoch   2 Batch   39/153 - Train Accuracy:  0.618, Validation Accuracy:  0.633, Loss:  1.383
Epoch   2 Batch   40/153 - Train Accuracy:  0.638, Validation Accuracy:  0.638, Loss:  1.379
Epoch   2 Batch   41/153 - Train Accuracy:  0.652, Validation Accuracy:  0.648, Loss:  1.356
Epoch   2 Batch   42/153 - Train Accuracy:  0.645, Validation Accuracy:  0.650, Loss:  1.353
Epoch   2 Batch   43/153 - Train Accuracy:  0.642, Validation Accuracy:  0.648, Loss:  1.374
Epoch   2 Batch   44/153 - Train Accuracy:  0.645, Validation Accuracy:  0.646, Loss:  1.359
Epoch   2 Batch   45/153 - Train Accuracy:  0.646, Validation Accuracy:  0.647, Loss:  1.336
Epoch   2 Batch   46/153 - Train Accuracy:  0.655, Validation Accuracy:  0.649, Loss:  1.357
Epoch   2 Batch   47/153 - Train Accuracy:  0.644, Validation Accuracy:  0.640, Loss:  1.366
Epoch   2 Batch   48/153 - Train Accuracy:  0.621, Validation Accuracy:  0.625, Loss:  1.359
Epoch   2 Batch   49/153 - Train Accuracy:  0.627, Validation Accuracy:  0.634, Loss:  1.356
Epoch   2 Batch   50/153 - Train Accuracy:  0.643, Validation Accuracy:  0.642, Loss:  1.340
Epoch   2 Batch   51/153 - Train Accuracy:  0.636, Validation Accuracy:  0.647, Loss:  1.366
Epoch   2 Batch   52/153 - Train Accuracy:  0.656, Validation Accuracy:  0.654, Loss:  1.323
Epoch   2 Batch   53/153 - Train Accuracy:  0.641, Validation Accuracy:  0.650, Loss:  1.345
Epoch   2 Batch   54/153 - Train Accuracy:  0.625, Validation Accuracy:  0.645, Loss:  1.370
Epoch   2 Batch   55/153 - Train Accuracy:  0.635, Validation Accuracy:  0.636, Loss:  1.340
Epoch   2 Batch   56/153 - Train Accuracy:  0.650, Validation Accuracy:  0.652, Loss:  1.345
Epoch   2 Batch   57/153 - Train Accuracy:  0.645, Validation Accuracy:  0.654, Loss:  1.362
Epoch   2 Batch   58/153 - Train Accuracy:  0.643, Validation Accuracy:  0.654, Loss:  1.339
Epoch   2 Batch   59/153 - Train Accuracy:  0.618, Validation Accuracy:  0.639, Loss:  1.357
Epoch   2 Batch   60/153 - Train Accuracy:  0.622, Validation Accuracy:  0.628, Loss:  1.368
Epoch   2 Batch   61/153 - Train Accuracy:  0.617, Validation Accuracy:  0.623, Loss:  1.362
Epoch   2 Batch   62/153 - Train Accuracy:  0.600, Validation Accuracy:  0.619, Loss:  1.348
Epoch   2 Batch   63/153 - Train Accuracy:  0.638, Validation Accuracy:  0.634, Loss:  1.340
Epoch   2 Batch   64/153 - Train Accuracy:  0.650, Validation Accuracy:  0.650, Loss:  1.347
Epoch   2 Batch   65/153 - Train Accuracy:  0.649, Validation Accuracy:  0.649, Loss:  1.347
Epoch   2 Batch   66/153 - Train Accuracy:  0.633, Validation Accuracy:  0.655, Loss:  1.348
Epoch   2 Batch   67/153 - Train Accuracy:  0.657, Validation Accuracy:  0.648, Loss:  1.351
Epoch   2 Batch   68/153 - Train Accuracy:  0.634, Validation Accuracy:  0.658, Loss:  1.366
Epoch   2 Batch   69/153 - Train Accuracy:  0.644, Validation Accuracy:  0.658, Loss:  1.340
Epoch   2 Batch   70/153 - Train Accuracy:  0.638, Validation Accuracy:  0.638, Loss:  1.346
Epoch   2 Batch   71/153 - Train Accuracy:  0.643, Validation Accuracy:  0.642, Loss:  1.338
Epoch   2 Batch   72/153 - Train Accuracy:  0.655, Validation Accuracy:  0.643, Loss:  1.345
Epoch   2 Batch   73/153 - Train Accuracy:  0.640, Validation Accuracy:  0.651, Loss:  1.347
Epoch   2 Batch   74/153 - Train Accuracy:  0.634, Validation Accuracy:  0.659, Loss:  1.325
Epoch   2 Batch   75/153 - Train Accuracy:  0.643, Validation Accuracy:  0.656, Loss:  1.348
Epoch   2 Batch   76/153 - Train Accuracy:  0.650, Validation Accuracy:  0.657, Loss:  1.323
Epoch   2 Batch   77/153 - Train Accuracy:  0.622, Validation Accuracy:  0.652, Loss:  1.372
Epoch   2 Batch   78/153 - Train Accuracy:  0.645, Validation Accuracy:  0.650, Loss:  1.368
Epoch   2 Batch   79/153 - Train Accuracy:  0.661, Validation Accuracy:  0.653, Loss:  1.326
Epoch   2 Batch   80/153 - Train Accuracy:  0.661, Validation Accuracy:  0.653, Loss:  1.324
Epoch   2 Batch   81/153 - Train Accuracy:  0.652, Validation Accuracy:  0.656, Loss:  1.310
Epoch   2 Batch   82/153 - Train Accuracy:  0.655, Validation Accuracy:  0.649, Loss:  1.340
Epoch   2 Batch   83/153 - Train Accuracy:  0.660, Validation Accuracy:  0.639, Loss:  1.318
Epoch   2 Batch   84/153 - Train Accuracy:  0.638, Validation Accuracy:  0.635, Loss:  1.331
Epoch   2 Batch   85/153 - Train Accuracy:  0.674, Validation Accuracy:  0.651, Loss:  1.310
Epoch   2 Batch   86/153 - Train Accuracy:  0.649, Validation Accuracy:  0.657, Loss:  1.313
Epoch   2 Batch   87/153 - Train Accuracy:  0.656, Validation Accuracy:  0.663, Loss:  1.333
Epoch   2 Batch   88/153 - Train Accuracy:  0.681, Validation Accuracy:  0.662, Loss:  1.310
Epoch   2 Batch   89/153 - Train Accuracy:  0.642, Validation Accuracy:  0.656, Loss:  1.321
Epoch   2 Batch   90/153 - Train Accuracy:  0.651, Validation Accuracy:  0.661, Loss:  1.326
Epoch   2 Batch   91/153 - Train Accuracy:  0.645, Validation Accuracy:  0.651, Loss:  1.346
Epoch   2 Batch   92/153 - Train Accuracy:  0.632, Validation Accuracy:  0.644, Loss:  1.335
Epoch   2 Batch   93/153 - Train Accuracy:  0.639, Validation Accuracy:  0.640, Loss:  1.451
Epoch   2 Batch   94/153 - Train Accuracy:  0.663, Validation Accuracy:  0.640, Loss:  1.339
Epoch   2 Batch   95/153 - Train Accuracy:  0.634, Validation Accuracy:  0.643, Loss:  1.360
Epoch   2 Batch   96/153 - Train Accuracy:  0.629, Validation Accuracy:  0.645, Loss:  1.352
Epoch   2 Batch   97/153 - Train Accuracy:  0.643, Validation Accuracy:  0.644, Loss:  1.382
Epoch   2 Batch   98/153 - Train Accuracy:  0.634, Validation Accuracy:  0.643, Loss:  1.339
Epoch   2 Batch   99/153 - Train Accuracy:  0.625, Validation Accuracy:  0.633, Loss:  1.358
Epoch   2 Batch  100/153 - Train Accuracy:  0.619, Validation Accuracy:  0.626, Loss:  1.351
Epoch   2 Batch  101/153 - Train Accuracy:  0.631, Validation Accuracy:  0.626, Loss:  1.336
Epoch   2 Batch  102/153 - Train Accuracy:  0.644, Validation Accuracy:  0.649, Loss:  1.364
Epoch   2 Batch  103/153 - Train Accuracy:  0.644, Validation Accuracy:  0.656, Loss:  1.373
Epoch   2 Batch  104/153 - Train Accuracy:  0.692, Validation Accuracy:  0.650, Loss:  1.295
Epoch   2 Batch  105/153 - Train Accuracy:  0.647, Validation Accuracy:  0.660, Loss:  1.345
Epoch   2 Batch  106/153 - Train Accuracy:  0.643, Validation Accuracy:  0.650, Loss:  1.348
Epoch   2 Batch  107/153 - Train Accuracy:  0.662, Validation Accuracy:  0.657, Loss:  1.333
Epoch   2 Batch  108/153 - Train Accuracy:  0.651, Validation Accuracy:  0.656, Loss:  1.354
Epoch   2 Batch  109/153 - Train Accuracy:  0.660, Validation Accuracy:  0.655, Loss:  1.338
Epoch   2 Batch  110/153 - Train Accuracy:  0.646, Validation Accuracy:  0.650, Loss:  1.354
Epoch   2 Batch  111/153 - Train Accuracy:  0.643, Validation Accuracy:  0.656, Loss:  1.327
Epoch   2 Batch  112/153 - Train Accuracy:  0.630, Validation Accuracy:  0.660, Loss:  1.379
Epoch   2 Batch  113/153 - Train Accuracy:  0.655, Validation Accuracy:  0.663, Loss:  1.354
Epoch   2 Batch  114/153 - Train Accuracy:  0.662, Validation Accuracy:  0.661, Loss:  1.332
Epoch   2 Batch  115/153 - Train Accuracy:  0.658, Validation Accuracy:  0.663, Loss:  1.347
Epoch   2 Batch  116/153 - Train Accuracy:  0.655, Validation Accuracy:  0.656, Loss:  1.320
Epoch   2 Batch  117/153 - Train Accuracy:  0.655, Validation Accuracy:  0.652, Loss:  1.318
Epoch   2 Batch  118/153 - Train Accuracy:  0.672, Validation Accuracy:  0.657, Loss:  1.283
Epoch   2 Batch  119/153 - Train Accuracy:  0.665, Validation Accuracy:  0.661, Loss:  1.309
Epoch   2 Batch  120/153 - Train Accuracy:  0.662, Validation Accuracy:  0.666, Loss:  1.299
Epoch   2 Batch  121/153 - Train Accuracy:  0.676, Validation Accuracy:  0.665, Loss:  1.318
Epoch   2 Batch  122/153 - Train Accuracy:  0.684, Validation Accuracy:  0.663, Loss:  1.307
Epoch   2 Batch  123/153 - Train Accuracy:  0.629, Validation Accuracy:  0.660, Loss:  1.352
Epoch   2 Batch  124/153 - Train Accuracy:  0.650, Validation Accuracy:  0.662, Loss:  1.340
Epoch   2 Batch  125/153 - Train Accuracy:  0.670, Validation Accuracy:  0.664, Loss:  1.287
Epoch   2 Batch  126/153 - Train Accuracy:  0.686, Validation Accuracy:  0.663, Loss:  1.306
Epoch   2 Batch  127/153 - Train Accuracy:  0.660, Validation Accuracy:  0.668, Loss:  1.317
Epoch   2 Batch  128/153 - Train Accuracy:  0.679, Validation Accuracy:  0.669, Loss:  1.323
Epoch   2 Batch  129/153 - Train Accuracy:  0.714, Validation Accuracy:  0.670, Loss:  1.267
Epoch   2 Batch  130/153 - Train Accuracy:  0.672, Validation Accuracy:  0.670, Loss:  1.296
Epoch   2 Batch  131/153 - Train Accuracy:  0.661, Validation Accuracy:  0.670, Loss:  1.315
Epoch   2 Batch  132/153 - Train Accuracy:  0.660, Validation Accuracy:  0.672, Loss:  1.297
Epoch   2 Batch  133/153 - Train Accuracy:  0.688, Validation Accuracy:  0.679, Loss:  1.301
Epoch   2 Batch  134/153 - Train Accuracy:  0.667, Validation Accuracy:  0.677, Loss:  1.275
Epoch   2 Batch  135/153 - Train Accuracy:  0.671, Validation Accuracy:  0.681, Loss:  1.324
Epoch   2 Batch  136/153 - Train Accuracy:  0.681, Validation Accuracy:  0.681, Loss:  1.300
Epoch   2 Batch  137/153 - Train Accuracy:  0.697, Validation Accuracy:  0.675, Loss:  1.234
Epoch   2 Batch  138/153 - Train Accuracy:  0.665, Validation Accuracy:  0.669, Loss:  1.267
Epoch   2 Batch  139/153 - Train Accuracy:  0.669, Validation Accuracy:  0.678, Loss:  1.316
Epoch   2 Batch  140/153 - Train Accuracy:  0.672, Validation Accuracy:  0.683, Loss:  1.277
Epoch   2 Batch  141/153 - Train Accuracy:  0.680, Validation Accuracy:  0.685, Loss:  1.293
Epoch   2 Batch  142/153 - Train Accuracy:  0.702, Validation Accuracy:  0.686, Loss:  1.239
Epoch   2 Batch  143/153 - Train Accuracy:  0.695, Validation Accuracy:  0.682, Loss:  1.302
Epoch   2 Batch  144/153 - Train Accuracy:  0.669, Validation Accuracy:  0.683, Loss:  1.288
Epoch   2 Batch  145/153 - Train Accuracy:  0.688, Validation Accuracy:  0.681, Loss:  1.281
Epoch   2 Batch  146/153 - Train Accuracy:  0.656, Validation Accuracy:  0.681, Loss:  1.298
Epoch   2 Batch  147/153 - Train Accuracy:  0.678, Validation Accuracy:  0.678, Loss:  1.300
Epoch   2 Batch  148/153 - Train Accuracy:  0.667, Validation Accuracy:  0.680, Loss:  1.298
Epoch   2 Batch  149/153 - Train Accuracy:  0.671, Validation Accuracy:  0.684, Loss:  1.293
Epoch   2 Batch  150/153 - Train Accuracy:  0.673, Validation Accuracy:  0.686, Loss:  1.286
Epoch   2 Batch  151/153 - Train Accuracy:  0.692, Validation Accuracy:  0.689, Loss:  1.289
Epoch   3 Batch    0/153 - Train Accuracy:  0.677, Validation Accuracy:  0.688, Loss:  1.298
Epoch   3 Batch    1/153 - Train Accuracy:  0.702, Validation Accuracy:  0.688, Loss:  1.286
Epoch   3 Batch    2/153 - Train Accuracy:  0.651, Validation Accuracy:  0.689, Loss:  1.293
Epoch   3 Batch    3/153 - Train Accuracy:  0.690, Validation Accuracy:  0.682, Loss:  1.261
Epoch   3 Batch    4/153 - Train Accuracy:  0.664, Validation Accuracy:  0.689, Loss:  1.288
Epoch   3 Batch    5/153 - Train Accuracy:  0.690, Validation Accuracy:  0.695, Loss:  1.263
Epoch   3 Batch    6/153 - Train Accuracy:  0.681, Validation Accuracy:  0.700, Loss:  1.271
Epoch   3 Batch    7/153 - Train Accuracy:  0.705, Validation Accuracy:  0.696, Loss:  1.253
Epoch   3 Batch    8/153 - Train Accuracy:  0.677, Validation Accuracy:  0.696, Loss:  1.251
Epoch   3 Batch    9/153 - Train Accuracy:  0.702, Validation Accuracy:  0.694, Loss:  1.265
Epoch   3 Batch   10/153 - Train Accuracy:  0.719, Validation Accuracy:  0.689, Loss:  1.234
Epoch   3 Batch   11/153 - Train Accuracy:  0.665, Validation Accuracy:  0.678, Loss:  1.286
Epoch   3 Batch   12/153 - Train Accuracy:  0.668, Validation Accuracy:  0.677, Loss:  1.280
Epoch   3 Batch   13/153 - Train Accuracy:  0.680, Validation Accuracy:  0.672, Loss:  1.287
Epoch   3 Batch   14/153 - Train Accuracy:  0.700, Validation Accuracy:  0.687, Loss:  1.305
Epoch   3 Batch   15/153 - Train Accuracy:  0.652, Validation Accuracy:  0.682, Loss:  1.302
Epoch   3 Batch   16/153 - Train Accuracy:  0.659, Validation Accuracy:  0.681, Loss:  1.343
Epoch   3 Batch   17/153 - Train Accuracy:  0.674, Validation Accuracy:  0.683, Loss:  1.296
Epoch   3 Batch   18/153 - Train Accuracy:  0.678, Validation Accuracy:  0.674, Loss:  1.283
Epoch   3 Batch   19/153 - Train Accuracy:  0.663, Validation Accuracy:  0.678, Loss:  1.268
Epoch   3 Batch   20/153 - Train Accuracy:  0.693, Validation Accuracy:  0.693, Loss:  1.296
Epoch   3 Batch   21/153 - Train Accuracy:  0.678, Validation Accuracy:  0.690, Loss:  1.244
Epoch   3 Batch   22/153 - Train Accuracy:  0.664, Validation Accuracy:  0.693, Loss:  1.318
Epoch   3 Batch   23/153 - Train Accuracy:  0.691, Validation Accuracy:  0.691, Loss:  1.272
Epoch   3 Batch   24/153 - Train Accuracy:  0.688, Validation Accuracy:  0.687, Loss:  1.294
Epoch   3 Batch   25/153 - Train Accuracy:  0.696, Validation Accuracy:  0.694, Loss:  1.274
Epoch   3 Batch   26/153 - Train Accuracy:  0.716, Validation Accuracy:  0.705, Loss:  1.245
Epoch   3 Batch   27/153 - Train Accuracy:  0.689, Validation Accuracy:  0.706, Loss:  1.281
Epoch   3 Batch   28/153 - Train Accuracy:  0.692, Validation Accuracy:  0.700, Loss:  1.277
Epoch   3 Batch   29/153 - Train Accuracy:  0.684, Validation Accuracy:  0.690, Loss:  1.250
Epoch   3 Batch   30/153 - Train Accuracy:  0.691, Validation Accuracy:  0.678, Loss:  1.269
Epoch   3 Batch   31/153 - Train Accuracy:  0.683, Validation Accuracy:  0.686, Loss:  1.261
Epoch   3 Batch   32/153 - Train Accuracy:  0.693, Validation Accuracy:  0.698, Loss:  1.283
Epoch   3 Batch   33/153 - Train Accuracy:  0.703, Validation Accuracy:  0.706, Loss:  1.253
Epoch   3 Batch   34/153 - Train Accuracy:  0.705, Validation Accuracy:  0.705, Loss:  1.222
Epoch   3 Batch   35/153 - Train Accuracy:  0.706, Validation Accuracy:  0.699, Loss:  1.242
Epoch   3 Batch   36/153 - Train Accuracy:  0.689, Validation Accuracy:  0.700, Loss:  1.253
Epoch   3 Batch   37/153 - Train Accuracy:  0.686, Validation Accuracy:  0.687, Loss:  1.237
Epoch   3 Batch   38/153 - Train Accuracy:  0.662, Validation Accuracy:  0.679, Loss:  1.254
Epoch   3 Batch   39/153 - Train Accuracy:  0.670, Validation Accuracy:  0.677, Loss:  1.265
Epoch   3 Batch   40/153 - Train Accuracy:  0.701, Validation Accuracy:  0.692, Loss:  1.248
Epoch   3 Batch   41/153 - Train Accuracy:  0.710, Validation Accuracy:  0.693, Loss:  1.230
Epoch   3 Batch   42/153 - Train Accuracy:  0.706, Validation Accuracy:  0.704, Loss:  1.267
Epoch   3 Batch   43/153 - Train Accuracy:  0.699, Validation Accuracy:  0.709, Loss:  1.266
Epoch   3 Batch   44/153 - Train Accuracy:  0.711, Validation Accuracy:  0.709, Loss:  1.231
Epoch   3 Batch   45/153 - Train Accuracy:  0.706, Validation Accuracy:  0.712, Loss:  1.246
Epoch   3 Batch   46/153 - Train Accuracy:  0.714, Validation Accuracy:  0.712, Loss:  1.232
Epoch   3 Batch   47/153 - Train Accuracy:  0.705, Validation Accuracy:  0.717, Loss:  1.248
Epoch   3 Batch   48/153 - Train Accuracy:  0.706, Validation Accuracy:  0.709, Loss:  1.246
Epoch   3 Batch   49/153 - Train Accuracy:  0.691, Validation Accuracy:  0.701, Loss:  1.226
Epoch   3 Batch   50/153 - Train Accuracy:  0.699, Validation Accuracy:  0.692, Loss:  1.231
Epoch   3 Batch   51/153 - Train Accuracy:  0.694, Validation Accuracy:  0.698, Loss:  1.215
Epoch   3 Batch   52/153 - Train Accuracy:  0.720, Validation Accuracy:  0.713, Loss:  1.207
Epoch   3 Batch   53/153 - Train Accuracy:  0.708, Validation Accuracy:  0.716, Loss:  1.236
Epoch   3 Batch   54/153 - Train Accuracy:  0.706, Validation Accuracy:  0.714, Loss:  1.220
Epoch   3 Batch   55/153 - Train Accuracy:  0.706, Validation Accuracy:  0.718, Loss:  1.215
Epoch   3 Batch   56/153 - Train Accuracy:  0.723, Validation Accuracy:  0.716, Loss:  1.221
Epoch   3 Batch   57/153 - Train Accuracy:  0.713, Validation Accuracy:  0.717, Loss:  1.224
Epoch   3 Batch   58/153 - Train Accuracy:  0.715, Validation Accuracy:  0.712, Loss:  1.242
Epoch   3 Batch   59/153 - Train Accuracy:  0.696, Validation Accuracy:  0.712, Loss:  1.202
Epoch   3 Batch   60/153 - Train Accuracy:  0.704, Validation Accuracy:  0.697, Loss:  1.199
Epoch   3 Batch   61/153 - Train Accuracy:  0.690, Validation Accuracy:  0.693, Loss:  1.212
Epoch   3 Batch   62/153 - Train Accuracy:  0.675, Validation Accuracy:  0.678, Loss:  1.196
Epoch   3 Batch   63/153 - Train Accuracy:  0.699, Validation Accuracy:  0.693, Loss:  1.196
Epoch   3 Batch   64/153 - Train Accuracy:  0.712, Validation Accuracy:  0.711, Loss:  1.196
Epoch   3 Batch   65/153 - Train Accuracy:  0.713, Validation Accuracy:  0.714, Loss:  1.197
Epoch   3 Batch   66/153 - Train Accuracy:  0.703, Validation Accuracy:  0.723, Loss:  1.229
Epoch   3 Batch   67/153 - Train Accuracy:  0.735, Validation Accuracy:  0.730, Loss:  1.205
Epoch   3 Batch   68/153 - Train Accuracy:  0.723, Validation Accuracy:  0.730, Loss:  1.202
Epoch   3 Batch   69/153 - Train Accuracy:  0.726, Validation Accuracy:  0.733, Loss:  1.200
Epoch   3 Batch   70/153 - Train Accuracy:  0.718, Validation Accuracy:  0.727, Loss:  1.224
Epoch   3 Batch   71/153 - Train Accuracy:  0.695, Validation Accuracy:  0.708, Loss:  1.239
Epoch   3 Batch   72/153 - Train Accuracy:  0.714, Validation Accuracy:  0.695, Loss:  1.198
Epoch   3 Batch   73/153 - Train Accuracy:  0.699, Validation Accuracy:  0.700, Loss:  1.235
Epoch   3 Batch   74/153 - Train Accuracy:  0.693, Validation Accuracy:  0.700, Loss:  1.220
Epoch   3 Batch   75/153 - Train Accuracy:  0.702, Validation Accuracy:  0.713, Loss:  1.235
Epoch   3 Batch   76/153 - Train Accuracy:  0.716, Validation Accuracy:  0.727, Loss:  1.218
Epoch   3 Batch   77/153 - Train Accuracy:  0.699, Validation Accuracy:  0.733, Loss:  1.227
Epoch   3 Batch   78/153 - Train Accuracy:  0.712, Validation Accuracy:  0.726, Loss:  1.232
Epoch   3 Batch   79/153 - Train Accuracy:  0.726, Validation Accuracy:  0.727, Loss:  1.192
Epoch   3 Batch   80/153 - Train Accuracy:  0.733, Validation Accuracy:  0.728, Loss:  1.194
Epoch   3 Batch   81/153 - Train Accuracy:  0.728, Validation Accuracy:  0.731, Loss:  1.161
Epoch   3 Batch   82/153 - Train Accuracy:  0.731, Validation Accuracy:  0.732, Loss:  1.193
Epoch   3 Batch   83/153 - Train Accuracy:  0.722, Validation Accuracy:  0.713, Loss:  1.183
Epoch   3 Batch   84/153 - Train Accuracy:  0.717, Validation Accuracy:  0.713, Loss:  1.197
Epoch   3 Batch   85/153 - Train Accuracy:  0.745, Validation Accuracy:  0.724, Loss:  1.154
Epoch   3 Batch   86/153 - Train Accuracy:  0.730, Validation Accuracy:  0.730, Loss:  1.199
Epoch   3 Batch   87/153 - Train Accuracy:  0.737, Validation Accuracy:  0.738, Loss:  1.190
Epoch   3 Batch   88/153 - Train Accuracy:  0.745, Validation Accuracy:  0.743, Loss:  1.168
Epoch   3 Batch   89/153 - Train Accuracy:  0.735, Validation Accuracy:  0.740, Loss:  1.180
Epoch   3 Batch   90/153 - Train Accuracy:  0.718, Validation Accuracy:  0.737, Loss:  1.185
Epoch   3 Batch   91/153 - Train Accuracy:  0.728, Validation Accuracy:  0.739, Loss:  1.178
Epoch   3 Batch   92/153 - Train Accuracy:  0.734, Validation Accuracy:  0.739, Loss:  1.194
Epoch   3 Batch   93/153 - Train Accuracy:  0.731, Validation Accuracy:  0.730, Loss:  1.169
Epoch   3 Batch   94/153 - Train Accuracy:  0.732, Validation Accuracy:  0.714, Loss:  1.169
Epoch   3 Batch   95/153 - Train Accuracy:  0.719, Validation Accuracy:  0.720, Loss:  1.164
Epoch   3 Batch   96/153 - Train Accuracy:  0.720, Validation Accuracy:  0.733, Loss:  1.189
Epoch   3 Batch   97/153 - Train Accuracy:  0.732, Validation Accuracy:  0.739, Loss:  1.188
Epoch   3 Batch   98/153 - Train Accuracy:  0.726, Validation Accuracy:  0.731, Loss:  1.174
Epoch   3 Batch   99/153 - Train Accuracy:  0.720, Validation Accuracy:  0.733, Loss:  1.186
Epoch   3 Batch  100/153 - Train Accuracy:  0.729, Validation Accuracy:  0.740, Loss:  1.202
Epoch   3 Batch  101/153 - Train Accuracy:  0.742, Validation Accuracy:  0.750, Loss:  1.177
Epoch   3 Batch  102/153 - Train Accuracy:  0.746, Validation Accuracy:  0.745, Loss:  1.168
Epoch   3 Batch  103/153 - Train Accuracy:  0.720, Validation Accuracy:  0.736, Loss:  1.194
Epoch   3 Batch  104/153 - Train Accuracy:  0.771, Validation Accuracy:  0.738, Loss:  1.140
Epoch   3 Batch  105/153 - Train Accuracy:  0.742, Validation Accuracy:  0.749, Loss:  1.175
Epoch   3 Batch  106/153 - Train Accuracy:  0.740, Validation Accuracy:  0.743, Loss:  1.164
Epoch   3 Batch  107/153 - Train Accuracy:  0.741, Validation Accuracy:  0.737, Loss:  1.180
Epoch   3 Batch  108/153 - Train Accuracy:  0.746, Validation Accuracy:  0.740, Loss:  1.177
Epoch   3 Batch  109/153 - Train Accuracy:  0.755, Validation Accuracy:  0.745, Loss:  1.172
Epoch   3 Batch  110/153 - Train Accuracy:  0.745, Validation Accuracy:  0.755, Loss:  1.187
Epoch   3 Batch  111/153 - Train Accuracy:  0.748, Validation Accuracy:  0.757, Loss:  1.154
Epoch   3 Batch  112/153 - Train Accuracy:  0.717, Validation Accuracy:  0.749, Loss:  1.185
Epoch   3 Batch  113/153 - Train Accuracy:  0.732, Validation Accuracy:  0.751, Loss:  1.165
Epoch   3 Batch  114/153 - Train Accuracy:  0.757, Validation Accuracy:  0.757, Loss:  1.147
Epoch   3 Batch  115/153 - Train Accuracy:  0.752, Validation Accuracy:  0.756, Loss:  1.185
Epoch   3 Batch  116/153 - Train Accuracy:  0.738, Validation Accuracy:  0.745, Loss:  1.142
Epoch   3 Batch  117/153 - Train Accuracy:  0.738, Validation Accuracy:  0.748, Loss:  1.155
Epoch   3 Batch  118/153 - Train Accuracy:  0.756, Validation Accuracy:  0.751, Loss:  1.136
Epoch   3 Batch  119/153 - Train Accuracy:  0.751, Validation Accuracy:  0.744, Loss:  1.179
Epoch   3 Batch  120/153 - Train Accuracy:  0.747, Validation Accuracy:  0.762, Loss:  1.161
Epoch   3 Batch  121/153 - Train Accuracy:  0.770, Validation Accuracy:  0.768, Loss:  1.172
Epoch   3 Batch  122/153 - Train Accuracy:  0.777, Validation Accuracy:  0.765, Loss:  1.116
Epoch   3 Batch  123/153 - Train Accuracy:  0.729, Validation Accuracy:  0.755, Loss:  1.178
Epoch   3 Batch  124/153 - Train Accuracy:  0.742, Validation Accuracy:  0.750, Loss:  1.146
Epoch   3 Batch  125/153 - Train Accuracy:  0.757, Validation Accuracy:  0.751, Loss:  1.137
Epoch   3 Batch  126/153 - Train Accuracy:  0.773, Validation Accuracy:  0.756, Loss:  1.153
Epoch   3 Batch  127/153 - Train Accuracy:  0.751, Validation Accuracy:  0.752, Loss:  1.126
Epoch   3 Batch  128/153 - Train Accuracy:  0.755, Validation Accuracy:  0.762, Loss:  1.151
Epoch   3 Batch  129/153 - Train Accuracy:  0.781, Validation Accuracy:  0.762, Loss:  1.110
Epoch   3 Batch  130/153 - Train Accuracy:  0.754, Validation Accuracy:  0.756, Loss:  1.144
Epoch   3 Batch  131/153 - Train Accuracy:  0.720, Validation Accuracy:  0.733, Loss:  1.150
Epoch   3 Batch  132/153 - Train Accuracy:  0.725, Validation Accuracy:  0.746, Loss:  1.192
Epoch   3 Batch  133/153 - Train Accuracy:  0.747, Validation Accuracy:  0.749, Loss:  1.183
Epoch   3 Batch  134/153 - Train Accuracy:  0.750, Validation Accuracy:  0.759, Loss:  1.150
Epoch   3 Batch  135/153 - Train Accuracy:  0.745, Validation Accuracy:  0.760, Loss:  1.135
Epoch   3 Batch  136/153 - Train Accuracy:  0.751, Validation Accuracy:  0.755, Loss:  1.151
Epoch   3 Batch  137/153 - Train Accuracy:  0.754, Validation Accuracy:  0.730, Loss:  1.129
Epoch   3 Batch  138/153 - Train Accuracy:  0.733, Validation Accuracy:  0.725, Loss:  1.173
Epoch   3 Batch  139/153 - Train Accuracy:  0.747, Validation Accuracy:  0.757, Loss:  1.174
Epoch   3 Batch  140/153 - Train Accuracy:  0.736, Validation Accuracy:  0.752, Loss:  1.188
Epoch   3 Batch  141/153 - Train Accuracy:  0.749, Validation Accuracy:  0.761, Loss:  1.140
Epoch   3 Batch  142/153 - Train Accuracy:  0.767, Validation Accuracy:  0.757, Loss:  1.130
Epoch   3 Batch  143/153 - Train Accuracy:  0.766, Validation Accuracy:  0.767, Loss:  1.153
Epoch   3 Batch  144/153 - Train Accuracy:  0.735, Validation Accuracy:  0.748, Loss:  1.154
Epoch   3 Batch  145/153 - Train Accuracy:  0.743, Validation Accuracy:  0.738, Loss:  1.170
Epoch   3 Batch  146/153 - Train Accuracy:  0.730, Validation Accuracy:  0.748, Loss:  1.149
Epoch   3 Batch  147/153 - Train Accuracy:  0.755, Validation Accuracy:  0.760, Loss:  1.146
Epoch   3 Batch  148/153 - Train Accuracy:  0.758, Validation Accuracy:  0.777, Loss:  1.155
Epoch   3 Batch  149/153 - Train Accuracy:  0.757, Validation Accuracy:  0.771, Loss:  1.138
Epoch   3 Batch  150/153 - Train Accuracy:  0.755, Validation Accuracy:  0.775, Loss:  1.125
Epoch   3 Batch  151/153 - Train Accuracy:  0.773, Validation Accuracy:  0.778, Loss:  1.150
Epoch   4 Batch    0/153 - Train Accuracy:  0.759, Validation Accuracy:  0.775, Loss:  1.121
Epoch   4 Batch    1/153 - Train Accuracy:  0.773, Validation Accuracy:  0.752, Loss:  1.149
Epoch   4 Batch    2/153 - Train Accuracy:  0.717, Validation Accuracy:  0.745, Loss:  1.153
Epoch   4 Batch    3/153 - Train Accuracy:  0.760, Validation Accuracy:  0.753, Loss:  1.109
Epoch   4 Batch    4/153 - Train Accuracy:  0.754, Validation Accuracy:  0.776, Loss:  1.185
Epoch   4 Batch    5/153 - Train Accuracy:  0.769, Validation Accuracy:  0.780, Loss:  1.151
Epoch   4 Batch    6/153 - Train Accuracy:  0.750, Validation Accuracy:  0.768, Loss:  1.133
Epoch   4 Batch    7/153 - Train Accuracy:  0.772, Validation Accuracy:  0.780, Loss:  1.125
Epoch   4 Batch    8/153 - Train Accuracy:  0.766, Validation Accuracy:  0.781, Loss:  1.130
Epoch   4 Batch    9/153 - Train Accuracy:  0.759, Validation Accuracy:  0.769, Loss:  1.129
Epoch   4 Batch   10/153 - Train Accuracy:  0.783, Validation Accuracy:  0.767, Loss:  1.103
Epoch   4 Batch   11/153 - Train Accuracy:  0.770, Validation Accuracy:  0.772, Loss:  1.153
Epoch   4 Batch   12/153 - Train Accuracy:  0.761, Validation Accuracy:  0.772, Loss:  1.119
Epoch   4 Batch   13/153 - Train Accuracy:  0.780, Validation Accuracy:  0.772, Loss:  1.110
Epoch   4 Batch   14/153 - Train Accuracy:  0.775, Validation Accuracy:  0.783, Loss:  1.073
Epoch   4 Batch   15/153 - Train Accuracy:  0.754, Validation Accuracy:  0.778, Loss:  1.135
Epoch   4 Batch   16/153 - Train Accuracy:  0.741, Validation Accuracy:  0.757, Loss:  1.137
Epoch   4 Batch   17/153 - Train Accuracy:  0.772, Validation Accuracy:  0.757, Loss:  1.127
Epoch   4 Batch   18/153 - Train Accuracy:  0.771, Validation Accuracy:  0.769, Loss:  1.102
Epoch   4 Batch   19/153 - Train Accuracy:  0.766, Validation Accuracy:  0.777, Loss:  1.113
Epoch   4 Batch   20/153 - Train Accuracy:  0.768, Validation Accuracy:  0.782, Loss:  1.094
Epoch   4 Batch   21/153 - Train Accuracy:  0.769, Validation Accuracy:  0.776, Loss:  1.115
Epoch   4 Batch   22/153 - Train Accuracy:  0.760, Validation Accuracy:  0.775, Loss:  1.130
Epoch   4 Batch   23/153 - Train Accuracy:  0.771, Validation Accuracy:  0.771, Loss:  1.097
Epoch   4 Batch   24/153 - Train Accuracy:  0.763, Validation Accuracy:  0.766, Loss:  1.095
Epoch   4 Batch   25/153 - Train Accuracy:  0.766, Validation Accuracy:  0.777, Loss:  1.122
Epoch   4 Batch   26/153 - Train Accuracy:  0.781, Validation Accuracy:  0.766, Loss:  1.098
Epoch   4 Batch   27/153 - Train Accuracy:  0.765, Validation Accuracy:  0.778, Loss:  1.094
Epoch   4 Batch   28/153 - Train Accuracy:  0.770, Validation Accuracy:  0.777, Loss:  1.123
Epoch   4 Batch   29/153 - Train Accuracy:  0.743, Validation Accuracy:  0.774, Loss:  1.106
Epoch   4 Batch   30/153 - Train Accuracy:  0.769, Validation Accuracy:  0.776, Loss:  1.122
Epoch   4 Batch   31/153 - Train Accuracy:  0.777, Validation Accuracy:  0.783, Loss:  1.109
Epoch   4 Batch   32/153 - Train Accuracy:  0.778, Validation Accuracy:  0.782, Loss:  1.109
Epoch   4 Batch   33/153 - Train Accuracy:  0.779, Validation Accuracy:  0.783, Loss:  1.111
Epoch   4 Batch   34/153 - Train Accuracy:  0.765, Validation Accuracy:  0.751, Loss:  1.115
Epoch   4 Batch   35/153 - Train Accuracy:  0.787, Validation Accuracy:  0.789, Loss:  1.099
Epoch   4 Batch   36/153 - Train Accuracy:  0.768, Validation Accuracy:  0.781, Loss:  1.125
Epoch   4 Batch   37/153 - Train Accuracy:  0.757, Validation Accuracy:  0.760, Loss:  1.095
Epoch   4 Batch   38/153 - Train Accuracy:  0.746, Validation Accuracy:  0.782, Loss:  1.123
Epoch   4 Batch   39/153 - Train Accuracy:  0.762, Validation Accuracy:  0.775, Loss:  1.139
Epoch   4 Batch   40/153 - Train Accuracy:  0.778, Validation Accuracy:  0.765, Loss:  1.131
Epoch   4 Batch   41/153 - Train Accuracy:  0.776, Validation Accuracy:  0.781, Loss:  1.087
Epoch   4 Batch   42/153 - Train Accuracy:  0.774, Validation Accuracy:  0.779, Loss:  1.092
Epoch   4 Batch   43/153 - Train Accuracy:  0.766, Validation Accuracy:  0.766, Loss:  1.113
Epoch   4 Batch   44/153 - Train Accuracy:  0.777, Validation Accuracy:  0.776, Loss:  1.082
Epoch   4 Batch   45/153 - Train Accuracy:  0.776, Validation Accuracy:  0.781, Loss:  1.079
Epoch   4 Batch   46/153 - Train Accuracy:  0.786, Validation Accuracy:  0.779, Loss:  1.074
Epoch   4 Batch   47/153 - Train Accuracy:  0.778, Validation Accuracy:  0.782, Loss:  1.101
Epoch   4 Batch   48/153 - Train Accuracy:  0.769, Validation Accuracy:  0.783, Loss:  1.097
Epoch   4 Batch   49/153 - Train Accuracy:  0.744, Validation Accuracy:  0.772, Loss:  1.107
Epoch   4 Batch   50/153 - Train Accuracy:  0.786, Validation Accuracy:  0.782, Loss:  1.115
Epoch   4 Batch   51/153 - Train Accuracy:  0.769, Validation Accuracy:  0.780, Loss:  1.109
Epoch   4 Batch   52/153 - Train Accuracy:  0.789, Validation Accuracy:  0.778, Loss:  1.098
Epoch   4 Batch   53/153 - Train Accuracy:  0.786, Validation Accuracy:  0.783, Loss:  1.077
Epoch   4 Batch   54/153 - Train Accuracy:  0.771, Validation Accuracy:  0.784, Loss:  1.096
Epoch   4 Batch   55/153 - Train Accuracy:  0.795, Validation Accuracy:  0.783, Loss:  1.096
Epoch   4 Batch   56/153 - Train Accuracy:  0.795, Validation Accuracy:  0.790, Loss:  1.069
Epoch   4 Batch   57/153 - Train Accuracy:  0.800, Validation Accuracy:  0.798, Loss:  1.097
Epoch   4 Batch   58/153 - Train Accuracy:  0.793, Validation Accuracy:  0.799, Loss:  1.060
Epoch   4 Batch   59/153 - Train Accuracy:  0.780, Validation Accuracy:  0.787, Loss:  1.068
Epoch   4 Batch   60/153 - Train Accuracy:  0.797, Validation Accuracy:  0.799, Loss:  1.085
Epoch   4 Batch   61/153 - Train Accuracy:  0.798, Validation Accuracy:  0.797, Loss:  1.091
Epoch   4 Batch   62/153 - Train Accuracy:  0.784, Validation Accuracy:  0.792, Loss:  1.096
Epoch   4 Batch   63/153 - Train Accuracy:  0.799, Validation Accuracy:  0.794, Loss:  1.054
Epoch   4 Batch   64/153 - Train Accuracy:  0.807, Validation Accuracy:  0.796, Loss:  1.065
Epoch   4 Batch   65/153 - Train Accuracy:  0.803, Validation Accuracy:  0.804, Loss:  1.066
Epoch   4 Batch   66/153 - Train Accuracy:  0.793, Validation Accuracy:  0.806, Loss:  1.076
Epoch   4 Batch   67/153 - Train Accuracy:  0.824, Validation Accuracy:  0.813, Loss:  1.076
Epoch   4 Batch   68/153 - Train Accuracy:  0.792, Validation Accuracy:  0.805, Loss:  1.068
Epoch   4 Batch   69/153 - Train Accuracy:  0.811, Validation Accuracy:  0.803, Loss:  1.061
Epoch   4 Batch   70/153 - Train Accuracy:  0.784, Validation Accuracy:  0.793, Loss:  1.082
Epoch   4 Batch   71/153 - Train Accuracy:  0.763, Validation Accuracy:  0.765, Loss:  1.089
Epoch   4 Batch   72/153 - Train Accuracy:  0.809, Validation Accuracy:  0.801, Loss:  1.106
Epoch   4 Batch   73/153 - Train Accuracy:  0.783, Validation Accuracy:  0.794, Loss:  1.077
Epoch   4 Batch   74/153 - Train Accuracy:  0.797, Validation Accuracy:  0.815, Loss:  1.098
Epoch   4 Batch   75/153 - Train Accuracy:  0.811, Validation Accuracy:  0.805, Loss:  1.074
Epoch   4 Batch   76/153 - Train Accuracy:  0.823, Validation Accuracy:  0.826, Loss:  1.059
Epoch   4 Batch   77/153 - Train Accuracy:  0.778, Validation Accuracy:  0.816, Loss:  1.090
Epoch   4 Batch   78/153 - Train Accuracy:  0.801, Validation Accuracy:  0.806, Loss:  1.060
Epoch   4 Batch   79/153 - Train Accuracy:  0.830, Validation Accuracy:  0.829, Loss:  1.074
Epoch   4 Batch   80/153 - Train Accuracy:  0.815, Validation Accuracy:  0.815, Loss:  1.059
Epoch   4 Batch   81/153 - Train Accuracy:  0.826, Validation Accuracy:  0.825, Loss:  1.058
Epoch   4 Batch   82/153 - Train Accuracy:  0.809, Validation Accuracy:  0.812, Loss:  1.092
Epoch   4 Batch   83/153 - Train Accuracy:  0.821, Validation Accuracy:  0.818, Loss:  1.075
Epoch   4 Batch   84/153 - Train Accuracy:  0.824, Validation Accuracy:  0.832, Loss:  1.061
Epoch   4 Batch   85/153 - Train Accuracy:  0.827, Validation Accuracy:  0.834, Loss:  1.045
Epoch   4 Batch   86/153 - Train Accuracy:  0.829, Validation Accuracy:  0.829, Loss:  1.055
Epoch   4 Batch   87/153 - Train Accuracy:  0.832, Validation Accuracy:  0.833, Loss:  1.068
Epoch   4 Batch   88/153 - Train Accuracy:  0.832, Validation Accuracy:  0.833, Loss:  1.062
Epoch   4 Batch   89/153 - Train Accuracy:  0.839, Validation Accuracy:  0.839, Loss:  1.047
Epoch   4 Batch   90/153 - Train Accuracy:  0.810, Validation Accuracy:  0.824, Loss:  1.082
Epoch   4 Batch   91/153 - Train Accuracy:  0.683, Validation Accuracy:  0.732, Loss:  1.081
Epoch   4 Batch   92/153 - Train Accuracy:  0.530, Validation Accuracy:  0.557, Loss:  1.329
Epoch   4 Batch   93/153 - Train Accuracy:  0.522, Validation Accuracy:  0.526, Loss:  1.594
Epoch   4 Batch   94/153 - Train Accuracy:  0.599, Validation Accuracy:  0.590, Loss:  1.938
Epoch   4 Batch   95/153 - Train Accuracy:  0.529, Validation Accuracy:  0.557, Loss:  1.615
Epoch   4 Batch   96/153 - Train Accuracy:  0.568, Validation Accuracy:  0.588, Loss:  1.635
Epoch   4 Batch   97/153 - Train Accuracy:  0.572, Validation Accuracy:  0.572, Loss:  1.485
Epoch   4 Batch   98/153 - Train Accuracy:  0.612, Validation Accuracy:  0.621, Loss:  1.476
Epoch   4 Batch   99/153 - Train Accuracy:  0.583, Validation Accuracy:  0.606, Loss:  1.405
Epoch   4 Batch  100/153 - Train Accuracy:  0.612, Validation Accuracy:  0.636, Loss:  1.415
Epoch   4 Batch  101/153 - Train Accuracy:  0.643, Validation Accuracy:  0.648, Loss:  1.342
Epoch   4 Batch  102/153 - Train Accuracy:  0.641, Validation Accuracy:  0.639, Loss:  1.341
Epoch   4 Batch  103/153 - Train Accuracy:  0.656, Validation Accuracy:  0.670, Loss:  1.355
Epoch   4 Batch  104/153 - Train Accuracy:  0.706, Validation Accuracy:  0.667, Loss:  1.250
Epoch   4 Batch  105/153 - Train Accuracy:  0.694, Validation Accuracy:  0.684, Loss:  1.289
Epoch   4 Batch  106/153 - Train Accuracy:  0.677, Validation Accuracy:  0.694, Loss:  1.280
Epoch   4 Batch  107/153 - Train Accuracy:  0.704, Validation Accuracy:  0.706, Loss:  1.258
Epoch   4 Batch  108/153 - Train Accuracy:  0.709, Validation Accuracy:  0.713, Loss:  1.227
Epoch   4 Batch  109/153 - Train Accuracy:  0.700, Validation Accuracy:  0.708, Loss:  1.251
Epoch   4 Batch  110/153 - Train Accuracy:  0.702, Validation Accuracy:  0.719, Loss:  1.211
Epoch   4 Batch  111/153 - Train Accuracy:  0.725, Validation Accuracy:  0.729, Loss:  1.215
Epoch   4 Batch  112/153 - Train Accuracy:  0.710, Validation Accuracy:  0.735, Loss:  1.228
Epoch   4 Batch  113/153 - Train Accuracy:  0.749, Validation Accuracy:  0.764, Loss:  1.205
Epoch   4 Batch  114/153 - Train Accuracy:  0.755, Validation Accuracy:  0.764, Loss:  1.174
Epoch   4 Batch  115/153 - Train Accuracy:  0.762, Validation Accuracy:  0.769, Loss:  1.195
Epoch   4 Batch  116/153 - Train Accuracy:  0.754, Validation Accuracy:  0.763, Loss:  1.170
Epoch   4 Batch  117/153 - Train Accuracy:  0.755, Validation Accuracy:  0.771, Loss:  1.178
Epoch   4 Batch  118/153 - Train Accuracy:  0.774, Validation Accuracy:  0.776, Loss:  1.153
Epoch   4 Batch  119/153 - Train Accuracy:  0.782, Validation Accuracy:  0.774, Loss:  1.158
Epoch   4 Batch  120/153 - Train Accuracy:  0.775, Validation Accuracy:  0.786, Loss:  1.164
Epoch   4 Batch  121/153 - Train Accuracy:  0.782, Validation Accuracy:  0.787, Loss:  1.148
Epoch   4 Batch  122/153 - Train Accuracy:  0.806, Validation Accuracy:  0.799, Loss:  1.128
Epoch   4 Batch  123/153 - Train Accuracy:  0.794, Validation Accuracy:  0.800, Loss:  1.145
Epoch   4 Batch  124/153 - Train Accuracy:  0.794, Validation Accuracy:  0.799, Loss:  1.117
Epoch   4 Batch  125/153 - Train Accuracy:  0.797, Validation Accuracy:  0.814, Loss:  1.109
Epoch   4 Batch  126/153 - Train Accuracy:  0.815, Validation Accuracy:  0.811, Loss:  1.100
Epoch   4 Batch  127/153 - Train Accuracy:  0.811, Validation Accuracy:  0.812, Loss:  1.100
Epoch   4 Batch  128/153 - Train Accuracy:  0.805, Validation Accuracy:  0.811, Loss:  1.111
Epoch   4 Batch  129/153 - Train Accuracy:  0.830, Validation Accuracy:  0.807, Loss:  1.109
Epoch   4 Batch  130/153 - Train Accuracy:  0.798, Validation Accuracy:  0.815, Loss:  1.085
Epoch   4 Batch  131/153 - Train Accuracy:  0.809, Validation Accuracy:  0.817, Loss:  1.106
Epoch   4 Batch  132/153 - Train Accuracy:  0.805, Validation Accuracy:  0.808, Loss:  1.088
Epoch   4 Batch  133/153 - Train Accuracy:  0.826, Validation Accuracy:  0.819, Loss:  1.083
Epoch   4 Batch  134/153 - Train Accuracy:  0.812, Validation Accuracy:  0.806, Loss:  1.073
Epoch   4 Batch  135/153 - Train Accuracy:  0.822, Validation Accuracy:  0.821, Loss:  1.068
Epoch   4 Batch  136/153 - Train Accuracy:  0.830, Validation Accuracy:  0.823, Loss:  1.098
Epoch   4 Batch  137/153 - Train Accuracy:  0.821, Validation Accuracy:  0.816, Loss:  1.085
Epoch   4 Batch  138/153 - Train Accuracy:  0.840, Validation Accuracy:  0.833, Loss:  1.078
Epoch   4 Batch  139/153 - Train Accuracy:  0.820, Validation Accuracy:  0.832, Loss:  1.101
Epoch   4 Batch  140/153 - Train Accuracy:  0.834, Validation Accuracy:  0.833, Loss:  1.065
Epoch   4 Batch  141/153 - Train Accuracy:  0.832, Validation Accuracy:  0.838, Loss:  1.033
Epoch   4 Batch  142/153 - Train Accuracy:  0.869, Validation Accuracy:  0.842, Loss:  1.053
Epoch   4 Batch  143/153 - Train Accuracy:  0.860, Validation Accuracy:  0.847, Loss:  1.042
Epoch   4 Batch  144/153 - Train Accuracy:  0.819, Validation Accuracy:  0.840, Loss:  1.062
Epoch   4 Batch  145/153 - Train Accuracy:  0.843, Validation Accuracy:  0.849, Loss:  1.047
Epoch   4 Batch  146/153 - Train Accuracy:  0.813, Validation Accuracy:  0.833, Loss:  1.056
Epoch   4 Batch  147/153 - Train Accuracy:  0.841, Validation Accuracy:  0.849, Loss:  1.059
Epoch   4 Batch  148/153 - Train Accuracy:  0.816, Validation Accuracy:  0.832, Loss:  1.071
Epoch   4 Batch  149/153 - Train Accuracy:  0.856, Validation Accuracy:  0.855, Loss:  1.057
Epoch   4 Batch  150/153 - Train Accuracy:  0.830, Validation Accuracy:  0.853, Loss:  1.068
Epoch   4 Batch  151/153 - Train Accuracy:  0.849, Validation Accuracy:  0.838, Loss:  1.074
Epoch   5 Batch    0/153 - Train Accuracy:  0.849, Validation Accuracy:  0.859, Loss:  1.049
Epoch   5 Batch    1/153 - Train Accuracy:  0.862, Validation Accuracy:  0.864, Loss:  1.051
Epoch   5 Batch    2/153 - Train Accuracy:  0.831, Validation Accuracy:  0.849, Loss:  1.085
Epoch   5 Batch    3/153 - Train Accuracy:  0.842, Validation Accuracy:  0.852, Loss:  1.062
Epoch   5 Batch    4/153 - Train Accuracy:  0.844, Validation Accuracy:  0.852, Loss:  1.088
Epoch   5 Batch    5/153 - Train Accuracy:  0.853, Validation Accuracy:  0.853, Loss:  1.038
Epoch   5 Batch    6/153 - Train Accuracy:  0.862, Validation Accuracy:  0.859, Loss:  1.056
Epoch   5 Batch    7/153 - Train Accuracy:  0.858, Validation Accuracy:  0.862, Loss:  1.051
Epoch   5 Batch    8/153 - Train Accuracy:  0.845, Validation Accuracy:  0.843, Loss:  1.036
Epoch   5 Batch    9/153 - Train Accuracy:  0.857, Validation Accuracy:  0.855, Loss:  1.045
Epoch   5 Batch   10/153 - Train Accuracy:  0.861, Validation Accuracy:  0.857, Loss:  1.025
Epoch   5 Batch   11/153 - Train Accuracy:  0.855, Validation Accuracy:  0.867, Loss:  1.039
Epoch   5 Batch   12/153 - Train Accuracy:  0.862, Validation Accuracy:  0.871, Loss:  1.056
Epoch   5 Batch   13/153 - Train Accuracy:  0.869, Validation Accuracy:  0.879, Loss:  1.033
Epoch   5 Batch   14/153 - Train Accuracy:  0.854, Validation Accuracy:  0.870, Loss:  1.011
Epoch   5 Batch   15/153 - Train Accuracy:  0.866, Validation Accuracy:  0.882, Loss:  1.021
Epoch   5 Batch   16/153 - Train Accuracy:  0.850, Validation Accuracy:  0.869, Loss:  1.051
Epoch   5 Batch   17/153 - Train Accuracy:  0.876, Validation Accuracy:  0.869, Loss:  1.024
Epoch   5 Batch   18/153 - Train Accuracy:  0.871, Validation Accuracy:  0.876, Loss:  1.029
Epoch   5 Batch   19/153 - Train Accuracy:  0.866, Validation Accuracy:  0.871, Loss:  1.030
Epoch   5 Batch   20/153 - Train Accuracy:  0.875, Validation Accuracy:  0.870, Loss:  1.019
Epoch   5 Batch   21/153 - Train Accuracy:  0.863, Validation Accuracy:  0.873, Loss:  1.023
Epoch   5 Batch   22/153 - Train Accuracy:  0.866, Validation Accuracy:  0.875, Loss:  1.046
Epoch   5 Batch   23/153 - Train Accuracy:  0.876, Validation Accuracy:  0.878, Loss:  0.993
Epoch   5 Batch   24/153 - Train Accuracy:  0.874, Validation Accuracy:  0.872, Loss:  1.005
Epoch   5 Batch   25/153 - Train Accuracy:  0.876, Validation Accuracy:  0.880, Loss:  1.019
Epoch   5 Batch   26/153 - Train Accuracy:  0.885, Validation Accuracy:  0.882, Loss:  1.012
Epoch   5 Batch   27/153 - Train Accuracy:  0.885, Validation Accuracy:  0.887, Loss:  1.011
Epoch   5 Batch   28/153 - Train Accuracy:  0.877, Validation Accuracy:  0.884, Loss:  1.016
Epoch   5 Batch   29/153 - Train Accuracy:  0.875, Validation Accuracy:  0.882, Loss:  1.011
Epoch   5 Batch   30/153 - Train Accuracy:  0.889, Validation Accuracy:  0.885, Loss:  1.028
Epoch   5 Batch   31/153 - Train Accuracy:  0.891, Validation Accuracy:  0.885, Loss:  1.024
Epoch   5 Batch   32/153 - Train Accuracy:  0.892, Validation Accuracy:  0.895, Loss:  0.990
Epoch   5 Batch   33/153 - Train Accuracy:  0.892, Validation Accuracy:  0.892, Loss:  0.990
Epoch   5 Batch   34/153 - Train Accuracy:  0.892, Validation Accuracy:  0.893, Loss:  0.998
Epoch   5 Batch   35/153 - Train Accuracy:  0.883, Validation Accuracy:  0.896, Loss:  1.011
Epoch   5 Batch   36/153 - Train Accuracy:  0.887, Validation Accuracy:  0.896, Loss:  0.997
Epoch   5 Batch   37/153 - Train Accuracy:  0.885, Validation Accuracy:  0.893, Loss:  1.008
Epoch   5 Batch   38/153 - Train Accuracy:  0.885, Validation Accuracy:  0.893, Loss:  1.042
Epoch   5 Batch   39/153 - Train Accuracy:  0.876, Validation Accuracy:  0.882, Loss:  1.001
Epoch   5 Batch   40/153 - Train Accuracy:  0.880, Validation Accuracy:  0.891, Loss:  0.997
Epoch   5 Batch   41/153 - Train Accuracy:  0.894, Validation Accuracy:  0.892, Loss:  1.008
Epoch   5 Batch   42/153 - Train Accuracy:  0.896, Validation Accuracy:  0.893, Loss:  0.994
Epoch   5 Batch   43/153 - Train Accuracy:  0.887, Validation Accuracy:  0.895, Loss:  1.011
Epoch   5 Batch   44/153 - Train Accuracy:  0.896, Validation Accuracy:  0.902, Loss:  1.012
Epoch   5 Batch   45/153 - Train Accuracy:  0.887, Validation Accuracy:  0.905, Loss:  1.007
Epoch   5 Batch   46/153 - Train Accuracy:  0.900, Validation Accuracy:  0.904, Loss:  0.980
Epoch   5 Batch   47/153 - Train Accuracy:  0.890, Validation Accuracy:  0.901, Loss:  0.985
Epoch   5 Batch   48/153 - Train Accuracy:  0.891, Validation Accuracy:  0.901, Loss:  0.981
Epoch   5 Batch   49/153 - Train Accuracy:  0.886, Validation Accuracy:  0.904, Loss:  0.998
Epoch   5 Batch   50/153 - Train Accuracy:  0.905, Validation Accuracy:  0.904, Loss:  0.995
Epoch   5 Batch   51/153 - Train Accuracy:  0.904, Validation Accuracy:  0.898, Loss:  0.981
Epoch   5 Batch   52/153 - Train Accuracy:  0.903, Validation Accuracy:  0.899, Loss:  0.984
Epoch   5 Batch   53/153 - Train Accuracy:  0.894, Validation Accuracy:  0.896, Loss:  0.998
Epoch   5 Batch   54/153 - Train Accuracy:  0.885, Validation Accuracy:  0.896, Loss:  0.988
Epoch   5 Batch   55/153 - Train Accuracy:  0.889, Validation Accuracy:  0.894, Loss:  1.011
Epoch   5 Batch   56/153 - Train Accuracy:  0.891, Validation Accuracy:  0.890, Loss:  1.007
Epoch   5 Batch   57/153 - Train Accuracy:  0.902, Validation Accuracy:  0.892, Loss:  0.981
Epoch   5 Batch   58/153 - Train Accuracy:  0.897, Validation Accuracy:  0.911, Loss:  1.008
Epoch   5 Batch   59/153 - Train Accuracy:  0.885, Validation Accuracy:  0.910, Loss:  0.965
Epoch   5 Batch   60/153 - Train Accuracy:  0.905, Validation Accuracy:  0.906, Loss:  0.982
Epoch   5 Batch   61/153 - Train Accuracy:  0.906, Validation Accuracy:  0.907, Loss:  1.006
Epoch   5 Batch   62/153 - Train Accuracy:  0.888, Validation Accuracy:  0.904, Loss:  0.960
Epoch   5 Batch   63/153 - Train Accuracy:  0.897, Validation Accuracy:  0.906, Loss:  0.992
Epoch   5 Batch   64/153 - Train Accuracy:  0.907, Validation Accuracy:  0.908, Loss:  0.968
Epoch   5 Batch   65/153 - Train Accuracy:  0.905, Validation Accuracy:  0.914, Loss:  0.978
Epoch   5 Batch   66/153 - Train Accuracy:  0.903, Validation Accuracy:  0.907, Loss:  0.964
Epoch   5 Batch   67/153 - Train Accuracy:  0.910, Validation Accuracy:  0.900, Loss:  0.977
Epoch   5 Batch   68/153 - Train Accuracy:  0.905, Validation Accuracy:  0.913, Loss:  1.000
Epoch   5 Batch   69/153 - Train Accuracy:  0.903, Validation Accuracy:  0.906, Loss:  0.973
Epoch   5 Batch   70/153 - Train Accuracy:  0.906, Validation Accuracy:  0.913, Loss:  0.993
Epoch   5 Batch   71/153 - Train Accuracy:  0.906, Validation Accuracy:  0.911, Loss:  0.958
Epoch   5 Batch   72/153 - Train Accuracy:  0.914, Validation Accuracy:  0.916, Loss:  0.996
Epoch   5 Batch   73/153 - Train Accuracy:  0.905, Validation Accuracy:  0.913, Loss:  0.969
Epoch   5 Batch   74/153 - Train Accuracy:  0.900, Validation Accuracy:  0.913, Loss:  0.983
Epoch   5 Batch   75/153 - Train Accuracy:  0.898, Validation Accuracy:  0.911, Loss:  0.966
Epoch   5 Batch   76/153 - Train Accuracy:  0.912, Validation Accuracy:  0.905, Loss:  0.966
Epoch   5 Batch   77/153 - Train Accuracy:  0.907, Validation Accuracy:  0.922, Loss:  0.978
Epoch   5 Batch   78/153 - Train Accuracy:  0.909, Validation Accuracy:  0.920, Loss:  0.958
Epoch   5 Batch   79/153 - Train Accuracy:  0.910, Validation Accuracy:  0.921, Loss:  0.953
Epoch   5 Batch   80/153 - Train Accuracy:  0.922, Validation Accuracy:  0.919, Loss:  0.974
Epoch   5 Batch   81/153 - Train Accuracy:  0.916, Validation Accuracy:  0.914, Loss:  0.970
Epoch   5 Batch   82/153 - Train Accuracy:  0.920, Validation Accuracy:  0.913, Loss:  0.958
Epoch   5 Batch   83/153 - Train Accuracy:  0.910, Validation Accuracy:  0.910, Loss:  0.957
Epoch   5 Batch   84/153 - Train Accuracy:  0.908, Validation Accuracy:  0.919, Loss:  0.971
Epoch   5 Batch   85/153 - Train Accuracy:  0.920, Validation Accuracy:  0.918, Loss:  0.959
Epoch   5 Batch   86/153 - Train Accuracy:  0.914, Validation Accuracy:  0.919, Loss:  0.967
Epoch   5 Batch   87/153 - Train Accuracy:  0.924, Validation Accuracy:  0.917, Loss:  0.977
Epoch   5 Batch   88/153 - Train Accuracy:  0.917, Validation Accuracy:  0.924, Loss:  0.965
Epoch   5 Batch   89/153 - Train Accuracy:  0.904, Validation Accuracy:  0.916, Loss:  0.950
Epoch   5 Batch   90/153 - Train Accuracy:  0.909, Validation Accuracy:  0.922, Loss:  0.974
Epoch   5 Batch   91/153 - Train Accuracy:  0.902, Validation Accuracy:  0.909, Loss:  0.980
Epoch   5 Batch   92/153 - Train Accuracy:  0.911, Validation Accuracy:  0.922, Loss:  0.956
Epoch   5 Batch   93/153 - Train Accuracy:  0.912, Validation Accuracy:  0.913, Loss:  0.940
Epoch   5 Batch   94/153 - Train Accuracy:  0.918, Validation Accuracy:  0.919, Loss:  0.963
Epoch   5 Batch   95/153 - Train Accuracy:  0.906, Validation Accuracy:  0.912, Loss:  0.963
Epoch   5 Batch   96/153 - Train Accuracy:  0.908, Validation Accuracy:  0.914, Loss:  0.969
Epoch   5 Batch   97/153 - Train Accuracy:  0.910, Validation Accuracy:  0.910, Loss:  0.942
Epoch   5 Batch   98/153 - Train Accuracy:  0.901, Validation Accuracy:  0.922, Loss:  0.948
Epoch   5 Batch   99/153 - Train Accuracy:  0.897, Validation Accuracy:  0.908, Loss:  0.963
Epoch   5 Batch  100/153 - Train Accuracy:  0.899, Validation Accuracy:  0.916, Loss:  0.999
Epoch   5 Batch  101/153 - Train Accuracy:  0.897, Validation Accuracy:  0.903, Loss:  0.967
Epoch   5 Batch  102/153 - Train Accuracy:  0.902, Validation Accuracy:  0.906, Loss:  0.960
Epoch   5 Batch  103/153 - Train Accuracy:  0.901, Validation Accuracy:  0.918, Loss:  0.948
Epoch   5 Batch  104/153 - Train Accuracy:  0.918, Validation Accuracy:  0.898, Loss:  0.964
Epoch   5 Batch  105/153 - Train Accuracy:  0.896, Validation Accuracy:  0.901, Loss:  0.990
Epoch   5 Batch  106/153 - Train Accuracy:  0.909, Validation Accuracy:  0.921, Loss:  0.975
Epoch   5 Batch  107/153 - Train Accuracy:  0.888, Validation Accuracy:  0.897, Loss:  0.953
Epoch   5 Batch  108/153 - Train Accuracy:  0.903, Validation Accuracy:  0.913, Loss:  0.991
Epoch   5 Batch  109/153 - Train Accuracy:  0.909, Validation Accuracy:  0.917, Loss:  0.969
Epoch   5 Batch  110/153 - Train Accuracy:  0.910, Validation Accuracy:  0.921, Loss:  0.953
Epoch   5 Batch  111/153 - Train Accuracy:  0.906, Validation Accuracy:  0.914, Loss:  0.963
Epoch   5 Batch  112/153 - Train Accuracy:  0.892, Validation Accuracy:  0.922, Loss:  0.959
Epoch   5 Batch  113/153 - Train Accuracy:  0.906, Validation Accuracy:  0.919, Loss:  0.962
Epoch   5 Batch  114/153 - Train Accuracy:  0.914, Validation Accuracy:  0.915, Loss:  0.947
Epoch   5 Batch  115/153 - Train Accuracy:  0.920, Validation Accuracy:  0.917, Loss:  0.955
Epoch   5 Batch  116/153 - Train Accuracy:  0.921, Validation Accuracy:  0.922, Loss:  0.953
Epoch   5 Batch  117/153 - Train Accuracy:  0.898, Validation Accuracy:  0.922, Loss:  0.949
Epoch   5 Batch  118/153 - Train Accuracy:  0.914, Validation Accuracy:  0.925, Loss:  0.969
Epoch   5 Batch  119/153 - Train Accuracy:  0.926, Validation Accuracy:  0.929, Loss:  0.910
Epoch   5 Batch  120/153 - Train Accuracy:  0.911, Validation Accuracy:  0.927, Loss:  0.954
Epoch   5 Batch  121/153 - Train Accuracy:  0.920, Validation Accuracy:  0.927, Loss:  0.958
Epoch   5 Batch  122/153 - Train Accuracy:  0.926, Validation Accuracy:  0.924, Loss:  0.952
Epoch   5 Batch  123/153 - Train Accuracy:  0.902, Validation Accuracy:  0.924, Loss:  0.948
Epoch   5 Batch  124/153 - Train Accuracy:  0.928, Validation Accuracy:  0.927, Loss:  0.953
Epoch   5 Batch  125/153 - Train Accuracy:  0.924, Validation Accuracy:  0.923, Loss:  0.928
Epoch   5 Batch  126/153 - Train Accuracy:  0.930, Validation Accuracy:  0.922, Loss:  0.937
Epoch   5 Batch  127/153 - Train Accuracy:  0.917, Validation Accuracy:  0.931, Loss:  0.931
Epoch   5 Batch  128/153 - Train Accuracy:  0.913, Validation Accuracy:  0.930, Loss:  0.924
Epoch   5 Batch  129/153 - Train Accuracy:  0.928, Validation Accuracy:  0.933, Loss:  0.932
Epoch   5 Batch  130/153 - Train Accuracy:  0.924, Validation Accuracy:  0.932, Loss:  0.949
Epoch   5 Batch  131/153 - Train Accuracy:  0.929, Validation Accuracy:  0.933, Loss:  0.925
Epoch   5 Batch  132/153 - Train Accuracy:  0.916, Validation Accuracy:  0.933, Loss:  0.934
Epoch   5 Batch  133/153 - Train Accuracy:  0.928, Validation Accuracy:  0.931, Loss:  0.931
Epoch   5 Batch  134/153 - Train Accuracy:  0.927, Validation Accuracy:  0.926, Loss:  0.921
Epoch   5 Batch  135/153 - Train Accuracy:  0.926, Validation Accuracy:  0.925, Loss:  0.928
Epoch   5 Batch  136/153 - Train Accuracy:  0.933, Validation Accuracy:  0.933, Loss:  0.930
Epoch   5 Batch  137/153 - Train Accuracy:  0.925, Validation Accuracy:  0.935, Loss:  0.936
Epoch   5 Batch  138/153 - Train Accuracy:  0.931, Validation Accuracy:  0.935, Loss:  0.947
Epoch   5 Batch  139/153 - Train Accuracy:  0.911, Validation Accuracy:  0.935, Loss:  0.923
Epoch   5 Batch  140/153 - Train Accuracy:  0.921, Validation Accuracy:  0.939, Loss:  0.943
Epoch   5 Batch  141/153 - Train Accuracy:  0.931, Validation Accuracy:  0.929, Loss:  0.920
Epoch   5 Batch  142/153 - Train Accuracy:  0.935, Validation Accuracy:  0.937, Loss:  0.906
Epoch   5 Batch  143/153 - Train Accuracy:  0.947, Validation Accuracy:  0.941, Loss:  0.914
Epoch   5 Batch  144/153 - Train Accuracy:  0.916, Validation Accuracy:  0.938, Loss:  0.921
Epoch   5 Batch  145/153 - Train Accuracy:  0.927, Validation Accuracy:  0.934, Loss:  0.913
Epoch   5 Batch  146/153 - Train Accuracy:  0.918, Validation Accuracy:  0.930, Loss:  0.944
Epoch   5 Batch  147/153 - Train Accuracy:  0.922, Validation Accuracy:  0.927, Loss:  0.947
Epoch   5 Batch  148/153 - Train Accuracy:  0.920, Validation Accuracy:  0.932, Loss:  0.928
Epoch   5 Batch  149/153 - Train Accuracy:  0.923, Validation Accuracy:  0.930, Loss:  0.921
Epoch   5 Batch  150/153 - Train Accuracy:  0.907, Validation Accuracy:  0.939, Loss:  0.929
Epoch   5 Batch  151/153 - Train Accuracy:  0.927, Validation Accuracy:  0.933, Loss:  0.932
Epoch   6 Batch    0/153 - Train Accuracy:  0.932, Validation Accuracy:  0.930, Loss:  0.925
Epoch   6 Batch    1/153 - Train Accuracy:  0.932, Validation Accuracy:  0.933, Loss:  0.942
Epoch   6 Batch    2/153 - Train Accuracy:  0.926, Validation Accuracy:  0.931, Loss:  0.947
Epoch   6 Batch    3/153 - Train Accuracy:  0.937, Validation Accuracy:  0.934, Loss:  0.919
Epoch   6 Batch    4/153 - Train Accuracy:  0.929, Validation Accuracy:  0.935, Loss:  0.937
Epoch   6 Batch    5/153 - Train Accuracy:  0.931, Validation Accuracy:  0.931, Loss:  0.927
Epoch   6 Batch    6/153 - Train Accuracy:  0.930, Validation Accuracy:  0.937, Loss:  0.926
Epoch   6 Batch    7/153 - Train Accuracy:  0.932, Validation Accuracy:  0.937, Loss:  0.916
Epoch   6 Batch    8/153 - Train Accuracy:  0.931, Validation Accuracy:  0.929, Loss:  0.921
Epoch   6 Batch    9/153 - Train Accuracy:  0.923, Validation Accuracy:  0.927, Loss:  0.913
Epoch   6 Batch   10/153 - Train Accuracy:  0.931, Validation Accuracy:  0.937, Loss:  0.903
Epoch   6 Batch   11/153 - Train Accuracy:  0.929, Validation Accuracy:  0.938, Loss:  0.930
Epoch   6 Batch   12/153 - Train Accuracy:  0.930, Validation Accuracy:  0.941, Loss:  0.929
Epoch   6 Batch   13/153 - Train Accuracy:  0.933, Validation Accuracy:  0.942, Loss:  0.936
Epoch   6 Batch   14/153 - Train Accuracy:  0.929, Validation Accuracy:  0.937, Loss:  0.912
Epoch   6 Batch   15/153 - Train Accuracy:  0.931, Validation Accuracy:  0.939, Loss:  0.915
Epoch   6 Batch   16/153 - Train Accuracy:  0.920, Validation Accuracy:  0.937, Loss:  0.912
Epoch   6 Batch   17/153 - Train Accuracy:  0.935, Validation Accuracy:  0.935, Loss:  0.914
Epoch   6 Batch   18/153 - Train Accuracy:  0.933, Validation Accuracy:  0.926, Loss:  0.936
Epoch   6 Batch   19/153 - Train Accuracy:  0.927, Validation Accuracy:  0.934, Loss:  0.928
Epoch   6 Batch   20/153 - Train Accuracy:  0.930, Validation Accuracy:  0.938, Loss:  0.940
Epoch   6 Batch   21/153 - Train Accuracy:  0.928, Validation Accuracy:  0.939, Loss:  0.910
Epoch   6 Batch   22/153 - Train Accuracy:  0.926, Validation Accuracy:  0.935, Loss:  0.934
Epoch   6 Batch   23/153 - Train Accuracy:  0.936, Validation Accuracy:  0.933, Loss:  0.902
Epoch   6 Batch   24/153 - Train Accuracy:  0.929, Validation Accuracy:  0.938, Loss:  0.904
Epoch   6 Batch   25/153 - Train Accuracy:  0.933, Validation Accuracy:  0.942, Loss:  0.914
Epoch   6 Batch   26/153 - Train Accuracy:  0.939, Validation Accuracy:  0.945, Loss:  0.911
Epoch   6 Batch   27/153 - Train Accuracy:  0.933, Validation Accuracy:  0.939, Loss:  0.931
Epoch   6 Batch   28/153 - Train Accuracy:  0.931, Validation Accuracy:  0.937, Loss:  0.914
Epoch   6 Batch   29/153 - Train Accuracy:  0.922, Validation Accuracy:  0.928, Loss:  0.909
Epoch   6 Batch   30/153 - Train Accuracy:  0.943, Validation Accuracy:  0.938, Loss:  0.912
Epoch   6 Batch   31/153 - Train Accuracy:  0.933, Validation Accuracy:  0.942, Loss:  0.913
Epoch   6 Batch   32/153 - Train Accuracy:  0.937, Validation Accuracy:  0.946, Loss:  0.922
Epoch   6 Batch   33/153 - Train Accuracy:  0.937, Validation Accuracy:  0.941, Loss:  0.898
Epoch   6 Batch   34/153 - Train Accuracy:  0.933, Validation Accuracy:  0.940, Loss:  0.907
Epoch   6 Batch   35/153 - Train Accuracy:  0.927, Validation Accuracy:  0.940, Loss:  0.923
Epoch   6 Batch   36/153 - Train Accuracy:  0.941, Validation Accuracy:  0.942, Loss:  0.901
Epoch   6 Batch   37/153 - Train Accuracy:  0.928, Validation Accuracy:  0.936, Loss:  0.943
Epoch   6 Batch   38/153 - Train Accuracy:  0.928, Validation Accuracy:  0.936, Loss:  0.933
Epoch   6 Batch   39/153 - Train Accuracy:  0.928, Validation Accuracy:  0.932, Loss:  0.924
Epoch   6 Batch   40/153 - Train Accuracy:  0.932, Validation Accuracy:  0.934, Loss:  0.937
Epoch   6 Batch   41/153 - Train Accuracy:  0.936, Validation Accuracy:  0.939, Loss:  0.919
Epoch   6 Batch   42/153 - Train Accuracy:  0.946, Validation Accuracy:  0.943, Loss:  0.921
Epoch   6 Batch   43/153 - Train Accuracy:  0.935, Validation Accuracy:  0.939, Loss:  0.923
Epoch   6 Batch   44/153 - Train Accuracy:  0.935, Validation Accuracy:  0.942, Loss:  0.923
Epoch   6 Batch   45/153 - Train Accuracy:  0.930, Validation Accuracy:  0.945, Loss:  0.934
Epoch   6 Batch   46/153 - Train Accuracy:  0.939, Validation Accuracy:  0.945, Loss:  0.904
Epoch   6 Batch   47/153 - Train Accuracy:  0.930, Validation Accuracy:  0.944, Loss:  0.901
Epoch   6 Batch   48/153 - Train Accuracy:  0.939, Validation Accuracy:  0.945, Loss:  0.901
Epoch   6 Batch   49/153 - Train Accuracy:  0.931, Validation Accuracy:  0.929, Loss:  0.931
Epoch   6 Batch   50/153 - Train Accuracy:  0.931, Validation Accuracy:  0.939, Loss:  0.928
Epoch   6 Batch   51/153 - Train Accuracy:  0.941, Validation Accuracy:  0.938, Loss:  0.936
Epoch   6 Batch   52/153 - Train Accuracy:  0.948, Validation Accuracy:  0.936, Loss:  0.916
Epoch   6 Batch   53/153 - Train Accuracy:  0.931, Validation Accuracy:  0.932, Loss:  0.907
Epoch   6 Batch   54/153 - Train Accuracy:  0.932, Validation Accuracy:  0.937, Loss:  0.930
Epoch   6 Batch   55/153 - Train Accuracy:  0.943, Validation Accuracy:  0.939, Loss:  0.916
Epoch   6 Batch   56/153 - Train Accuracy:  0.942, Validation Accuracy:  0.936, Loss:  0.900
Epoch   6 Batch   57/153 - Train Accuracy:  0.941, Validation Accuracy:  0.930, Loss:  0.930
Epoch   6 Batch   58/153 - Train Accuracy:  0.937, Validation Accuracy:  0.932, Loss:  0.909
Epoch   6 Batch   59/153 - Train Accuracy:  0.924, Validation Accuracy:  0.942, Loss:  0.911
Epoch   6 Batch   60/153 - Train Accuracy:  0.943, Validation Accuracy:  0.940, Loss:  0.904
Epoch   6 Batch   61/153 - Train Accuracy:  0.945, Validation Accuracy:  0.939, Loss:  0.941
Epoch   6 Batch   62/153 - Train Accuracy:  0.918, Validation Accuracy:  0.939, Loss:  0.907
Epoch   6 Batch   63/153 - Train Accuracy:  0.932, Validation Accuracy:  0.945, Loss:  0.917
Epoch   6 Batch   64/153 - Train Accuracy:  0.933, Validation Accuracy:  0.940, Loss:  0.893
Epoch   6 Batch   65/153 - Train Accuracy:  0.936, Validation Accuracy:  0.945, Loss:  0.900
Epoch   6 Batch   66/153 - Train Accuracy:  0.932, Validation Accuracy:  0.933, Loss:  0.916
Epoch   6 Batch   67/153 - Train Accuracy:  0.943, Validation Accuracy:  0.939, Loss:  0.904
Epoch   6 Batch   68/153 - Train Accuracy:  0.933, Validation Accuracy:  0.939, Loss:  0.901
Epoch   6 Batch   69/153 - Train Accuracy:  0.934, Validation Accuracy:  0.939, Loss:  0.911
Epoch   6 Batch   70/153 - Train Accuracy:  0.938, Validation Accuracy:  0.932, Loss:  0.914
Epoch   6 Batch   71/153 - Train Accuracy:  0.935, Validation Accuracy:  0.938, Loss:  0.916
Epoch   6 Batch   72/153 - Train Accuracy:  0.939, Validation Accuracy:  0.938, Loss:  0.882
Epoch   6 Batch   73/153 - Train Accuracy:  0.927, Validation Accuracy:  0.936, Loss:  0.923
Epoch   6 Batch   74/153 - Train Accuracy:  0.936, Validation Accuracy:  0.936, Loss:  0.923
Epoch   6 Batch   75/153 - Train Accuracy:  0.929, Validation Accuracy:  0.937, Loss:  0.922
Epoch   6 Batch   76/153 - Train Accuracy:  0.940, Validation Accuracy:  0.933, Loss:  0.906
Epoch   6 Batch   77/153 - Train Accuracy:  0.924, Validation Accuracy:  0.939, Loss:  0.948
Epoch   6 Batch   78/153 - Train Accuracy:  0.935, Validation Accuracy:  0.942, Loss:  0.901
Epoch   6 Batch   79/153 - Train Accuracy:  0.936, Validation Accuracy:  0.941, Loss:  0.926
Epoch   6 Batch   80/153 - Train Accuracy:  0.939, Validation Accuracy:  0.940, Loss:  0.924
Epoch   6 Batch   81/153 - Train Accuracy:  0.936, Validation Accuracy:  0.941, Loss:  0.922
Epoch   6 Batch   82/153 - Train Accuracy:  0.950, Validation Accuracy:  0.943, Loss:  0.931
Epoch   6 Batch   83/153 - Train Accuracy:  0.933, Validation Accuracy:  0.936, Loss:  0.898
Epoch   6 Batch   84/153 - Train Accuracy:  0.936, Validation Accuracy:  0.936, Loss:  0.914
Epoch   6 Batch   85/153 - Train Accuracy:  0.937, Validation Accuracy:  0.931, Loss:  0.906
Epoch   6 Batch   86/153 - Train Accuracy:  0.935, Validation Accuracy:  0.936, Loss:  0.907
Epoch   6 Batch   87/153 - Train Accuracy:  0.943, Validation Accuracy:  0.930, Loss:  0.904
Epoch   6 Batch   88/153 - Train Accuracy:  0.934, Validation Accuracy:  0.944, Loss:  0.911
Epoch   6 Batch   89/153 - Train Accuracy:  0.936, Validation Accuracy:  0.945, Loss:  0.890
Epoch   6 Batch   90/153 - Train Accuracy:  0.938, Validation Accuracy:  0.946, Loss:  0.900
Epoch   6 Batch   91/153 - Train Accuracy:  0.939, Validation Accuracy:  0.943, Loss:  0.903
Epoch   6 Batch   92/153 - Train Accuracy:  0.948, Validation Accuracy:  0.946, Loss:  0.908
Epoch   6 Batch   93/153 - Train Accuracy:  0.943, Validation Accuracy:  0.941, Loss:  0.926
Epoch   6 Batch   94/153 - Train Accuracy:  0.940, Validation Accuracy:  0.938, Loss:  0.903
Epoch   6 Batch   95/153 - Train Accuracy:  0.941, Validation Accuracy:  0.940, Loss:  0.918
Epoch   6 Batch   96/153 - Train Accuracy:  0.943, Validation Accuracy:  0.938, Loss:  0.918
Epoch   6 Batch   97/153 - Train Accuracy:  0.946, Validation Accuracy:  0.943, Loss:  0.926
Epoch   6 Batch   98/153 - Train Accuracy:  0.932, Validation Accuracy:  0.941, Loss:  0.916
Epoch   6 Batch   99/153 - Train Accuracy:  0.933, Validation Accuracy:  0.944, Loss:  0.931
Epoch   6 Batch  100/153 - Train Accuracy:  0.928, Validation Accuracy:  0.946, Loss:  0.931
Epoch   6 Batch  101/153 - Train Accuracy:  0.942, Validation Accuracy:  0.943, Loss:  0.912
Epoch   6 Batch  102/153 - Train Accuracy:  0.949, Validation Accuracy:  0.949, Loss:  0.898
Epoch   6 Batch  103/153 - Train Accuracy:  0.941, Validation Accuracy:  0.947, Loss:  0.917
Epoch   6 Batch  104/153 - Train Accuracy:  0.952, Validation Accuracy:  0.950, Loss:  0.890
Epoch   6 Batch  105/153 - Train Accuracy:  0.954, Validation Accuracy:  0.949, Loss:  0.898
Epoch   6 Batch  106/153 - Train Accuracy:  0.942, Validation Accuracy:  0.946, Loss:  0.901
Epoch   6 Batch  107/153 - Train Accuracy:  0.947, Validation Accuracy:  0.952, Loss:  0.915
Epoch   6 Batch  108/153 - Train Accuracy:  0.946, Validation Accuracy:  0.949, Loss:  0.904
Epoch   6 Batch  109/153 - Train Accuracy:  0.946, Validation Accuracy:  0.946, Loss:  0.902
Epoch   6 Batch  110/153 - Train Accuracy:  0.935, Validation Accuracy:  0.944, Loss:  0.925
Epoch   6 Batch  111/153 - Train Accuracy:  0.940, Validation Accuracy:  0.949, Loss:  0.912
Epoch   6 Batch  112/153 - Train Accuracy:  0.927, Validation Accuracy:  0.951, Loss:  0.891
Epoch   6 Batch  113/153 - Train Accuracy:  0.931, Validation Accuracy:  0.948, Loss:  0.913
Epoch   6 Batch  114/153 - Train Accuracy:  0.948, Validation Accuracy:  0.950, Loss:  0.897
Epoch   6 Batch  115/153 - Train Accuracy:  0.944, Validation Accuracy:  0.948, Loss:  0.924
Epoch   6 Batch  116/153 - Train Accuracy:  0.947, Validation Accuracy:  0.945, Loss:  0.900
Epoch   6 Batch  117/153 - Train Accuracy:  0.925, Validation Accuracy:  0.951, Loss:  0.903
Epoch   6 Batch  118/153 - Train Accuracy:  0.949, Validation Accuracy:  0.948, Loss:  0.902
Epoch   6 Batch  119/153 - Train Accuracy:  0.943, Validation Accuracy:  0.950, Loss:  0.898
Epoch   6 Batch  120/153 - Train Accuracy:  0.943, Validation Accuracy:  0.951, Loss:  0.894
Epoch   6 Batch  121/153 - Train Accuracy:  0.943, Validation Accuracy:  0.952, Loss:  0.895
Epoch   6 Batch  122/153 - Train Accuracy:  0.943, Validation Accuracy:  0.948, Loss:  0.908
Epoch   6 Batch  123/153 - Train Accuracy:  0.939, Validation Accuracy:  0.947, Loss:  0.923
Epoch   6 Batch  124/153 - Train Accuracy:  0.945, Validation Accuracy:  0.947, Loss:  0.903
Epoch   6 Batch  125/153 - Train Accuracy:  0.936, Validation Accuracy:  0.950, Loss:  0.908
Epoch   6 Batch  126/153 - Train Accuracy:  0.949, Validation Accuracy:  0.950, Loss:  0.892
Epoch   6 Batch  127/153 - Train Accuracy:  0.944, Validation Accuracy:  0.952, Loss:  0.926
Epoch   6 Batch  128/153 - Train Accuracy:  0.946, Validation Accuracy:  0.949, Loss:  0.898
Epoch   6 Batch  129/153 - Train Accuracy:  0.949, Validation Accuracy:  0.953, Loss:  0.924
Epoch   6 Batch  130/153 - Train Accuracy:  0.944, Validation Accuracy:  0.953, Loss:  0.914
Epoch   6 Batch  131/153 - Train Accuracy:  0.948, Validation Accuracy:  0.956, Loss:  0.907
Epoch   6 Batch  132/153 - Train Accuracy:  0.946, Validation Accuracy:  0.955, Loss:  0.903
Epoch   6 Batch  133/153 - Train Accuracy:  0.957, Validation Accuracy:  0.952, Loss:  0.897
Epoch   6 Batch  134/153 - Train Accuracy:  0.955, Validation Accuracy:  0.950, Loss:  0.882
Epoch   6 Batch  135/153 - Train Accuracy:  0.957, Validation Accuracy:  0.948, Loss:  0.885
Epoch   6 Batch  136/153 - Train Accuracy:  0.947, Validation Accuracy:  0.950, Loss:  0.897
Epoch   6 Batch  137/153 - Train Accuracy:  0.944, Validation Accuracy:  0.948, Loss:  0.894
Epoch   6 Batch  138/153 - Train Accuracy:  0.949, Validation Accuracy:  0.949, Loss:  0.903
Epoch   6 Batch  139/153 - Train Accuracy:  0.946, Validation Accuracy:  0.952, Loss:  0.889
Epoch   6 Batch  140/153 - Train Accuracy:  0.938, Validation Accuracy:  0.949, Loss:  0.898
Epoch   6 Batch  141/153 - Train Accuracy:  0.952, Validation Accuracy:  0.947, Loss:  0.902
Epoch   6 Batch  142/153 - Train Accuracy:  0.951, Validation Accuracy:  0.950, Loss:  0.917
Epoch   6 Batch  143/153 - Train Accuracy:  0.959, Validation Accuracy:  0.950, Loss:  0.905
Epoch   6 Batch  144/153 - Train Accuracy:  0.949, Validation Accuracy:  0.953, Loss:  0.890
Epoch   6 Batch  145/153 - Train Accuracy:  0.947, Validation Accuracy:  0.954, Loss:  0.909
Epoch   6 Batch  146/153 - Train Accuracy:  0.934, Validation Accuracy:  0.953, Loss:  0.886
Epoch   6 Batch  147/153 - Train Accuracy:  0.945, Validation Accuracy:  0.951, Loss:  0.891
Epoch   6 Batch  148/153 - Train Accuracy:  0.952, Validation Accuracy:  0.951, Loss:  0.884
Epoch   6 Batch  149/153 - Train Accuracy:  0.944, Validation Accuracy:  0.948, Loss:  0.900
Epoch   6 Batch  150/153 - Train Accuracy:  0.939, Validation Accuracy:  0.956, Loss:  0.924
Epoch   6 Batch  151/153 - Train Accuracy:  0.945, Validation Accuracy:  0.956, Loss:  0.899
Epoch   7 Batch    0/153 - Train Accuracy:  0.954, Validation Accuracy:  0.957, Loss:  0.905
Epoch   7 Batch    1/153 - Train Accuracy:  0.953, Validation Accuracy:  0.949, Loss:  0.904
Epoch   7 Batch    2/153 - Train Accuracy:  0.945, Validation Accuracy:  0.953, Loss:  0.906
Epoch   7 Batch    3/153 - Train Accuracy:  0.950, Validation Accuracy:  0.955, Loss:  0.902
Epoch   7 Batch    4/153 - Train Accuracy:  0.951, Validation Accuracy:  0.952, Loss:  0.894
Epoch   7 Batch    5/153 - Train Accuracy:  0.956, Validation Accuracy:  0.954, Loss:  0.911
Epoch   7 Batch    6/153 - Train Accuracy:  0.946, Validation Accuracy:  0.948, Loss:  0.911
Epoch   7 Batch    7/153 - Train Accuracy:  0.956, Validation Accuracy:  0.959, Loss:  0.913
Epoch   7 Batch    8/153 - Train Accuracy:  0.951, Validation Accuracy:  0.951, Loss:  0.882
Epoch   7 Batch    9/153 - Train Accuracy:  0.950, Validation Accuracy:  0.951, Loss:  0.897
Epoch   7 Batch   10/153 - Train Accuracy:  0.948, Validation Accuracy:  0.946, Loss:  0.874
Epoch   7 Batch   11/153 - Train Accuracy:  0.942, Validation Accuracy:  0.958, Loss:  0.880
Epoch   7 Batch   12/153 - Train Accuracy:  0.942, Validation Accuracy:  0.949, Loss:  0.894
Epoch   7 Batch   13/153 - Train Accuracy:  0.945, Validation Accuracy:  0.951, Loss:  0.896
Epoch   7 Batch   14/153 - Train Accuracy:  0.948, Validation Accuracy:  0.953, Loss:  0.918
Epoch   7 Batch   15/153 - Train Accuracy:  0.935, Validation Accuracy:  0.940, Loss:  0.896
Epoch   7 Batch   16/153 - Train Accuracy:  0.946, Validation Accuracy:  0.949, Loss:  0.907
Epoch   7 Batch   17/153 - Train Accuracy:  0.946, Validation Accuracy:  0.940, Loss:  0.894
Epoch   7 Batch   18/153 - Train Accuracy:  0.950, Validation Accuracy:  0.946, Loss:  0.893
Epoch   7 Batch   19/153 - Train Accuracy:  0.943, Validation Accuracy:  0.950, Loss:  0.889
Epoch   7 Batch   20/153 - Train Accuracy:  0.945, Validation Accuracy:  0.955, Loss:  0.898
Epoch   7 Batch   21/153 - Train Accuracy:  0.945, Validation Accuracy:  0.950, Loss:  0.904
Epoch   7 Batch   22/153 - Train Accuracy:  0.947, Validation Accuracy:  0.956, Loss:  0.887
Epoch   7 Batch   23/153 - Train Accuracy:  0.947, Validation Accuracy:  0.956, Loss:  0.911
Epoch   7 Batch   24/153 - Train Accuracy:  0.948, Validation Accuracy:  0.958, Loss:  0.869
Epoch   7 Batch   25/153 - Train Accuracy:  0.950, Validation Accuracy:  0.953, Loss:  0.926
Epoch   7 Batch   26/153 - Train Accuracy:  0.946, Validation Accuracy:  0.951, Loss:  0.900
Epoch   7 Batch   27/153 - Train Accuracy:  0.952, Validation Accuracy:  0.955, Loss:  0.900
Epoch   7 Batch   28/153 - Train Accuracy:  0.945, Validation Accuracy:  0.952, Loss:  0.909
Epoch   7 Batch   29/153 - Train Accuracy:  0.947, Validation Accuracy:  0.959, Loss:  0.875
Epoch   7 Batch   30/153 - Train Accuracy:  0.961, Validation Accuracy:  0.956, Loss:  0.905
Epoch   7 Batch   31/153 - Train Accuracy:  0.942, Validation Accuracy:  0.950, Loss:  0.896
Epoch   7 Batch   32/153 - Train Accuracy:  0.955, Validation Accuracy:  0.957, Loss:  0.903
Epoch   7 Batch   33/153 - Train Accuracy:  0.957, Validation Accuracy:  0.957, Loss:  0.874
Epoch   7 Batch   34/153 - Train Accuracy:  0.947, Validation Accuracy:  0.957, Loss:  0.884
Epoch   7 Batch   35/153 - Train Accuracy:  0.942, Validation Accuracy:  0.957, Loss:  0.910
Epoch   7 Batch   36/153 - Train Accuracy:  0.954, Validation Accuracy:  0.954, Loss:  0.902
Epoch   7 Batch   37/153 - Train Accuracy:  0.946, Validation Accuracy:  0.952, Loss:  0.894
Epoch   7 Batch   38/153 - Train Accuracy:  0.952, Validation Accuracy:  0.953, Loss:  0.931
Epoch   7 Batch   39/153 - Train Accuracy:  0.943, Validation Accuracy:  0.946, Loss:  0.917
Epoch   7 Batch   40/153 - Train Accuracy:  0.954, Validation Accuracy:  0.954, Loss:  0.923
Epoch   7 Batch   41/153 - Train Accuracy:  0.950, Validation Accuracy:  0.950, Loss:  0.913
Epoch   7 Batch   42/153 - Train Accuracy:  0.956, Validation Accuracy:  0.957, Loss:  0.896
Epoch   7 Batch   43/153 - Train Accuracy:  0.950, Validation Accuracy:  0.956, Loss:  0.910
Epoch   7 Batch   44/153 - Train Accuracy:  0.952, Validation Accuracy:  0.952, Loss:  0.899
Epoch   7 Batch   45/153 - Train Accuracy:  0.929, Validation Accuracy:  0.940, Loss:  0.925
Epoch   7 Batch   46/153 - Train Accuracy:  0.924, Validation Accuracy:  0.927, Loss:  0.946
Epoch   7 Batch   47/153 - Train Accuracy:  0.908, Validation Accuracy:  0.929, Loss:  1.010
Epoch   7 Batch   48/153 - Train Accuracy:  0.919, Validation Accuracy:  0.931, Loss:  1.022
Epoch   7 Batch   49/153 - Train Accuracy:  0.913, Validation Accuracy:  0.917, Loss:  0.935
Epoch   7 Batch   50/153 - Train Accuracy:  0.931, Validation Accuracy:  0.926, Loss:  0.969
Epoch   7 Batch   51/153 - Train Accuracy:  0.931, Validation Accuracy:  0.913, Loss:  0.933
Epoch   7 Batch   52/153 - Train Accuracy:  0.931, Validation Accuracy:  0.926, Loss:  0.963
Epoch   7 Batch   53/153 - Train Accuracy:  0.916, Validation Accuracy:  0.920, Loss:  0.926
Epoch   7 Batch   54/153 - Train Accuracy:  0.920, Validation Accuracy:  0.917, Loss:  0.956
Epoch   7 Batch   55/153 - Train Accuracy:  0.923, Validation Accuracy:  0.918, Loss:  0.940
Epoch   7 Batch   56/153 - Train Accuracy:  0.930, Validation Accuracy:  0.935, Loss:  0.939
Epoch   7 Batch   57/153 - Train Accuracy:  0.929, Validation Accuracy:  0.934, Loss:  0.936
Epoch   7 Batch   58/153 - Train Accuracy:  0.939, Validation Accuracy:  0.936, Loss:  0.946
Epoch   7 Batch   59/153 - Train Accuracy:  0.930, Validation Accuracy:  0.939, Loss:  0.946
Epoch   7 Batch   60/153 - Train Accuracy:  0.940, Validation Accuracy:  0.933, Loss:  0.918
Epoch   7 Batch   61/153 - Train Accuracy:  0.942, Validation Accuracy:  0.935, Loss:  0.911
Epoch   7 Batch   62/153 - Train Accuracy:  0.934, Validation Accuracy:  0.937, Loss:  0.928
Epoch   7 Batch   63/153 - Train Accuracy:  0.936, Validation Accuracy:  0.941, Loss:  0.911
Epoch   7 Batch   64/153 - Train Accuracy:  0.932, Validation Accuracy:  0.943, Loss:  0.891
Epoch   7 Batch   65/153 - Train Accuracy:  0.939, Validation Accuracy:  0.943, Loss:  0.915
Epoch   7 Batch   66/153 - Train Accuracy:  0.936, Validation Accuracy:  0.947, Loss:  0.911
Epoch   7 Batch   67/153 - Train Accuracy:  0.942, Validation Accuracy:  0.946, Loss:  0.908
Epoch   7 Batch   68/153 - Train Accuracy:  0.937, Validation Accuracy:  0.950, Loss:  0.924
Epoch   7 Batch   69/153 - Train Accuracy:  0.936, Validation Accuracy:  0.951, Loss:  0.927
Epoch   7 Batch   70/153 - Train Accuracy:  0.943, Validation Accuracy:  0.953, Loss:  0.920
Epoch   7 Batch   71/153 - Train Accuracy:  0.939, Validation Accuracy:  0.953, Loss:  0.910
Epoch   7 Batch   72/153 - Train Accuracy:  0.948, Validation Accuracy:  0.953, Loss:  0.890
Epoch   7 Batch   73/153 - Train Accuracy:  0.938, Validation Accuracy:  0.950, Loss:  0.917
Epoch   7 Batch   74/153 - Train Accuracy:  0.942, Validation Accuracy:  0.951, Loss:  0.906
Epoch   7 Batch   75/153 - Train Accuracy:  0.939, Validation Accuracy:  0.949, Loss:  0.913
Epoch   7 Batch   76/153 - Train Accuracy:  0.947, Validation Accuracy:  0.946, Loss:  0.919
Epoch   7 Batch   77/153 - Train Accuracy:  0.941, Validation Accuracy:  0.950, Loss:  0.909
Epoch   7 Batch   78/153 - Train Accuracy:  0.940, Validation Accuracy:  0.954, Loss:  0.899
Epoch   7 Batch   79/153 - Train Accuracy:  0.950, Validation Accuracy:  0.954, Loss:  0.900
Epoch   7 Batch   80/153 - Train Accuracy:  0.944, Validation Accuracy:  0.953, Loss:  0.910
Epoch   7 Batch   81/153 - Train Accuracy:  0.954, Validation Accuracy:  0.953, Loss:  0.902
Epoch   7 Batch   82/153 - Train Accuracy:  0.957, Validation Accuracy:  0.953, Loss:  0.877
Epoch   7 Batch   83/153 - Train Accuracy:  0.952, Validation Accuracy:  0.953, Loss:  0.910
Epoch   7 Batch   84/153 - Train Accuracy:  0.945, Validation Accuracy:  0.951, Loss:  0.917
Epoch   7 Batch   85/153 - Train Accuracy:  0.950, Validation Accuracy:  0.955, Loss:  0.909
Epoch   7 Batch   86/153 - Train Accuracy:  0.948, Validation Accuracy:  0.962, Loss:  0.877
Epoch   7 Batch   87/153 - Train Accuracy:  0.960, Validation Accuracy:  0.960, Loss:  0.913
Epoch   7 Batch   88/153 - Train Accuracy:  0.946, Validation Accuracy:  0.957, Loss:  0.896
Epoch   7 Batch   89/153 - Train Accuracy:  0.953, Validation Accuracy:  0.960, Loss:  0.915
Epoch   7 Batch   90/153 - Train Accuracy:  0.953, Validation Accuracy:  0.960, Loss:  0.911
Epoch   7 Batch   91/153 - Train Accuracy:  0.950, Validation Accuracy:  0.959, Loss:  0.891
Epoch   7 Batch   92/153 - Train Accuracy:  0.956, Validation Accuracy:  0.955, Loss:  0.888
Epoch   7 Batch   93/153 - Train Accuracy:  0.958, Validation Accuracy:  0.958, Loss:  0.895
Epoch   7 Batch   94/153 - Train Accuracy:  0.959, Validation Accuracy:  0.958, Loss:  0.894
Epoch   7 Batch   95/153 - Train Accuracy:  0.946, Validation Accuracy:  0.959, Loss:  0.896
Epoch   7 Batch   96/153 - Train Accuracy:  0.956, Validation Accuracy:  0.959, Loss:  0.924
Epoch   7 Batch   97/153 - Train Accuracy:  0.958, Validation Accuracy:  0.956, Loss:  0.894
Epoch   7 Batch   98/153 - Train Accuracy:  0.956, Validation Accuracy:  0.955, Loss:  0.910
Epoch   7 Batch   99/153 - Train Accuracy:  0.955, Validation Accuracy:  0.955, Loss:  0.884
Epoch   7 Batch  100/153 - Train Accuracy:  0.951, Validation Accuracy:  0.955, Loss:  0.895
Epoch   7 Batch  101/153 - Train Accuracy:  0.958, Validation Accuracy:  0.960, Loss:  0.903
Epoch   7 Batch  102/153 - Train Accuracy:  0.961, Validation Accuracy:  0.961, Loss:  0.907
Epoch   7 Batch  103/153 - Train Accuracy:  0.951, Validation Accuracy:  0.960, Loss:  0.884
Epoch   7 Batch  104/153 - Train Accuracy:  0.967, Validation Accuracy:  0.959, Loss:  0.887
Epoch   7 Batch  105/153 - Train Accuracy:  0.964, Validation Accuracy:  0.959, Loss:  0.887
Epoch   7 Batch  106/153 - Train Accuracy:  0.954, Validation Accuracy:  0.962, Loss:  0.910
Epoch   7 Batch  107/153 - Train Accuracy:  0.963, Validation Accuracy:  0.962, Loss:  0.909
Epoch   7 Batch  108/153 - Train Accuracy:  0.957, Validation Accuracy:  0.962, Loss:  0.897
Epoch   7 Batch  109/153 - Train Accuracy:  0.960, Validation Accuracy:  0.960, Loss:  0.894
Epoch   7 Batch  110/153 - Train Accuracy:  0.952, Validation Accuracy:  0.960, Loss:  0.906
Epoch   7 Batch  111/153 - Train Accuracy:  0.961, Validation Accuracy:  0.962, Loss:  0.891
Epoch   7 Batch  112/153 - Train Accuracy:  0.949, Validation Accuracy:  0.964, Loss:  0.901
Epoch   7 Batch  113/153 - Train Accuracy:  0.958, Validation Accuracy:  0.965, Loss:  0.887
Epoch   7 Batch  114/153 - Train Accuracy:  0.958, Validation Accuracy:  0.964, Loss:  0.915
Epoch   7 Batch  115/153 - Train Accuracy:  0.956, Validation Accuracy:  0.961, Loss:  0.906
Epoch   7 Batch  116/153 - Train Accuracy:  0.962, Validation Accuracy:  0.960, Loss:  0.891
Epoch   7 Batch  117/153 - Train Accuracy:  0.951, Validation Accuracy:  0.962, Loss:  0.881
Epoch   7 Batch  118/153 - Train Accuracy:  0.961, Validation Accuracy:  0.959, Loss:  0.897
Epoch   7 Batch  119/153 - Train Accuracy:  0.960, Validation Accuracy:  0.956, Loss:  0.895
Epoch   7 Batch  120/153 - Train Accuracy:  0.952, Validation Accuracy:  0.959, Loss:  0.864
Epoch   7 Batch  121/153 - Train Accuracy:  0.955, Validation Accuracy:  0.963, Loss:  0.878
Epoch   7 Batch  122/153 - Train Accuracy:  0.953, Validation Accuracy:  0.966, Loss:  0.887
Epoch   7 Batch  123/153 - Train Accuracy:  0.951, Validation Accuracy:  0.965, Loss:  0.903
Epoch   7 Batch  124/153 - Train Accuracy:  0.961, Validation Accuracy:  0.964, Loss:  0.868
Epoch   7 Batch  125/153 - Train Accuracy:  0.952, Validation Accuracy:  0.964, Loss:  0.856
Epoch   7 Batch  126/153 - Train Accuracy:  0.958, Validation Accuracy:  0.962, Loss:  0.873
Epoch   7 Batch  127/153 - Train Accuracy:  0.952, Validation Accuracy:  0.959, Loss:  0.909
Epoch   7 Batch  128/153 - Train Accuracy:  0.956, Validation Accuracy:  0.960, Loss:  0.885
Epoch   7 Batch  129/153 - Train Accuracy:  0.958, Validation Accuracy:  0.959, Loss:  0.895
Epoch   7 Batch  130/153 - Train Accuracy:  0.961, Validation Accuracy:  0.958, Loss:  0.886
Epoch   7 Batch  131/153 - Train Accuracy:  0.962, Validation Accuracy:  0.961, Loss:  0.874
Epoch   7 Batch  132/153 - Train Accuracy:  0.950, Validation Accuracy:  0.964, Loss:  0.863
Epoch   7 Batch  133/153 - Train Accuracy:  0.963, Validation Accuracy:  0.959, Loss:  0.890
Epoch   7 Batch  134/153 - Train Accuracy:  0.964, Validation Accuracy:  0.960, Loss:  0.865
Epoch   7 Batch  135/153 - Train Accuracy:  0.966, Validation Accuracy:  0.961, Loss:  0.892
Epoch   7 Batch  136/153 - Train Accuracy:  0.963, Validation Accuracy:  0.960, Loss:  0.891
Epoch   7 Batch  137/153 - Train Accuracy:  0.961, Validation Accuracy:  0.962, Loss:  0.906
Epoch   7 Batch  138/153 - Train Accuracy:  0.959, Validation Accuracy:  0.965, Loss:  0.902
Epoch   7 Batch  139/153 - Train Accuracy:  0.950, Validation Accuracy:  0.960, Loss:  0.869
Epoch   7 Batch  140/153 - Train Accuracy:  0.949, Validation Accuracy:  0.960, Loss:  0.894
Epoch   7 Batch  141/153 - Train Accuracy:  0.964, Validation Accuracy:  0.961, Loss:  0.894
Epoch   7 Batch  142/153 - Train Accuracy:  0.964, Validation Accuracy:  0.963, Loss:  0.860
Epoch   7 Batch  143/153 - Train Accuracy:  0.969, Validation Accuracy:  0.964, Loss:  0.895
Epoch   7 Batch  144/153 - Train Accuracy:  0.956, Validation Accuracy:  0.965, Loss:  0.903
Epoch   7 Batch  145/153 - Train Accuracy:  0.957, Validation Accuracy:  0.965, Loss:  0.894
Epoch   7 Batch  146/153 - Train Accuracy:  0.949, Validation Accuracy:  0.960, Loss:  0.891
Epoch   7 Batch  147/153 - Train Accuracy:  0.961, Validation Accuracy:  0.958, Loss:  0.899
Epoch   7 Batch  148/153 - Train Accuracy:  0.961, Validation Accuracy:  0.955, Loss:  0.895
Epoch   7 Batch  149/153 - Train Accuracy:  0.951, Validation Accuracy:  0.958, Loss:  0.900
Epoch   7 Batch  150/153 - Train Accuracy:  0.951, Validation Accuracy:  0.962, Loss:  0.867
Epoch   7 Batch  151/153 - Train Accuracy:  0.957, Validation Accuracy:  0.958, Loss:  0.874
Epoch   8 Batch    0/153 - Train Accuracy:  0.964, Validation Accuracy:  0.965, Loss:  0.909
Epoch   8 Batch    1/153 - Train Accuracy:  0.959, Validation Accuracy:  0.961, Loss:  0.919
Epoch   8 Batch    2/153 - Train Accuracy:  0.955, Validation Accuracy:  0.957, Loss:  0.875
Epoch   8 Batch    3/153 - Train Accuracy:  0.958, Validation Accuracy:  0.963, Loss:  0.894
Epoch   8 Batch    4/153 - Train Accuracy:  0.960, Validation Accuracy:  0.961, Loss:  0.909
Epoch   8 Batch    5/153 - Train Accuracy:  0.963, Validation Accuracy:  0.962, Loss:  0.875
Epoch   8 Batch    6/153 - Train Accuracy:  0.956, Validation Accuracy:  0.963, Loss:  0.908
Epoch   8 Batch    7/153 - Train Accuracy:  0.964, Validation Accuracy:  0.957, Loss:  0.905
Epoch   8 Batch    8/153 - Train Accuracy:  0.965, Validation Accuracy:  0.960, Loss:  0.892
Epoch   8 Batch    9/153 - Train Accuracy:  0.960, Validation Accuracy:  0.963, Loss:  0.877
Epoch   8 Batch   10/153 - Train Accuracy:  0.962, Validation Accuracy:  0.968, Loss:  0.880
Epoch   8 Batch   11/153 - Train Accuracy:  0.959, Validation Accuracy:  0.971, Loss:  0.880
Epoch   8 Batch   12/153 - Train Accuracy:  0.963, Validation Accuracy:  0.967, Loss:  0.876
Epoch   8 Batch   13/153 - Train Accuracy:  0.954, Validation Accuracy:  0.964, Loss:  0.886
Epoch   8 Batch   14/153 - Train Accuracy:  0.959, Validation Accuracy:  0.963, Loss:  0.876
Epoch   8 Batch   15/153 - Train Accuracy:  0.958, Validation Accuracy:  0.960, Loss:  0.897
Epoch   8 Batch   16/153 - Train Accuracy:  0.959, Validation Accuracy:  0.963, Loss:  0.893
Epoch   8 Batch   17/153 - Train Accuracy:  0.959, Validation Accuracy:  0.952, Loss:  0.895
Epoch   8 Batch   18/153 - Train Accuracy:  0.964, Validation Accuracy:  0.955, Loss:  0.883
Epoch   8 Batch   19/153 - Train Accuracy:  0.966, Validation Accuracy:  0.961, Loss:  0.878
Epoch   8 Batch   20/153 - Train Accuracy:  0.958, Validation Accuracy:  0.963, Loss:  0.904
Epoch   8 Batch   21/153 - Train Accuracy:  0.960, Validation Accuracy:  0.963, Loss:  0.907
Epoch   8 Batch   22/153 - Train Accuracy:  0.960, Validation Accuracy:  0.962, Loss:  0.853
Epoch   8 Batch   23/153 - Train Accuracy:  0.960, Validation Accuracy:  0.960, Loss:  0.895
Epoch   8 Batch   24/153 - Train Accuracy:  0.955, Validation Accuracy:  0.957, Loss:  0.884
Epoch   8 Batch   25/153 - Train Accuracy:  0.958, Validation Accuracy:  0.961, Loss:  0.864
Epoch   8 Batch   26/153 - Train Accuracy:  0.959, Validation Accuracy:  0.963, Loss:  0.881
Epoch   8 Batch   27/153 - Train Accuracy:  0.963, Validation Accuracy:  0.961, Loss:  0.898
Epoch   8 Batch   28/153 - Train Accuracy:  0.955, Validation Accuracy:  0.960, Loss:  0.905
Epoch   8 Batch   29/153 - Train Accuracy:  0.960, Validation Accuracy:  0.964, Loss:  0.888
Epoch   8 Batch   30/153 - Train Accuracy:  0.969, Validation Accuracy:  0.960, Loss:  0.902
Epoch   8 Batch   31/153 - Train Accuracy:  0.955, Validation Accuracy:  0.956, Loss:  0.890
Epoch   8 Batch   32/153 - Train Accuracy:  0.963, Validation Accuracy:  0.957, Loss:  0.892
Epoch   8 Batch   33/153 - Train Accuracy:  0.968, Validation Accuracy:  0.958, Loss:  0.893
Epoch   8 Batch   34/153 - Train Accuracy:  0.956, Validation Accuracy:  0.964, Loss:  0.898
Epoch   8 Batch   35/153 - Train Accuracy:  0.958, Validation Accuracy:  0.965, Loss:  0.887
Epoch   8 Batch   36/153 - Train Accuracy:  0.961, Validation Accuracy:  0.964, Loss:  0.871
Epoch   8 Batch   37/153 - Train Accuracy:  0.958, Validation Accuracy:  0.961, Loss:  0.885
Epoch   8 Batch   38/153 - Train Accuracy:  0.958, Validation Accuracy:  0.962, Loss:  0.860
Epoch   8 Batch   39/153 - Train Accuracy:  0.958, Validation Accuracy:  0.958, Loss:  0.893
Epoch   8 Batch   40/153 - Train Accuracy:  0.962, Validation Accuracy:  0.957, Loss:  0.909
Epoch   8 Batch   41/153 - Train Accuracy:  0.955, Validation Accuracy:  0.959, Loss:  0.874
Epoch   8 Batch   42/153 - Train Accuracy:  0.965, Validation Accuracy:  0.960, Loss:  0.891
Epoch   8 Batch   43/153 - Train Accuracy:  0.962, Validation Accuracy:  0.959, Loss:  0.882
Epoch   8 Batch   44/153 - Train Accuracy:  0.958, Validation Accuracy:  0.958, Loss:  0.877
Epoch   8 Batch   45/153 - Train Accuracy:  0.958, Validation Accuracy:  0.963, Loss:  0.895
Epoch   8 Batch   46/153 - Train Accuracy:  0.966, Validation Accuracy:  0.968, Loss:  0.889
Epoch   8 Batch   47/153 - Train Accuracy:  0.955, Validation Accuracy:  0.965, Loss:  0.914
Epoch   8 Batch   48/153 - Train Accuracy:  0.956, Validation Accuracy:  0.961, Loss:  0.897
Epoch   8 Batch   49/153 - Train Accuracy:  0.967, Validation Accuracy:  0.955, Loss:  0.893
Epoch   8 Batch   50/153 - Train Accuracy:  0.954, Validation Accuracy:  0.955, Loss:  0.871
Epoch   8 Batch   51/153 - Train Accuracy:  0.971, Validation Accuracy:  0.956, Loss:  0.910
Epoch   8 Batch   52/153 - Train Accuracy:  0.968, Validation Accuracy:  0.958, Loss:  0.884
Epoch   8 Batch   53/153 - Train Accuracy:  0.963, Validation Accuracy:  0.959, Loss:  0.897
Epoch   8 Batch   54/153 - Train Accuracy:  0.962, Validation Accuracy:  0.962, Loss:  0.880
Epoch   8 Batch   55/153 - Train Accuracy:  0.962, Validation Accuracy:  0.962, Loss:  0.907
Epoch   8 Batch   56/153 - Train Accuracy:  0.960, Validation Accuracy:  0.960, Loss:  0.864
Epoch   8 Batch   57/153 - Train Accuracy:  0.958, Validation Accuracy:  0.955, Loss:  0.882
Epoch   8 Batch   58/153 - Train Accuracy:  0.961, Validation Accuracy:  0.961, Loss:  0.900
Epoch   8 Batch   59/153 - Train Accuracy:  0.958, Validation Accuracy:  0.964, Loss:  0.888
Epoch   8 Batch   60/153 - Train Accuracy:  0.969, Validation Accuracy:  0.966, Loss:  0.891
Epoch   8 Batch   61/153 - Train Accuracy:  0.965, Validation Accuracy:  0.965, Loss:  0.895
Epoch   8 Batch   62/153 - Train Accuracy:  0.957, Validation Accuracy:  0.963, Loss:  0.885
Epoch   8 Batch   63/153 - Train Accuracy:  0.967, Validation Accuracy:  0.962, Loss:  0.922
Epoch   8 Batch   64/153 - Train Accuracy:  0.956, Validation Accuracy:  0.963, Loss:  0.912
Epoch   8 Batch   65/153 - Train Accuracy:  0.962, Validation Accuracy:  0.965, Loss:  0.896
Epoch   8 Batch   66/153 - Train Accuracy:  0.961, Validation Accuracy:  0.964, Loss:  0.873
Epoch   8 Batch   67/153 - Train Accuracy:  0.962, Validation Accuracy:  0.964, Loss:  0.863
Epoch   8 Batch   68/153 - Train Accuracy:  0.963, Validation Accuracy:  0.968, Loss:  0.877
Epoch   8 Batch   69/153 - Train Accuracy:  0.951, Validation Accuracy:  0.965, Loss:  0.878
Epoch   8 Batch   70/153 - Train Accuracy:  0.966, Validation Accuracy:  0.967, Loss:  0.876
Epoch   8 Batch   71/153 - Train Accuracy:  0.958, Validation Accuracy:  0.964, Loss:  0.871
Epoch   8 Batch   72/153 - Train Accuracy:  0.969, Validation Accuracy:  0.964, Loss:  0.874
Epoch   8 Batch   73/153 - Train Accuracy:  0.960, Validation Accuracy:  0.963, Loss:  0.902
Epoch   8 Batch   74/153 - Train Accuracy:  0.958, Validation Accuracy:  0.964, Loss:  0.871
Epoch   8 Batch   75/153 - Train Accuracy:  0.960, Validation Accuracy:  0.966, Loss:  0.877
Epoch   8 Batch   76/153 - Train Accuracy:  0.969, Validation Accuracy:  0.967, Loss:  0.881
Epoch   8 Batch   77/153 - Train Accuracy:  0.956, Validation Accuracy:  0.968, Loss:  0.887
Epoch   8 Batch   78/153 - Train Accuracy:  0.969, Validation Accuracy:  0.966, Loss:  0.895
Epoch   8 Batch   79/153 - Train Accuracy:  0.967, Validation Accuracy:  0.967, Loss:  0.886
Epoch   8 Batch   80/153 - Train Accuracy:  0.964, Validation Accuracy:  0.970, Loss:  0.863
Epoch   8 Batch   81/153 - Train Accuracy:  0.964, Validation Accuracy:  0.968, Loss:  0.893
Epoch   8 Batch   82/153 - Train Accuracy:  0.974, Validation Accuracy:  0.971, Loss:  0.884
Epoch   8 Batch   83/153 - Train Accuracy:  0.961, Validation Accuracy:  0.967, Loss:  0.891
Epoch   8 Batch   84/153 - Train Accuracy:  0.963, Validation Accuracy:  0.966, Loss:  0.892
Epoch   8 Batch   85/153 - Train Accuracy:  0.965, Validation Accuracy:  0.965, Loss:  0.862
Epoch   8 Batch   86/153 - Train Accuracy:  0.963, Validation Accuracy:  0.966, Loss:  0.912
Epoch   8 Batch   87/153 - Train Accuracy:  0.973, Validation Accuracy:  0.970, Loss:  0.903
Epoch   8 Batch   88/153 - Train Accuracy:  0.960, Validation Accuracy:  0.968, Loss:  0.895
Epoch   8 Batch   89/153 - Train Accuracy:  0.962, Validation Accuracy:  0.972, Loss:  0.904
Epoch   8 Batch   90/153 - Train Accuracy:  0.964, Validation Accuracy:  0.970, Loss:  0.876
Epoch   8 Batch   91/153 - Train Accuracy:  0.966, Validation Accuracy:  0.968, Loss:  0.890
Epoch   8 Batch   92/153 - Train Accuracy:  0.971, Validation Accuracy:  0.967, Loss:  0.865
Epoch   8 Batch   93/153 - Train Accuracy:  0.972, Validation Accuracy:  0.966, Loss:  0.879
Epoch   8 Batch   94/153 - Train Accuracy:  0.968, Validation Accuracy:  0.965, Loss:  0.895
Epoch   8 Batch   95/153 - Train Accuracy:  0.961, Validation Accuracy:  0.966, Loss:  0.898
Epoch   8 Batch   96/153 - Train Accuracy:  0.967, Validation Accuracy:  0.968, Loss:  0.889
Epoch   8 Batch   97/153 - Train Accuracy:  0.966, Validation Accuracy:  0.968, Loss:  0.901
Epoch   8 Batch   98/153 - Train Accuracy:  0.967, Validation Accuracy:  0.969, Loss:  0.866
Epoch   8 Batch   99/153 - Train Accuracy:  0.965, Validation Accuracy:  0.967, Loss:  0.905
Epoch   8 Batch  100/153 - Train Accuracy:  0.962, Validation Accuracy:  0.968, Loss:  0.895
Epoch   8 Batch  101/153 - Train Accuracy:  0.964, Validation Accuracy:  0.967, Loss:  0.880
Epoch   8 Batch  102/153 - Train Accuracy:  0.965, Validation Accuracy:  0.962, Loss:  0.892
Epoch   8 Batch  103/153 - Train Accuracy:  0.962, Validation Accuracy:  0.966, Loss:  0.873
Epoch   8 Batch  104/153 - Train Accuracy:  0.971, Validation Accuracy:  0.964, Loss:  0.871
Epoch   8 Batch  105/153 - Train Accuracy:  0.968, Validation Accuracy:  0.964, Loss:  0.880
Epoch   8 Batch  106/153 - Train Accuracy:  0.962, Validation Accuracy:  0.968, Loss:  0.880
Epoch   8 Batch  107/153 - Train Accuracy:  0.969, Validation Accuracy:  0.969, Loss:  0.904
Epoch   8 Batch  108/153 - Train Accuracy:  0.963, Validation Accuracy:  0.969, Loss:  0.875
Epoch   8 Batch  109/153 - Train Accuracy:  0.966, Validation Accuracy:  0.970, Loss:  0.892
Epoch   8 Batch  110/153 - Train Accuracy:  0.959, Validation Accuracy:  0.967, Loss:  0.872
Epoch   8 Batch  111/153 - Train Accuracy:  0.967, Validation Accuracy:  0.966, Loss:  0.880
Epoch   8 Batch  112/153 - Train Accuracy:  0.966, Validation Accuracy:  0.966, Loss:  0.890
Epoch   8 Batch  113/153 - Train Accuracy:  0.972, Validation Accuracy:  0.965, Loss:  0.889
Epoch   8 Batch  114/153 - Train Accuracy:  0.966, Validation Accuracy:  0.967, Loss:  0.882
Epoch   8 Batch  115/153 - Train Accuracy:  0.965, Validation Accuracy:  0.964, Loss:  0.896
Epoch   8 Batch  116/153 - Train Accuracy:  0.971, Validation Accuracy:  0.965, Loss:  0.896
Epoch   8 Batch  117/153 - Train Accuracy:  0.959, Validation Accuracy:  0.964, Loss:  0.887
Epoch   8 Batch  118/153 - Train Accuracy:  0.967, Validation Accuracy:  0.967, Loss:  0.869
Epoch   8 Batch  119/153 - Train Accuracy:  0.971, Validation Accuracy:  0.970, Loss:  0.902
Epoch   8 Batch  120/153 - Train Accuracy:  0.958, Validation Accuracy:  0.970, Loss:  0.904
Epoch   8 Batch  121/153 - Train Accuracy:  0.962, Validation Accuracy:  0.967, Loss:  0.882
Epoch   8 Batch  122/153 - Train Accuracy:  0.961, Validation Accuracy:  0.968, Loss:  0.860
Epoch   8 Batch  123/153 - Train Accuracy:  0.958, Validation Accuracy:  0.966, Loss:  0.881
Epoch   8 Batch  124/153 - Train Accuracy:  0.973, Validation Accuracy:  0.967, Loss:  0.883
Epoch   8 Batch  125/153 - Train Accuracy:  0.963, Validation Accuracy:  0.966, Loss:  0.890
Epoch   8 Batch  126/153 - Train Accuracy:  0.968, Validation Accuracy:  0.966, Loss:  0.876
Epoch   8 Batch  127/153 - Train Accuracy:  0.968, Validation Accuracy:  0.965, Loss:  0.871
Epoch   8 Batch  128/153 - Train Accuracy:  0.968, Validation Accuracy:  0.959, Loss:  0.879
Epoch   8 Batch  129/153 - Train Accuracy:  0.962, Validation Accuracy:  0.961, Loss:  0.869
Epoch   8 Batch  130/153 - Train Accuracy:  0.974, Validation Accuracy:  0.964, Loss:  0.861
Epoch   8 Batch  131/153 - Train Accuracy:  0.966, Validation Accuracy:  0.967, Loss:  0.886
Epoch   8 Batch  132/153 - Train Accuracy:  0.968, Validation Accuracy:  0.969, Loss:  0.885
Epoch   8 Batch  133/153 - Train Accuracy:  0.971, Validation Accuracy:  0.968, Loss:  0.891
Epoch   8 Batch  134/153 - Train Accuracy:  0.974, Validation Accuracy:  0.968, Loss:  0.860
Epoch   8 Batch  135/153 - Train Accuracy:  0.973, Validation Accuracy:  0.965, Loss:  0.885
Epoch   8 Batch  136/153 - Train Accuracy:  0.968, Validation Accuracy:  0.966, Loss:  0.886
Epoch   8 Batch  137/153 - Train Accuracy:  0.965, Validation Accuracy:  0.965, Loss:  0.886
Epoch   8 Batch  138/153 - Train Accuracy:  0.969, Validation Accuracy:  0.970, Loss:  0.882
Epoch   8 Batch  139/153 - Train Accuracy:  0.961, Validation Accuracy:  0.970, Loss:  0.899
Epoch   8 Batch  140/153 - Train Accuracy:  0.964, Validation Accuracy:  0.967, Loss:  0.904
Epoch   8 Batch  141/153 - Train Accuracy:  0.974, Validation Accuracy:  0.968, Loss:  0.877
Epoch   8 Batch  142/153 - Train Accuracy:  0.969, Validation Accuracy:  0.970, Loss:  0.881
Epoch   8 Batch  143/153 - Train Accuracy:  0.976, Validation Accuracy:  0.970, Loss:  0.867
Epoch   8 Batch  144/153 - Train Accuracy:  0.966, Validation Accuracy:  0.968, Loss:  0.871
Epoch   8 Batch  145/153 - Train Accuracy:  0.965, Validation Accuracy:  0.966, Loss:  0.878
Epoch   8 Batch  146/153 - Train Accuracy:  0.964, Validation Accuracy:  0.960, Loss:  0.919
Epoch   8 Batch  147/153 - Train Accuracy:  0.968, Validation Accuracy:  0.965, Loss:  0.876
Epoch   8 Batch  148/153 - Train Accuracy:  0.969, Validation Accuracy:  0.968, Loss:  0.888
Epoch   8 Batch  149/153 - Train Accuracy:  0.963, Validation Accuracy:  0.972, Loss:  0.865
Epoch   8 Batch  150/153 - Train Accuracy:  0.959, Validation Accuracy:  0.971, Loss:  0.892
Epoch   8 Batch  151/153 - Train Accuracy:  0.967, Validation Accuracy:  0.971, Loss:  0.889
Epoch   9 Batch    0/153 - Train Accuracy:  0.970, Validation Accuracy:  0.970, Loss:  0.886
Epoch   9 Batch    1/153 - Train Accuracy:  0.962, Validation Accuracy:  0.966, Loss:  0.857
Epoch   9 Batch    2/153 - Train Accuracy:  0.958, Validation Accuracy:  0.963, Loss:  0.878
Epoch   9 Batch    3/153 - Train Accuracy:  0.968, Validation Accuracy:  0.970, Loss:  0.898
Epoch   9 Batch    4/153 - Train Accuracy:  0.963, Validation Accuracy:  0.968, Loss:  0.894
Epoch   9 Batch    5/153 - Train Accuracy:  0.972, Validation Accuracy:  0.969, Loss:  0.861
Epoch   9 Batch    6/153 - Train Accuracy:  0.966, Validation Accuracy:  0.964, Loss:  0.891
Epoch   9 Batch    7/153 - Train Accuracy:  0.968, Validation Accuracy:  0.969, Loss:  0.871
Epoch   9 Batch    8/153 - Train Accuracy:  0.968, Validation Accuracy:  0.967, Loss:  0.869
Epoch   9 Batch    9/153 - Train Accuracy:  0.967, Validation Accuracy:  0.964, Loss:  0.882
Epoch   9 Batch   10/153 - Train Accuracy:  0.963, Validation Accuracy:  0.964, Loss:  0.878
Epoch   9 Batch   11/153 - Train Accuracy:  0.959, Validation Accuracy:  0.964, Loss:  0.885
Epoch   9 Batch   12/153 - Train Accuracy:  0.972, Validation Accuracy:  0.967, Loss:  0.875
Epoch   9 Batch   13/153 - Train Accuracy:  0.962, Validation Accuracy:  0.966, Loss:  0.865
Epoch   9 Batch   14/153 - Train Accuracy:  0.966, Validation Accuracy:  0.966, Loss:  0.861
Epoch   9 Batch   15/153 - Train Accuracy:  0.963, Validation Accuracy:  0.966, Loss:  0.896
Epoch   9 Batch   16/153 - Train Accuracy:  0.965, Validation Accuracy:  0.963, Loss:  0.898
Epoch   9 Batch   17/153 - Train Accuracy:  0.966, Validation Accuracy:  0.962, Loss:  0.911
Epoch   9 Batch   18/153 - Train Accuracy:  0.971, Validation Accuracy:  0.965, Loss:  0.867
Epoch   9 Batch   19/153 - Train Accuracy:  0.971, Validation Accuracy:  0.967, Loss:  0.875
Epoch   9 Batch   20/153 - Train Accuracy:  0.967, Validation Accuracy:  0.971, Loss:  0.901
Epoch   9 Batch   21/153 - Train Accuracy:  0.967, Validation Accuracy:  0.970, Loss:  0.859
Epoch   9 Batch   22/153 - Train Accuracy:  0.965, Validation Accuracy:  0.967, Loss:  0.866
Epoch   9 Batch   23/153 - Train Accuracy:  0.967, Validation Accuracy:  0.963, Loss:  0.881
Epoch   9 Batch   24/153 - Train Accuracy:  0.964, Validation Accuracy:  0.965, Loss:  0.880
Epoch   9 Batch   25/153 - Train Accuracy:  0.966, Validation Accuracy:  0.963, Loss:  0.897
Epoch   9 Batch   26/153 - Train Accuracy:  0.966, Validation Accuracy:  0.965, Loss:  0.887
Epoch   9 Batch   27/153 - Train Accuracy:  0.963, Validation Accuracy:  0.962, Loss:  0.876
Epoch   9 Batch   28/153 - Train Accuracy:  0.962, Validation Accuracy:  0.965, Loss:  0.860
Epoch   9 Batch   29/153 - Train Accuracy:  0.965, Validation Accuracy:  0.964, Loss:  0.883
Epoch   9 Batch   30/153 - Train Accuracy:  0.973, Validation Accuracy:  0.963, Loss:  0.868
Epoch   9 Batch   31/153 - Train Accuracy:  0.960, Validation Accuracy:  0.962, Loss:  0.879
Epoch   9 Batch   32/153 - Train Accuracy:  0.971, Validation Accuracy:  0.967, Loss:  0.887
Epoch   9 Batch   33/153 - Train Accuracy:  0.972, Validation Accuracy:  0.970, Loss:  0.894
Epoch   9 Batch   34/153 - Train Accuracy:  0.961, Validation Accuracy:  0.968, Loss:  0.900
Epoch   9 Batch   35/153 - Train Accuracy:  0.963, Validation Accuracy:  0.964, Loss:  0.864
Epoch   9 Batch   36/153 - Train Accuracy:  0.971, Validation Accuracy:  0.964, Loss:  0.886
Epoch   9 Batch   37/153 - Train Accuracy:  0.970, Validation Accuracy:  0.961, Loss:  0.887
Epoch   9 Batch   38/153 - Train Accuracy:  0.966, Validation Accuracy:  0.962, Loss:  0.892
Epoch   9 Batch   39/153 - Train Accuracy:  0.963, Validation Accuracy:  0.958, Loss:  0.900
Epoch   9 Batch   40/153 - Train Accuracy:  0.965, Validation Accuracy:  0.955, Loss:  0.910
Epoch   9 Batch   41/153 - Train Accuracy:  0.966, Validation Accuracy:  0.958, Loss:  0.889
Epoch   9 Batch   42/153 - Train Accuracy:  0.964, Validation Accuracy:  0.961, Loss:  0.901
Epoch   9 Batch   43/153 - Train Accuracy:  0.962, Validation Accuracy:  0.960, Loss:  0.886
Epoch   9 Batch   44/153 - Train Accuracy:  0.971, Validation Accuracy:  0.964, Loss:  0.877
Epoch   9 Batch   45/153 - Train Accuracy:  0.966, Validation Accuracy:  0.964, Loss:  0.877
Epoch   9 Batch   46/153 - Train Accuracy:  0.967, Validation Accuracy:  0.961, Loss:  0.883
Epoch   9 Batch   47/153 - Train Accuracy:  0.958, Validation Accuracy:  0.962, Loss:  0.896
Epoch   9 Batch   48/153 - Train Accuracy:  0.961, Validation Accuracy:  0.965, Loss:  0.901
Epoch   9 Batch   49/153 - Train Accuracy:  0.969, Validation Accuracy:  0.957, Loss:  0.895
Epoch   9 Batch   50/153 - Train Accuracy:  0.965, Validation Accuracy:  0.960, Loss:  0.858
Epoch   9 Batch   51/153 - Train Accuracy:  0.973, Validation Accuracy:  0.958, Loss:  0.884
Epoch   9 Batch   52/153 - Train Accuracy:  0.966, Validation Accuracy:  0.958, Loss:  0.863
Epoch   9 Batch   53/153 - Train Accuracy:  0.965, Validation Accuracy:  0.964, Loss:  0.896
Epoch   9 Batch   54/153 - Train Accuracy:  0.962, Validation Accuracy:  0.961, Loss:  0.876
Epoch   9 Batch   55/153 - Train Accuracy:  0.965, Validation Accuracy:  0.963, Loss:  0.902
Epoch   9 Batch   56/153 - Train Accuracy:  0.968, Validation Accuracy:  0.964, Loss:  0.867
Epoch   9 Batch   57/153 - Train Accuracy:  0.963, Validation Accuracy:  0.963, Loss:  0.885
Epoch   9 Batch   58/153 - Train Accuracy:  0.968, Validation Accuracy:  0.963, Loss:  0.897
Epoch   9 Batch   59/153 - Train Accuracy:  0.959, Validation Accuracy:  0.967, Loss:  0.895
Epoch   9 Batch   60/153 - Train Accuracy:  0.969, Validation Accuracy:  0.971, Loss:  0.891
Epoch   9 Batch   61/153 - Train Accuracy:  0.965, Validation Accuracy:  0.965, Loss:  0.878
Epoch   9 Batch   62/153 - Train Accuracy:  0.964, Validation Accuracy:  0.965, Loss:  0.883
Epoch   9 Batch   63/153 - Train Accuracy:  0.966, Validation Accuracy:  0.968, Loss:  0.883
Epoch   9 Batch   64/153 - Train Accuracy:  0.961, Validation Accuracy:  0.964, Loss:  0.873
Epoch   9 Batch   65/153 - Train Accuracy:  0.970, Validation Accuracy:  0.965, Loss:  0.896
Epoch   9 Batch   66/153 - Train Accuracy:  0.964, Validation Accuracy:  0.962, Loss:  0.862
Epoch   9 Batch   67/153 - Train Accuracy:  0.959, Validation Accuracy:  0.961, Loss:  0.885
Epoch   9 Batch   68/153 - Train Accuracy:  0.968, Validation Accuracy:  0.964, Loss:  0.889
Epoch   9 Batch   69/153 - Train Accuracy:  0.960, Validation Accuracy:  0.969, Loss:  0.871
Epoch   9 Batch   70/153 - Train Accuracy:  0.970, Validation Accuracy:  0.970, Loss:  0.881
Epoch   9 Batch   71/153 - Train Accuracy:  0.959, Validation Accuracy:  0.971, Loss:  0.893
Epoch   9 Batch   72/153 - Train Accuracy:  0.970, Validation Accuracy:  0.969, Loss:  0.876
Epoch   9 Batch   73/153 - Train Accuracy:  0.964, Validation Accuracy:  0.968, Loss:  0.876
Epoch   9 Batch   74/153 - Train Accuracy:  0.964, Validation Accuracy:  0.973, Loss:  0.900
Epoch   9 Batch   75/153 - Train Accuracy:  0.963, Validation Accuracy:  0.973, Loss:  0.889
Epoch   9 Batch   76/153 - Train Accuracy:  0.974, Validation Accuracy:  0.974, Loss:  0.874
Epoch   9 Batch   77/153 - Train Accuracy:  0.962, Validation Accuracy:  0.971, Loss:  0.869
Epoch   9 Batch   78/153 - Train Accuracy:  0.972, Validation Accuracy:  0.968, Loss:  0.899
Epoch   9 Batch   79/153 - Train Accuracy:  0.972, Validation Accuracy:  0.971, Loss:  0.872
Epoch   9 Batch   80/153 - Train Accuracy:  0.972, Validation Accuracy:  0.973, Loss:  0.882
Epoch   9 Batch   81/153 - Train Accuracy:  0.970, Validation Accuracy:  0.970, Loss:  0.884
Epoch   9 Batch   82/153 - Train Accuracy:  0.973, Validation Accuracy:  0.972, Loss:  0.854
Epoch   9 Batch   83/153 - Train Accuracy:  0.970, Validation Accuracy:  0.971, Loss:  0.896
Epoch   9 Batch   84/153 - Train Accuracy:  0.969, Validation Accuracy:  0.974, Loss:  0.893
Epoch   9 Batch   85/153 - Train Accuracy:  0.973, Validation Accuracy:  0.973, Loss:  0.870
Epoch   9 Batch   86/153 - Train Accuracy:  0.971, Validation Accuracy:  0.971, Loss:  0.867
Epoch   9 Batch   87/153 - Train Accuracy:  0.976, Validation Accuracy:  0.969, Loss:  0.857
Epoch   9 Batch   88/153 - Train Accuracy:  0.964, Validation Accuracy:  0.971, Loss:  0.881
Epoch   9 Batch   89/153 - Train Accuracy:  0.968, Validation Accuracy:  0.973, Loss:  0.868
Epoch   9 Batch   90/153 - Train Accuracy:  0.971, Validation Accuracy:  0.974, Loss:  0.893
Epoch   9 Batch   91/153 - Train Accuracy:  0.976, Validation Accuracy:  0.973, Loss:  0.878
Epoch   9 Batch   92/153 - Train Accuracy:  0.974, Validation Accuracy:  0.973, Loss:  0.861
Epoch   9 Batch   93/153 - Train Accuracy:  0.980, Validation Accuracy:  0.973, Loss:  0.865
Epoch   9 Batch   94/153 - Train Accuracy:  0.976, Validation Accuracy:  0.972, Loss:  0.887
Epoch   9 Batch   95/153 - Train Accuracy:  0.961, Validation Accuracy:  0.970, Loss:  0.878
Epoch   9 Batch   96/153 - Train Accuracy:  0.970, Validation Accuracy:  0.968, Loss:  0.862
Epoch   9 Batch   97/153 - Train Accuracy:  0.969, Validation Accuracy:  0.970, Loss:  0.868
Epoch   9 Batch   98/153 - Train Accuracy:  0.968, Validation Accuracy:  0.968, Loss:  0.890
Epoch   9 Batch   99/153 - Train Accuracy:  0.968, Validation Accuracy:  0.962, Loss:  0.857
Epoch   9 Batch  100/153 - Train Accuracy:  0.970, Validation Accuracy:  0.965, Loss:  0.894
Epoch   9 Batch  101/153 - Train Accuracy:  0.970, Validation Accuracy:  0.962, Loss:  0.888
Epoch   9 Batch  102/153 - Train Accuracy:  0.967, Validation Accuracy:  0.963, Loss:  0.886
Epoch   9 Batch  103/153 - Train Accuracy:  0.964, Validation Accuracy:  0.965, Loss:  0.861
Epoch   9 Batch  104/153 - Train Accuracy:  0.974, Validation Accuracy:  0.966, Loss:  0.867
Epoch   9 Batch  105/153 - Train Accuracy:  0.979, Validation Accuracy:  0.965, Loss:  0.877
Epoch   9 Batch  106/153 - Train Accuracy:  0.971, Validation Accuracy:  0.971, Loss:  0.868
Epoch   9 Batch  107/153 - Train Accuracy:  0.972, Validation Accuracy:  0.970, Loss:  0.880
Epoch   9 Batch  108/153 - Train Accuracy:  0.972, Validation Accuracy:  0.970, Loss:  0.888
Epoch   9 Batch  109/153 - Train Accuracy:  0.970, Validation Accuracy:  0.975, Loss:  0.889
Epoch   9 Batch  110/153 - Train Accuracy:  0.964, Validation Accuracy:  0.973, Loss:  0.852
Epoch   9 Batch  111/153 - Train Accuracy:  0.971, Validation Accuracy:  0.972, Loss:  0.890
Epoch   9 Batch  112/153 - Train Accuracy:  0.969, Validation Accuracy:  0.974, Loss:  0.873
Epoch   9 Batch  113/153 - Train Accuracy:  0.971, Validation Accuracy:  0.975, Loss:  0.868
Epoch   9 Batch  114/153 - Train Accuracy:  0.968, Validation Accuracy:  0.975, Loss:  0.880
Epoch   9 Batch  115/153 - Train Accuracy:  0.970, Validation Accuracy:  0.972, Loss:  0.885
Epoch   9 Batch  116/153 - Train Accuracy:  0.976, Validation Accuracy:  0.971, Loss:  0.887
Epoch   9 Batch  117/153 - Train Accuracy:  0.965, Validation Accuracy:  0.975, Loss:  0.878
Epoch   9 Batch  118/153 - Train Accuracy:  0.974, Validation Accuracy:  0.975, Loss:  0.885
Epoch   9 Batch  119/153 - Train Accuracy:  0.974, Validation Accuracy:  0.974, Loss:  0.873
Epoch   9 Batch  120/153 - Train Accuracy:  0.970, Validation Accuracy:  0.975, Loss:  0.880
Epoch   9 Batch  121/153 - Train Accuracy:  0.971, Validation Accuracy:  0.974, Loss:  0.875
Epoch   9 Batch  122/153 - Train Accuracy:  0.968, Validation Accuracy:  0.974, Loss:  0.883
Epoch   9 Batch  123/153 - Train Accuracy:  0.962, Validation Accuracy:  0.973, Loss:  0.875
Epoch   9 Batch  124/153 - Train Accuracy:  0.977, Validation Accuracy:  0.971, Loss:  0.893
Epoch   9 Batch  125/153 - Train Accuracy:  0.969, Validation Accuracy:  0.970, Loss:  0.886
Epoch   9 Batch  126/153 - Train Accuracy:  0.973, Validation Accuracy:  0.971, Loss:  0.872
Epoch   9 Batch  127/153 - Train Accuracy:  0.971, Validation Accuracy:  0.971, Loss:  0.897
Epoch   9 Batch  128/153 - Train Accuracy:  0.971, Validation Accuracy:  0.970, Loss:  0.904
Epoch   9 Batch  129/153 - Train Accuracy:  0.968, Validation Accuracy:  0.969, Loss:  0.892
Epoch   9 Batch  130/153 - Train Accuracy:  0.975, Validation Accuracy:  0.970, Loss:  0.861
Epoch   9 Batch  131/153 - Train Accuracy:  0.973, Validation Accuracy:  0.975, Loss:  0.862
Epoch   9 Batch  132/153 - Train Accuracy:  0.974, Validation Accuracy:  0.974, Loss:  0.885
Epoch   9 Batch  133/153 - Train Accuracy:  0.975, Validation Accuracy:  0.974, Loss:  0.863
Epoch   9 Batch  134/153 - Train Accuracy:  0.978, Validation Accuracy:  0.972, Loss:  0.855
Epoch   9 Batch  135/153 - Train Accuracy:  0.977, Validation Accuracy:  0.967, Loss:  0.865
Epoch   9 Batch  136/153 - Train Accuracy:  0.968, Validation Accuracy:  0.965, Loss:  0.883
Epoch   9 Batch  137/153 - Train Accuracy:  0.975, Validation Accuracy:  0.963, Loss:  0.870
Epoch   9 Batch  138/153 - Train Accuracy:  0.972, Validation Accuracy:  0.971, Loss:  0.879
Epoch   9 Batch  139/153 - Train Accuracy:  0.968, Validation Accuracy:  0.974, Loss:  0.876
Epoch   9 Batch  140/153 - Train Accuracy:  0.966, Validation Accuracy:  0.972, Loss:  0.879
Epoch   9 Batch  141/153 - Train Accuracy:  0.977, Validation Accuracy:  0.966, Loss:  0.857
Epoch   9 Batch  142/153 - Train Accuracy:  0.973, Validation Accuracy:  0.967, Loss:  0.874
Epoch   9 Batch  143/153 - Train Accuracy:  0.983, Validation Accuracy:  0.971, Loss:  0.870
Epoch   9 Batch  144/153 - Train Accuracy:  0.969, Validation Accuracy:  0.970, Loss:  0.895
Epoch   9 Batch  145/153 - Train Accuracy:  0.968, Validation Accuracy:  0.970, Loss:  0.884
Epoch   9 Batch  146/153 - Train Accuracy:  0.965, Validation Accuracy:  0.973, Loss:  0.885
Epoch   9 Batch  147/153 - Train Accuracy:  0.972, Validation Accuracy:  0.972, Loss:  0.863
Epoch   9 Batch  148/153 - Train Accuracy:  0.971, Validation Accuracy:  0.968, Loss:  0.855
Epoch   9 Batch  149/153 - Train Accuracy:  0.964, Validation Accuracy:  0.971, Loss:  0.869
Epoch   9 Batch  150/153 - Train Accuracy:  0.960, Validation Accuracy:  0.974, Loss:  0.889
Epoch   9 Batch  151/153 - Train Accuracy:  0.971, Validation Accuracy:  0.972, Loss:  0.869
Epoch  10 Batch    0/153 - Train Accuracy:  0.977, Validation Accuracy:  0.974, Loss:  0.867
Epoch  10 Batch    1/153 - Train Accuracy:  0.975, Validation Accuracy:  0.970, Loss:  0.863
Epoch  10 Batch    2/153 - Train Accuracy:  0.963, Validation Accuracy:  0.956, Loss:  0.870
Epoch  10 Batch    3/153 - Train Accuracy:  0.971, Validation Accuracy:  0.967, Loss:  0.876
Epoch  10 Batch    4/153 - Train Accuracy:  0.975, Validation Accuracy:  0.974, Loss:  0.869
Epoch  10 Batch    5/153 - Train Accuracy:  0.969, Validation Accuracy:  0.976, Loss:  0.879
Epoch  10 Batch    6/153 - Train Accuracy:  0.970, Validation Accuracy:  0.973, Loss:  0.865
Epoch  10 Batch    7/153 - Train Accuracy:  0.973, Validation Accuracy:  0.974, Loss:  0.879
Epoch  10 Batch    8/153 - Train Accuracy:  0.972, Validation Accuracy:  0.970, Loss:  0.859
Epoch  10 Batch    9/153 - Train Accuracy:  0.971, Validation Accuracy:  0.965, Loss:  0.882
Epoch  10 Batch   10/153 - Train Accuracy:  0.976, Validation Accuracy:  0.965, Loss:  0.875
Epoch  10 Batch   11/153 - Train Accuracy:  0.969, Validation Accuracy:  0.966, Loss:  0.874
Epoch  10 Batch   12/153 - Train Accuracy:  0.975, Validation Accuracy:  0.970, Loss:  0.863
Epoch  10 Batch   13/153 - Train Accuracy:  0.968, Validation Accuracy:  0.970, Loss:  0.885
Epoch  10 Batch   14/153 - Train Accuracy:  0.971, Validation Accuracy:  0.968, Loss:  0.869
Epoch  10 Batch   15/153 - Train Accuracy:  0.959, Validation Accuracy:  0.966, Loss:  0.895
Epoch  10 Batch   16/153 - Train Accuracy:  0.975, Validation Accuracy:  0.974, Loss:  0.846
Epoch  10 Batch   17/153 - Train Accuracy:  0.969, Validation Accuracy:  0.971, Loss:  0.873
Epoch  10 Batch   18/153 - Train Accuracy:  0.967, Validation Accuracy:  0.967, Loss:  0.885
Epoch  10 Batch   19/153 - Train Accuracy:  0.977, Validation Accuracy:  0.967, Loss:  0.857
Epoch  10 Batch   20/153 - Train Accuracy:  0.969, Validation Accuracy:  0.971, Loss:  0.871
Epoch  10 Batch   21/153 - Train Accuracy:  0.972, Validation Accuracy:  0.970, Loss:  0.876
Epoch  10 Batch   22/153 - Train Accuracy:  0.968, Validation Accuracy:  0.968, Loss:  0.872
Epoch  10 Batch   23/153 - Train Accuracy:  0.968, Validation Accuracy:  0.965, Loss:  0.891
Epoch  10 Batch   24/153 - Train Accuracy:  0.967, Validation Accuracy:  0.964, Loss:  0.889
Epoch  10 Batch   25/153 - Train Accuracy:  0.964, Validation Accuracy:  0.968, Loss:  0.877
Epoch  10 Batch   26/153 - Train Accuracy:  0.970, Validation Accuracy:  0.968, Loss:  0.874
Epoch  10 Batch   27/153 - Train Accuracy:  0.974, Validation Accuracy:  0.969, Loss:  0.859
Epoch  10 Batch   28/153 - Train Accuracy:  0.967, Validation Accuracy:  0.969, Loss:  0.883
Epoch  10 Batch   29/153 - Train Accuracy:  0.969, Validation Accuracy:  0.964, Loss:  0.853
Epoch  10 Batch   30/153 - Train Accuracy:  0.978, Validation Accuracy:  0.963, Loss:  0.873
Epoch  10 Batch   31/153 - Train Accuracy:  0.968, Validation Accuracy:  0.966, Loss:  0.881
Epoch  10 Batch   32/153 - Train Accuracy:  0.972, Validation Accuracy:  0.968, Loss:  0.897
Epoch  10 Batch   33/153 - Train Accuracy:  0.974, Validation Accuracy:  0.968, Loss:  0.865
Epoch  10 Batch   34/153 - Train Accuracy:  0.968, Validation Accuracy:  0.969, Loss:  0.874
Epoch  10 Batch   35/153 - Train Accuracy:  0.970, Validation Accuracy:  0.968, Loss:  0.859
Epoch  10 Batch   36/153 - Train Accuracy:  0.973, Validation Accuracy:  0.968, Loss:  0.885
Epoch  10 Batch   37/153 - Train Accuracy:  0.970, Validation Accuracy:  0.966, Loss:  0.887
Epoch  10 Batch   38/153 - Train Accuracy:  0.972, Validation Accuracy:  0.962, Loss:  0.873
Epoch  10 Batch   39/153 - Train Accuracy:  0.963, Validation Accuracy:  0.963, Loss:  0.875
Epoch  10 Batch   40/153 - Train Accuracy:  0.971, Validation Accuracy:  0.965, Loss:  0.880
Epoch  10 Batch   41/153 - Train Accuracy:  0.968, Validation Accuracy:  0.968, Loss:  0.876
Epoch  10 Batch   42/153 - Train Accuracy:  0.972, Validation Accuracy:  0.966, Loss:  0.898
Epoch  10 Batch   43/153 - Train Accuracy:  0.967, Validation Accuracy:  0.969, Loss:  0.847
Epoch  10 Batch   44/153 - Train Accuracy:  0.972, Validation Accuracy:  0.970, Loss:  0.860
Epoch  10 Batch   45/153 - Train Accuracy:  0.971, Validation Accuracy:  0.973, Loss:  0.874
Epoch  10 Batch   46/153 - Train Accuracy:  0.977, Validation Accuracy:  0.975, Loss:  0.891
Epoch  10 Batch   47/153 - Train Accuracy:  0.967, Validation Accuracy:  0.972, Loss:  0.863
Epoch  10 Batch   48/153 - Train Accuracy:  0.970, Validation Accuracy:  0.969, Loss:  0.869
Epoch  10 Batch   49/153 - Train Accuracy:  0.980, Validation Accuracy:  0.971, Loss:  0.842
Epoch  10 Batch   50/153 - Train Accuracy:  0.970, Validation Accuracy:  0.967, Loss:  0.885
Epoch  10 Batch   51/153 - Train Accuracy:  0.974, Validation Accuracy:  0.961, Loss:  0.887
Epoch  10 Batch   52/153 - Train Accuracy:  0.975, Validation Accuracy:  0.963, Loss:  0.879
Epoch  10 Batch   53/153 - Train Accuracy:  0.971, Validation Accuracy:  0.973, Loss:  0.867
Epoch  10 Batch   54/153 - Train Accuracy:  0.974, Validation Accuracy:  0.977, Loss:  0.866
Epoch  10 Batch   55/153 - Train Accuracy:  0.973, Validation Accuracy:  0.974, Loss:  0.876
Epoch  10 Batch   56/153 - Train Accuracy:  0.973, Validation Accuracy:  0.973, Loss:  0.869
Epoch  10 Batch   57/153 - Train Accuracy:  0.971, Validation Accuracy:  0.974, Loss:  0.858
Epoch  10 Batch   58/153 - Train Accuracy:  0.968, Validation Accuracy:  0.971, Loss:  0.880
Epoch  10 Batch   59/153 - Train Accuracy:  0.970, Validation Accuracy:  0.972, Loss:  0.858
Epoch  10 Batch   60/153 - Train Accuracy:  0.975, Validation Accuracy:  0.973, Loss:  0.888
Epoch  10 Batch   61/153 - Train Accuracy:  0.974, Validation Accuracy:  0.970, Loss:  0.863
Epoch  10 Batch   62/153 - Train Accuracy:  0.969, Validation Accuracy:  0.971, Loss:  0.887
Epoch  10 Batch   63/153 - Train Accuracy:  0.977, Validation Accuracy:  0.972, Loss:  0.861
Epoch  10 Batch   64/153 - Train Accuracy:  0.969, Validation Accuracy:  0.972, Loss:  0.862
Epoch  10 Batch   65/153 - Train Accuracy:  0.975, Validation Accuracy:  0.972, Loss:  0.859
Epoch  10 Batch   66/153 - Train Accuracy:  0.975, Validation Accuracy:  0.971, Loss:  0.857
Epoch  10 Batch   67/153 - Train Accuracy:  0.972, Validation Accuracy:  0.972, Loss:  0.872
Epoch  10 Batch   68/153 - Train Accuracy:  0.972, Validation Accuracy:  0.973, Loss:  0.870
Epoch  10 Batch   69/153 - Train Accuracy:  0.966, Validation Accuracy:  0.972, Loss:  0.872
Epoch  10 Batch   70/153 - Train Accuracy:  0.972, Validation Accuracy:  0.974, Loss:  0.907
Epoch  10 Batch   71/153 - Train Accuracy:  0.968, Validation Accuracy:  0.977, Loss:  0.875
Epoch  10 Batch   72/153 - Train Accuracy:  0.979, Validation Accuracy:  0.975, Loss:  0.884
Epoch  10 Batch   73/153 - Train Accuracy:  0.973, Validation Accuracy:  0.976, Loss:  0.892
Epoch  10 Batch   74/153 - Train Accuracy:  0.970, Validation Accuracy:  0.976, Loss:  0.879
Epoch  10 Batch   75/153 - Train Accuracy:  0.972, Validation Accuracy:  0.976, Loss:  0.868
Epoch  10 Batch   76/153 - Train Accuracy:  0.976, Validation Accuracy:  0.975, Loss:  0.865
Epoch  10 Batch   77/153 - Train Accuracy:  0.970, Validation Accuracy:  0.974, Loss:  0.873
Epoch  10 Batch   78/153 - Train Accuracy:  0.979, Validation Accuracy:  0.976, Loss:  0.879
Epoch  10 Batch   79/153 - Train Accuracy:  0.974, Validation Accuracy:  0.975, Loss:  0.865
Epoch  10 Batch   80/153 - Train Accuracy:  0.974, Validation Accuracy:  0.976, Loss:  0.858
Epoch  10 Batch   81/153 - Train Accuracy:  0.974, Validation Accuracy:  0.977, Loss:  0.860
Epoch  10 Batch   82/153 - Train Accuracy:  0.979, Validation Accuracy:  0.977, Loss:  0.870
Epoch  10 Batch   83/153 - Train Accuracy:  0.976, Validation Accuracy:  0.972, Loss:  0.886
Epoch  10 Batch   84/153 - Train Accuracy:  0.976, Validation Accuracy:  0.969, Loss:  0.879
Epoch  10 Batch   85/153 - Train Accuracy:  0.977, Validation Accuracy:  0.975, Loss:  0.878
Epoch  10 Batch   86/153 - Train Accuracy:  0.978, Validation Accuracy:  0.975, Loss:  0.870
Epoch  10 Batch   87/153 - Train Accuracy:  0.978, Validation Accuracy:  0.975, Loss:  0.876
Epoch  10 Batch   88/153 - Train Accuracy:  0.972, Validation Accuracy:  0.976, Loss:  0.881
Epoch  10 Batch   89/153 - Train Accuracy:  0.973, Validation Accuracy:  0.977, Loss:  0.878
Epoch  10 Batch   90/153 - Train Accuracy:  0.974, Validation Accuracy:  0.977, Loss:  0.863
Epoch  10 Batch   91/153 - Train Accuracy:  0.979, Validation Accuracy:  0.977, Loss:  0.882
Epoch  10 Batch   92/153 - Train Accuracy:  0.978, Validation Accuracy:  0.976, Loss:  0.881
Epoch  10 Batch   93/153 - Train Accuracy:  0.986, Validation Accuracy:  0.975, Loss:  0.881
Epoch  10 Batch   94/153 - Train Accuracy:  0.978, Validation Accuracy:  0.976, Loss:  0.873
Epoch  10 Batch   95/153 - Train Accuracy:  0.968, Validation Accuracy:  0.975, Loss:  0.872
Epoch  10 Batch   96/153 - Train Accuracy:  0.974, Validation Accuracy:  0.975, Loss:  0.866
Epoch  10 Batch   97/153 - Train Accuracy:  0.974, Validation Accuracy:  0.975, Loss:  0.887
Epoch  10 Batch   98/153 - Train Accuracy:  0.972, Validation Accuracy:  0.975, Loss:  0.892
Epoch  10 Batch   99/153 - Train Accuracy:  0.974, Validation Accuracy:  0.971, Loss:  0.867
Epoch  10 Batch  100/153 - Train Accuracy:  0.978, Validation Accuracy:  0.973, Loss:  0.910
Epoch  10 Batch  101/153 - Train Accuracy:  0.977, Validation Accuracy:  0.974, Loss:  0.864
Epoch  10 Batch  102/153 - Train Accuracy:  0.976, Validation Accuracy:  0.974, Loss:  0.877
Epoch  10 Batch  103/153 - Train Accuracy:  0.975, Validation Accuracy:  0.972, Loss:  0.883
Epoch  10 Batch  104/153 - Train Accuracy:  0.982, Validation Accuracy:  0.973, Loss:  0.883
Epoch  10 Batch  105/153 - Train Accuracy:  0.979, Validation Accuracy:  0.967, Loss:  0.889
Epoch  10 Batch  106/153 - Train Accuracy:  0.974, Validation Accuracy:  0.968, Loss:  0.866
Epoch  10 Batch  107/153 - Train Accuracy:  0.978, Validation Accuracy:  0.974, Loss:  0.886
Epoch  10 Batch  108/153 - Train Accuracy:  0.977, Validation Accuracy:  0.973, Loss:  0.876
Epoch  10 Batch  109/153 - Train Accuracy:  0.979, Validation Accuracy:  0.972, Loss:  0.856
Epoch  10 Batch  110/153 - Train Accuracy:  0.972, Validation Accuracy:  0.973, Loss:  0.902
Epoch  10 Batch  111/153 - Train Accuracy:  0.977, Validation Accuracy:  0.971, Loss:  0.857
Epoch  10 Batch  112/153 - Train Accuracy:  0.968, Validation Accuracy:  0.968, Loss:  0.878
Epoch  10 Batch  113/153 - Train Accuracy:  0.975, Validation Accuracy:  0.971, Loss:  0.878
Epoch  10 Batch  114/153 - Train Accuracy:  0.975, Validation Accuracy:  0.976, Loss:  0.862
Epoch  10 Batch  115/153 - Train Accuracy:  0.974, Validation Accuracy:  0.973, Loss:  0.866
Epoch  10 Batch  116/153 - Train Accuracy:  0.976, Validation Accuracy:  0.975, Loss:  0.874
Epoch  10 Batch  117/153 - Train Accuracy:  0.969, Validation Accuracy:  0.975, Loss:  0.884
Epoch  10 Batch  118/153 - Train Accuracy:  0.973, Validation Accuracy:  0.971, Loss:  0.874
Epoch  10 Batch  119/153 - Train Accuracy:  0.978, Validation Accuracy:  0.971, Loss:  0.862
Epoch  10 Batch  120/153 - Train Accuracy:  0.973, Validation Accuracy:  0.972, Loss:  0.866
Epoch  10 Batch  121/153 - Train Accuracy:  0.974, Validation Accuracy:  0.975, Loss:  0.872
Epoch  10 Batch  122/153 - Train Accuracy:  0.968, Validation Accuracy:  0.972, Loss:  0.895
Epoch  10 Batch  123/153 - Train Accuracy:  0.963, Validation Accuracy:  0.972, Loss:  0.873
Epoch  10 Batch  124/153 - Train Accuracy:  0.979, Validation Accuracy:  0.972, Loss:  0.864
Epoch  10 Batch  125/153 - Train Accuracy:  0.971, Validation Accuracy:  0.968, Loss:  0.871
Epoch  10 Batch  126/153 - Train Accuracy:  0.971, Validation Accuracy:  0.965, Loss:  0.874
Epoch  10 Batch  127/153 - Train Accuracy:  0.971, Validation Accuracy:  0.973, Loss:  0.890
Epoch  10 Batch  128/153 - Train Accuracy:  0.975, Validation Accuracy:  0.974, Loss:  0.849
Epoch  10 Batch  129/153 - Train Accuracy:  0.973, Validation Accuracy:  0.975, Loss:  0.885
Epoch  10 Batch  130/153 - Train Accuracy:  0.979, Validation Accuracy:  0.973, Loss:  0.866
Epoch  10 Batch  131/153 - Train Accuracy:  0.976, Validation Accuracy:  0.973, Loss:  0.867
Epoch  10 Batch  132/153 - Train Accuracy:  0.976, Validation Accuracy:  0.973, Loss:  0.878
Epoch  10 Batch  133/153 - Train Accuracy:  0.980, Validation Accuracy:  0.973, Loss:  0.903
Epoch  10 Batch  134/153 - Train Accuracy:  0.981, Validation Accuracy:  0.974, Loss:  0.864
Epoch  10 Batch  135/153 - Train Accuracy:  0.978, Validation Accuracy:  0.972, Loss:  0.875
Epoch  10 Batch  136/153 - Train Accuracy:  0.977, Validation Accuracy:  0.970, Loss:  0.872
Epoch  10 Batch  137/153 - Train Accuracy:  0.976, Validation Accuracy:  0.969, Loss:  0.852
Epoch  10 Batch  138/153 - Train Accuracy:  0.980, Validation Accuracy:  0.969, Loss:  0.869
Epoch  10 Batch  139/153 - Train Accuracy:  0.968, Validation Accuracy:  0.972, Loss:  0.879
Epoch  10 Batch  140/153 - Train Accuracy:  0.972, Validation Accuracy:  0.977, Loss:  0.881
Epoch  10 Batch  141/153 - Train Accuracy:  0.979, Validation Accuracy:  0.974, Loss:  0.856
Epoch  10 Batch  142/153 - Train Accuracy:  0.979, Validation Accuracy:  0.972, Loss:  0.895
Epoch  10 Batch  143/153 - Train Accuracy:  0.984, Validation Accuracy:  0.970, Loss:  0.855
Epoch  10 Batch  144/153 - Train Accuracy:  0.977, Validation Accuracy:  0.972, Loss:  0.867
Epoch  10 Batch  145/153 - Train Accuracy:  0.974, Validation Accuracy:  0.972, Loss:  0.886
Epoch  10 Batch  146/153 - Train Accuracy:  0.973, Validation Accuracy:  0.972, Loss:  0.878
Epoch  10 Batch  147/153 - Train Accuracy:  0.969, Validation Accuracy:  0.971, Loss:  0.870
Epoch  10 Batch  148/153 - Train Accuracy:  0.975, Validation Accuracy:  0.973, Loss:  0.869
Epoch  10 Batch  149/153 - Train Accuracy:  0.967, Validation Accuracy:  0.971, Loss:  0.877
Epoch  10 Batch  150/153 - Train Accuracy:  0.970, Validation Accuracy:  0.972, Loss:  0.883
Epoch  10 Batch  151/153 - Train Accuracy:  0.976, Validation Accuracy:  0.975, Loss:  0.875
Epoch  11 Batch    0/153 - Train Accuracy:  0.977, Validation Accuracy:  0.974, Loss:  0.859
Epoch  11 Batch    1/153 - Train Accuracy:  0.980, Validation Accuracy:  0.975, Loss:  0.855
Epoch  11 Batch    2/153 - Train Accuracy:  0.976, Validation Accuracy:  0.973, Loss:  0.888
Epoch  11 Batch    3/153 - Train Accuracy:  0.976, Validation Accuracy:  0.970, Loss:  0.897
Epoch  11 Batch    4/153 - Train Accuracy:  0.974, Validation Accuracy:  0.969, Loss:  0.881
Epoch  11 Batch    5/153 - Train Accuracy:  0.978, Validation Accuracy:  0.970, Loss:  0.868
Epoch  11 Batch    6/153 - Train Accuracy:  0.973, Validation Accuracy:  0.973, Loss:  0.873
Epoch  11 Batch    7/153 - Train Accuracy:  0.974, Validation Accuracy:  0.969, Loss:  0.864
Epoch  11 Batch    8/153 - Train Accuracy:  0.973, Validation Accuracy:  0.970, Loss:  0.883
Epoch  11 Batch    9/153 - Train Accuracy:  0.976, Validation Accuracy:  0.968, Loss:  0.860
Epoch  11 Batch   10/153 - Train Accuracy:  0.978, Validation Accuracy:  0.966, Loss:  0.874
Epoch  11 Batch   11/153 - Train Accuracy:  0.977, Validation Accuracy:  0.969, Loss:  0.877
Epoch  11 Batch   12/153 - Train Accuracy:  0.979, Validation Accuracy:  0.970, Loss:  0.866
Epoch  11 Batch   13/153 - Train Accuracy:  0.971, Validation Accuracy:  0.966, Loss:  0.876
Epoch  11 Batch   14/153 - Train Accuracy:  0.971, Validation Accuracy:  0.968, Loss:  0.883
Epoch  11 Batch   15/153 - Train Accuracy:  0.970, Validation Accuracy:  0.971, Loss:  0.896
Epoch  11 Batch   16/153 - Train Accuracy:  0.975, Validation Accuracy:  0.971, Loss:  0.877
Epoch  11 Batch   17/153 - Train Accuracy:  0.972, Validation Accuracy:  0.973, Loss:  0.901
Epoch  11 Batch   18/153 - Train Accuracy:  0.979, Validation Accuracy:  0.974, Loss:  0.872
Epoch  11 Batch   19/153 - Train Accuracy:  0.974, Validation Accuracy:  0.968, Loss:  0.871
Epoch  11 Batch   20/153 - Train Accuracy:  0.968, Validation Accuracy:  0.967, Loss:  0.876
Epoch  11 Batch   21/153 - Train Accuracy:  0.973, Validation Accuracy:  0.973, Loss:  0.877
Epoch  11 Batch   22/153 - Train Accuracy:  0.974, Validation Accuracy:  0.973, Loss:  0.868
Epoch  11 Batch   23/153 - Train Accuracy:  0.975, Validation Accuracy:  0.962, Loss:  0.852
Epoch  11 Batch   24/153 - Train Accuracy:  0.970, Validation Accuracy:  0.967, Loss:  0.879
Epoch  11 Batch   25/153 - Train Accuracy:  0.964, Validation Accuracy:  0.966, Loss:  0.877
Epoch  11 Batch   26/153 - Train Accuracy:  0.970, Validation Accuracy:  0.968, Loss:  0.861
Epoch  11 Batch   27/153 - Train Accuracy:  0.969, Validation Accuracy:  0.971, Loss:  0.879
Epoch  11 Batch   28/153 - Train Accuracy:  0.974, Validation Accuracy:  0.971, Loss:  0.864
Epoch  11 Batch   29/153 - Train Accuracy:  0.972, Validation Accuracy:  0.967, Loss:  0.867
Epoch  11 Batch   30/153 - Train Accuracy:  0.979, Validation Accuracy:  0.964, Loss:  0.895
Epoch  11 Batch   31/153 - Train Accuracy:  0.970, Validation Accuracy:  0.969, Loss:  0.895
Epoch  11 Batch   32/153 - Train Accuracy:  0.973, Validation Accuracy:  0.967, Loss:  0.866
Epoch  11 Batch   33/153 - Train Accuracy:  0.976, Validation Accuracy:  0.968, Loss:  0.882
Epoch  11 Batch   34/153 - Train Accuracy:  0.975, Validation Accuracy:  0.971, Loss:  0.874
Epoch  11 Batch   35/153 - Train Accuracy:  0.973, Validation Accuracy:  0.967, Loss:  0.883
Epoch  11 Batch   36/153 - Train Accuracy:  0.978, Validation Accuracy:  0.967, Loss:  0.896
Epoch  11 Batch   37/153 - Train Accuracy:  0.973, Validation Accuracy:  0.971, Loss:  0.872
Epoch  11 Batch   38/153 - Train Accuracy:  0.974, Validation Accuracy:  0.974, Loss:  0.885
Epoch  11 Batch   39/153 - Train Accuracy:  0.972, Validation Accuracy:  0.971, Loss:  0.878
Epoch  11 Batch   40/153 - Train Accuracy:  0.973, Validation Accuracy:  0.970, Loss:  0.870
Epoch  11 Batch   41/153 - Train Accuracy:  0.973, Validation Accuracy:  0.970, Loss:  0.877
Epoch  11 Batch   42/153 - Train Accuracy:  0.973, Validation Accuracy:  0.972, Loss:  0.883
Epoch  11 Batch   43/153 - Train Accuracy:  0.975, Validation Accuracy:  0.970, Loss:  0.864
Epoch  11 Batch   44/153 - Train Accuracy:  0.975, Validation Accuracy:  0.970, Loss:  0.869
Epoch  11 Batch   45/153 - Train Accuracy:  0.979, Validation Accuracy:  0.971, Loss:  0.890
Epoch  11 Batch   46/153 - Train Accuracy:  0.980, Validation Accuracy:  0.971, Loss:  0.884
Epoch  11 Batch   47/153 - Train Accuracy:  0.971, Validation Accuracy:  0.971, Loss:  0.869
Epoch  11 Batch   48/153 - Train Accuracy:  0.972, Validation Accuracy:  0.971, Loss:  0.878
Epoch  11 Batch   49/153 - Train Accuracy:  0.978, Validation Accuracy:  0.973, Loss:  0.865
Epoch  11 Batch   50/153 - Train Accuracy:  0.976, Validation Accuracy:  0.970, Loss:  0.874
Epoch  11 Batch   51/153 - Train Accuracy:  0.976, Validation Accuracy:  0.972, Loss:  0.901
Epoch  11 Batch   52/153 - Train Accuracy:  0.978, Validation Accuracy:  0.971, Loss:  0.887
Epoch  11 Batch   53/153 - Train Accuracy:  0.976, Validation Accuracy:  0.974, Loss:  0.856
Epoch  11 Batch   54/153 - Train Accuracy:  0.979, Validation Accuracy:  0.972, Loss:  0.865
Epoch  11 Batch   55/153 - Train Accuracy:  0.975, Validation Accuracy:  0.976, Loss:  0.886
Epoch  11 Batch   56/153 - Train Accuracy:  0.974, Validation Accuracy:  0.973, Loss:  0.880
Epoch  11 Batch   57/153 - Train Accuracy:  0.973, Validation Accuracy:  0.974, Loss:  0.881
Epoch  11 Batch   58/153 - Train Accuracy:  0.977, Validation Accuracy:  0.976, Loss:  0.883
Epoch  11 Batch   59/153 - Train Accuracy:  0.971, Validation Accuracy:  0.974, Loss:  0.858
Epoch  11 Batch   60/153 - Train Accuracy:  0.979, Validation Accuracy:  0.972, Loss:  0.875
Epoch  11 Batch   61/153 - Train Accuracy:  0.975, Validation Accuracy:  0.975, Loss:  0.878
Epoch  11 Batch   62/153 - Train Accuracy:  0.972, Validation Accuracy:  0.974, Loss:  0.878
Epoch  11 Batch   63/153 - Train Accuracy:  0.979, Validation Accuracy:  0.974, Loss:  0.876
Epoch  11 Batch   64/153 - Train Accuracy:  0.971, Validation Accuracy:  0.974, Loss:  0.870
Epoch  11 Batch   65/153 - Train Accuracy:  0.974, Validation Accuracy:  0.971, Loss:  0.902
Epoch  11 Batch   66/153 - Train Accuracy:  0.977, Validation Accuracy:  0.971, Loss:  0.901
Epoch  11 Batch   67/153 - Train Accuracy:  0.970, Validation Accuracy:  0.973, Loss:  0.868
Epoch  11 Batch   68/153 - Train Accuracy:  0.974, Validation Accuracy:  0.974, Loss:  0.880
Epoch  11 Batch   69/153 - Train Accuracy:  0.971, Validation Accuracy:  0.975, Loss:  0.851
Epoch  11 Batch   70/153 - Train Accuracy:  0.973, Validation Accuracy:  0.973, Loss:  0.871
Epoch  11 Batch   71/153 - Train Accuracy:  0.973, Validation Accuracy:  0.972, Loss:  0.884
Epoch  11 Batch   72/153 - Train Accuracy:  0.977, Validation Accuracy:  0.975, Loss:  0.873
Epoch  11 Batch   73/153 - Train Accuracy:  0.973, Validation Accuracy:  0.976, Loss:  0.884
Epoch  11 Batch   74/153 - Train Accuracy:  0.972, Validation Accuracy:  0.975, Loss:  0.877
Epoch  11 Batch   75/153 - Train Accuracy:  0.971, Validation Accuracy:  0.976, Loss:  0.876
Epoch  11 Batch   76/153 - Train Accuracy:  0.976, Validation Accuracy:  0.977, Loss:  0.861
Epoch  11 Batch   77/153 - Train Accuracy:  0.969, Validation Accuracy:  0.978, Loss:  0.888
Epoch  11 Batch   78/153 - Train Accuracy:  0.976, Validation Accuracy:  0.978, Loss:  0.883
Epoch  11 Batch   79/153 - Train Accuracy:  0.980, Validation Accuracy:  0.978, Loss:  0.867
Epoch  11 Batch   80/153 - Train Accuracy:  0.978, Validation Accuracy:  0.978, Loss:  0.862
Epoch  11 Batch   81/153 - Train Accuracy:  0.979, Validation Accuracy:  0.974, Loss:  0.868
Epoch  11 Batch   82/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.845
Epoch  11 Batch   83/153 - Train Accuracy:  0.976, Validation Accuracy:  0.973, Loss:  0.878
Epoch  11 Batch   84/153 - Train Accuracy:  0.975, Validation Accuracy:  0.973, Loss:  0.885
Epoch  11 Batch   85/153 - Train Accuracy:  0.984, Validation Accuracy:  0.970, Loss:  0.868
Epoch  11 Batch   86/153 - Train Accuracy:  0.977, Validation Accuracy:  0.969, Loss:  0.871
Epoch  11 Batch   87/153 - Train Accuracy:  0.977, Validation Accuracy:  0.970, Loss:  0.875
Epoch  11 Batch   88/153 - Train Accuracy:  0.975, Validation Accuracy:  0.974, Loss:  0.866
Epoch  11 Batch   89/153 - Train Accuracy:  0.972, Validation Accuracy:  0.975, Loss:  0.865
Epoch  11 Batch   90/153 - Train Accuracy:  0.972, Validation Accuracy:  0.972, Loss:  0.873
Epoch  11 Batch   91/153 - Train Accuracy:  0.979, Validation Accuracy:  0.973, Loss:  0.876
Epoch  11 Batch   92/153 - Train Accuracy:  0.979, Validation Accuracy:  0.976, Loss:  0.901
Epoch  11 Batch   93/153 - Train Accuracy:  0.983, Validation Accuracy:  0.975, Loss:  0.890
Epoch  11 Batch   94/153 - Train Accuracy:  0.985, Validation Accuracy:  0.973, Loss:  0.879
Epoch  11 Batch   95/153 - Train Accuracy:  0.970, Validation Accuracy:  0.980, Loss:  0.868
Epoch  11 Batch   96/153 - Train Accuracy:  0.976, Validation Accuracy:  0.974, Loss:  0.869
Epoch  11 Batch   97/153 - Train Accuracy:  0.973, Validation Accuracy:  0.970, Loss:  0.889
Epoch  11 Batch   98/153 - Train Accuracy:  0.969, Validation Accuracy:  0.972, Loss:  0.876
Epoch  11 Batch   99/153 - Train Accuracy:  0.973, Validation Accuracy:  0.972, Loss:  0.904
Epoch  11 Batch  100/153 - Train Accuracy:  0.976, Validation Accuracy:  0.973, Loss:  0.862
Epoch  11 Batch  101/153 - Train Accuracy:  0.980, Validation Accuracy:  0.973, Loss:  0.869
Epoch  11 Batch  102/153 - Train Accuracy:  0.978, Validation Accuracy:  0.974, Loss:  0.887
Epoch  11 Batch  103/153 - Train Accuracy:  0.974, Validation Accuracy:  0.971, Loss:  0.869
Epoch  11 Batch  104/153 - Train Accuracy:  0.983, Validation Accuracy:  0.974, Loss:  0.858
Epoch  11 Batch  105/153 - Train Accuracy:  0.982, Validation Accuracy:  0.972, Loss:  0.884
Epoch  11 Batch  106/153 - Train Accuracy:  0.973, Validation Accuracy:  0.969, Loss:  0.868
Epoch  11 Batch  107/153 - Train Accuracy:  0.979, Validation Accuracy:  0.970, Loss:  0.873
Epoch  11 Batch  108/153 - Train Accuracy:  0.976, Validation Accuracy:  0.974, Loss:  0.887
Epoch  11 Batch  109/153 - Train Accuracy:  0.979, Validation Accuracy:  0.973, Loss:  0.854
Epoch  11 Batch  110/153 - Train Accuracy:  0.974, Validation Accuracy:  0.973, Loss:  0.865
Epoch  11 Batch  111/153 - Train Accuracy:  0.978, Validation Accuracy:  0.973, Loss:  0.872
Epoch  11 Batch  112/153 - Train Accuracy:  0.975, Validation Accuracy:  0.972, Loss:  0.873
Epoch  11 Batch  113/153 - Train Accuracy:  0.977, Validation Accuracy:  0.968, Loss:  0.879
Epoch  11 Batch  114/153 - Train Accuracy:  0.978, Validation Accuracy:  0.977, Loss:  0.880
Epoch  11 Batch  115/153 - Train Accuracy:  0.975, Validation Accuracy:  0.975, Loss:  0.859
Epoch  11 Batch  116/153 - Train Accuracy:  0.973, Validation Accuracy:  0.973, Loss:  0.876
Epoch  11 Batch  117/153 - Train Accuracy:  0.972, Validation Accuracy:  0.977, Loss:  0.867
Epoch  11 Batch  118/153 - Train Accuracy:  0.977, Validation Accuracy:  0.976, Loss:  0.863
Epoch  11 Batch  119/153 - Train Accuracy:  0.981, Validation Accuracy:  0.969, Loss:  0.872
Epoch  11 Batch  120/153 - Train Accuracy:  0.977, Validation Accuracy:  0.972, Loss:  0.876
Epoch  11 Batch  121/153 - Train Accuracy:  0.976, Validation Accuracy:  0.976, Loss:  0.860
Epoch  11 Batch  122/153 - Train Accuracy:  0.974, Validation Accuracy:  0.975, Loss:  0.868
Epoch  11 Batch  123/153 - Train Accuracy:  0.972, Validation Accuracy:  0.975, Loss:  0.905
Epoch  11 Batch  124/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.868
Epoch  11 Batch  125/153 - Train Accuracy:  0.972, Validation Accuracy:  0.976, Loss:  0.862
Epoch  11 Batch  126/153 - Train Accuracy:  0.976, Validation Accuracy:  0.975, Loss:  0.863
Epoch  11 Batch  127/153 - Train Accuracy:  0.971, Validation Accuracy:  0.966, Loss:  0.857
Epoch  11 Batch  128/153 - Train Accuracy:  0.972, Validation Accuracy:  0.971, Loss:  0.860
Epoch  11 Batch  129/153 - Train Accuracy:  0.964, Validation Accuracy:  0.959, Loss:  0.873
Epoch  11 Batch  130/153 - Train Accuracy:  0.983, Validation Accuracy:  0.975, Loss:  0.875
Epoch  11 Batch  131/153 - Train Accuracy:  0.973, Validation Accuracy:  0.973, Loss:  0.867
Epoch  11 Batch  132/153 - Train Accuracy:  0.976, Validation Accuracy:  0.975, Loss:  0.892
Epoch  11 Batch  133/153 - Train Accuracy:  0.980, Validation Accuracy:  0.976, Loss:  0.866
Epoch  11 Batch  134/153 - Train Accuracy:  0.982, Validation Accuracy:  0.973, Loss:  0.865
Epoch  11 Batch  135/153 - Train Accuracy:  0.978, Validation Accuracy:  0.973, Loss:  0.872
Epoch  11 Batch  136/153 - Train Accuracy:  0.981, Validation Accuracy:  0.975, Loss:  0.856
Epoch  11 Batch  137/153 - Train Accuracy:  0.976, Validation Accuracy:  0.979, Loss:  0.868
Epoch  11 Batch  138/153 - Train Accuracy:  0.983, Validation Accuracy:  0.979, Loss:  0.857
Epoch  11 Batch  139/153 - Train Accuracy:  0.973, Validation Accuracy:  0.978, Loss:  0.890
Epoch  11 Batch  140/153 - Train Accuracy:  0.971, Validation Accuracy:  0.979, Loss:  0.874
Epoch  11 Batch  141/153 - Train Accuracy:  0.981, Validation Accuracy:  0.973, Loss:  0.865
Epoch  11 Batch  142/153 - Train Accuracy:  0.976, Validation Accuracy:  0.972, Loss:  0.862
Epoch  11 Batch  143/153 - Train Accuracy:  0.983, Validation Accuracy:  0.971, Loss:  0.859
Epoch  11 Batch  144/153 - Train Accuracy:  0.972, Validation Accuracy:  0.973, Loss:  0.874
Epoch  11 Batch  145/153 - Train Accuracy:  0.977, Validation Accuracy:  0.974, Loss:  0.879
Epoch  11 Batch  146/153 - Train Accuracy:  0.978, Validation Accuracy:  0.975, Loss:  0.880
Epoch  11 Batch  147/153 - Train Accuracy:  0.978, Validation Accuracy:  0.977, Loss:  0.868
Epoch  11 Batch  148/153 - Train Accuracy:  0.979, Validation Accuracy:  0.975, Loss:  0.849
Epoch  11 Batch  149/153 - Train Accuracy:  0.969, Validation Accuracy:  0.972, Loss:  0.876
Epoch  11 Batch  150/153 - Train Accuracy:  0.973, Validation Accuracy:  0.975, Loss:  0.883
Epoch  11 Batch  151/153 - Train Accuracy:  0.975, Validation Accuracy:  0.975, Loss:  0.850
Epoch  12 Batch    0/153 - Train Accuracy:  0.981, Validation Accuracy:  0.975, Loss:  0.869
Epoch  12 Batch    1/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.864
Epoch  12 Batch    2/153 - Train Accuracy:  0.978, Validation Accuracy:  0.970, Loss:  0.882
Epoch  12 Batch    3/153 - Train Accuracy:  0.978, Validation Accuracy:  0.968, Loss:  0.868
Epoch  12 Batch    4/153 - Train Accuracy:  0.975, Validation Accuracy:  0.969, Loss:  0.877
Epoch  12 Batch    5/153 - Train Accuracy:  0.977, Validation Accuracy:  0.974, Loss:  0.878
Epoch  12 Batch    6/153 - Train Accuracy:  0.971, Validation Accuracy:  0.975, Loss:  0.877
Epoch  12 Batch    7/153 - Train Accuracy:  0.982, Validation Accuracy:  0.975, Loss:  0.888
Epoch  12 Batch    8/153 - Train Accuracy:  0.980, Validation Accuracy:  0.975, Loss:  0.859
Epoch  12 Batch    9/153 - Train Accuracy:  0.977, Validation Accuracy:  0.974, Loss:  0.869
Epoch  12 Batch   10/153 - Train Accuracy:  0.981, Validation Accuracy:  0.970, Loss:  0.848
Epoch  12 Batch   11/153 - Train Accuracy:  0.973, Validation Accuracy:  0.970, Loss:  0.869
Epoch  12 Batch   12/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.881
Epoch  12 Batch   13/153 - Train Accuracy:  0.976, Validation Accuracy:  0.975, Loss:  0.872
Epoch  12 Batch   14/153 - Train Accuracy:  0.968, Validation Accuracy:  0.974, Loss:  0.863
Epoch  12 Batch   15/153 - Train Accuracy:  0.966, Validation Accuracy:  0.973, Loss:  0.880
Epoch  12 Batch   16/153 - Train Accuracy:  0.974, Validation Accuracy:  0.974, Loss:  0.890
Epoch  12 Batch   17/153 - Train Accuracy:  0.974, Validation Accuracy:  0.972, Loss:  0.881
Epoch  12 Batch   18/153 - Train Accuracy:  0.977, Validation Accuracy:  0.973, Loss:  0.851
Epoch  12 Batch   19/153 - Train Accuracy:  0.978, Validation Accuracy:  0.974, Loss:  0.871
Epoch  12 Batch   20/153 - Train Accuracy:  0.974, Validation Accuracy:  0.971, Loss:  0.873
Epoch  12 Batch   21/153 - Train Accuracy:  0.972, Validation Accuracy:  0.972, Loss:  0.882
Epoch  12 Batch   22/153 - Train Accuracy:  0.978, Validation Accuracy:  0.977, Loss:  0.892
Epoch  12 Batch   23/153 - Train Accuracy:  0.980, Validation Accuracy:  0.973, Loss:  0.863
Epoch  12 Batch   24/153 - Train Accuracy:  0.970, Validation Accuracy:  0.968, Loss:  0.864
Epoch  12 Batch   25/153 - Train Accuracy:  0.971, Validation Accuracy:  0.972, Loss:  0.886
Epoch  12 Batch   26/153 - Train Accuracy:  0.974, Validation Accuracy:  0.976, Loss:  0.862
Epoch  12 Batch   27/153 - Train Accuracy:  0.975, Validation Accuracy:  0.977, Loss:  0.864
Epoch  12 Batch   28/153 - Train Accuracy:  0.978, Validation Accuracy:  0.977, Loss:  0.885
Epoch  12 Batch   29/153 - Train Accuracy:  0.976, Validation Accuracy:  0.977, Loss:  0.867
Epoch  12 Batch   30/153 - Train Accuracy:  0.979, Validation Accuracy:  0.974, Loss:  0.861
Epoch  12 Batch   31/153 - Train Accuracy:  0.971, Validation Accuracy:  0.970, Loss:  0.872
Epoch  12 Batch   32/153 - Train Accuracy:  0.977, Validation Accuracy:  0.974, Loss:  0.884
Epoch  12 Batch   33/153 - Train Accuracy:  0.975, Validation Accuracy:  0.976, Loss:  0.866
Epoch  12 Batch   34/153 - Train Accuracy:  0.975, Validation Accuracy:  0.977, Loss:  0.868
Epoch  12 Batch   35/153 - Train Accuracy:  0.971, Validation Accuracy:  0.976, Loss:  0.877
Epoch  12 Batch   36/153 - Train Accuracy:  0.979, Validation Accuracy:  0.978, Loss:  0.853
Epoch  12 Batch   37/153 - Train Accuracy:  0.973, Validation Accuracy:  0.976, Loss:  0.879
Epoch  12 Batch   38/153 - Train Accuracy:  0.972, Validation Accuracy:  0.973, Loss:  0.863
Epoch  12 Batch   39/153 - Train Accuracy:  0.976, Validation Accuracy:  0.975, Loss:  0.872
Epoch  12 Batch   40/153 - Train Accuracy:  0.977, Validation Accuracy:  0.975, Loss:  0.873
Epoch  12 Batch   41/153 - Train Accuracy:  0.973, Validation Accuracy:  0.973, Loss:  0.867
Epoch  12 Batch   42/153 - Train Accuracy:  0.974, Validation Accuracy:  0.969, Loss:  0.852
Epoch  12 Batch   43/153 - Train Accuracy:  0.967, Validation Accuracy:  0.970, Loss:  0.878
Epoch  12 Batch   44/153 - Train Accuracy:  0.982, Validation Accuracy:  0.971, Loss:  0.879
Epoch  12 Batch   45/153 - Train Accuracy:  0.981, Validation Accuracy:  0.972, Loss:  0.863
Epoch  12 Batch   46/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.882
Epoch  12 Batch   47/153 - Train Accuracy:  0.975, Validation Accuracy:  0.975, Loss:  0.860
Epoch  12 Batch   48/153 - Train Accuracy:  0.978, Validation Accuracy:  0.974, Loss:  0.876
Epoch  12 Batch   49/153 - Train Accuracy:  0.981, Validation Accuracy:  0.972, Loss:  0.856
Epoch  12 Batch   50/153 - Train Accuracy:  0.978, Validation Accuracy:  0.972, Loss:  0.891
Epoch  12 Batch   51/153 - Train Accuracy:  0.980, Validation Accuracy:  0.975, Loss:  0.872
Epoch  12 Batch   52/153 - Train Accuracy:  0.983, Validation Accuracy:  0.975, Loss:  0.864
Epoch  12 Batch   53/153 - Train Accuracy:  0.977, Validation Accuracy:  0.972, Loss:  0.875
Epoch  12 Batch   54/153 - Train Accuracy:  0.979, Validation Accuracy:  0.974, Loss:  0.877
Epoch  12 Batch   55/153 - Train Accuracy:  0.975, Validation Accuracy:  0.977, Loss:  0.868
Epoch  12 Batch   56/153 - Train Accuracy:  0.977, Validation Accuracy:  0.976, Loss:  0.868
Epoch  12 Batch   57/153 - Train Accuracy:  0.976, Validation Accuracy:  0.975, Loss:  0.884
Epoch  12 Batch   58/153 - Train Accuracy:  0.975, Validation Accuracy:  0.976, Loss:  0.867
Epoch  12 Batch   59/153 - Train Accuracy:  0.973, Validation Accuracy:  0.976, Loss:  0.879
Epoch  12 Batch   60/153 - Train Accuracy:  0.976, Validation Accuracy:  0.977, Loss:  0.868
Epoch  12 Batch   61/153 - Train Accuracy:  0.981, Validation Accuracy:  0.976, Loss:  0.873
Epoch  12 Batch   62/153 - Train Accuracy:  0.979, Validation Accuracy:  0.975, Loss:  0.871
Epoch  12 Batch   63/153 - Train Accuracy:  0.981, Validation Accuracy:  0.973, Loss:  0.866
Epoch  12 Batch   64/153 - Train Accuracy:  0.977, Validation Accuracy:  0.972, Loss:  0.857
Epoch  12 Batch   65/153 - Train Accuracy:  0.981, Validation Accuracy:  0.970, Loss:  0.868
Epoch  12 Batch   66/153 - Train Accuracy:  0.981, Validation Accuracy:  0.972, Loss:  0.862
Epoch  12 Batch   67/153 - Train Accuracy:  0.976, Validation Accuracy:  0.972, Loss:  0.864
Epoch  12 Batch   68/153 - Train Accuracy:  0.980, Validation Accuracy:  0.972, Loss:  0.883
Epoch  12 Batch   69/153 - Train Accuracy:  0.971, Validation Accuracy:  0.974, Loss:  0.864
Epoch  12 Batch   70/153 - Train Accuracy:  0.979, Validation Accuracy:  0.976, Loss:  0.879
Epoch  12 Batch   71/153 - Train Accuracy:  0.980, Validation Accuracy:  0.977, Loss:  0.853
Epoch  12 Batch   72/153 - Train Accuracy:  0.981, Validation Accuracy:  0.978, Loss:  0.876
Epoch  12 Batch   73/153 - Train Accuracy:  0.977, Validation Accuracy:  0.979, Loss:  0.856
Epoch  12 Batch   74/153 - Train Accuracy:  0.981, Validation Accuracy:  0.979, Loss:  0.866
Epoch  12 Batch   75/153 - Train Accuracy:  0.975, Validation Accuracy:  0.976, Loss:  0.870
Epoch  12 Batch   76/153 - Train Accuracy:  0.981, Validation Accuracy:  0.979, Loss:  0.871
Epoch  12 Batch   77/153 - Train Accuracy:  0.974, Validation Accuracy:  0.980, Loss:  0.869
Epoch  12 Batch   78/153 - Train Accuracy:  0.983, Validation Accuracy:  0.982, Loss:  0.871
Epoch  12 Batch   79/153 - Train Accuracy:  0.984, Validation Accuracy:  0.980, Loss:  0.873
Epoch  12 Batch   80/153 - Train Accuracy:  0.983, Validation Accuracy:  0.980, Loss:  0.883
Epoch  12 Batch   81/153 - Train Accuracy:  0.976, Validation Accuracy:  0.978, Loss:  0.856
Epoch  12 Batch   82/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.873
Epoch  12 Batch   83/153 - Train Accuracy:  0.978, Validation Accuracy:  0.977, Loss:  0.870
Epoch  12 Batch   84/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.867
Epoch  12 Batch   85/153 - Train Accuracy:  0.980, Validation Accuracy:  0.977, Loss:  0.866
Epoch  12 Batch   86/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.882
Epoch  12 Batch   87/153 - Train Accuracy:  0.980, Validation Accuracy:  0.976, Loss:  0.858
Epoch  12 Batch   88/153 - Train Accuracy:  0.977, Validation Accuracy:  0.977, Loss:  0.883
Epoch  12 Batch   89/153 - Train Accuracy:  0.980, Validation Accuracy:  0.977, Loss:  0.857
Epoch  12 Batch   90/153 - Train Accuracy:  0.980, Validation Accuracy:  0.979, Loss:  0.870
Epoch  12 Batch   91/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.867
Epoch  12 Batch   92/153 - Train Accuracy:  0.980, Validation Accuracy:  0.978, Loss:  0.897
Epoch  12 Batch   93/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.857
Epoch  12 Batch   94/153 - Train Accuracy:  0.986, Validation Accuracy:  0.977, Loss:  0.885
Epoch  12 Batch   95/153 - Train Accuracy:  0.975, Validation Accuracy:  0.978, Loss:  0.890
Epoch  12 Batch   96/153 - Train Accuracy:  0.981, Validation Accuracy:  0.973, Loss:  0.880
Epoch  12 Batch   97/153 - Train Accuracy:  0.983, Validation Accuracy:  0.974, Loss:  0.884
Epoch  12 Batch   98/153 - Train Accuracy:  0.975, Validation Accuracy:  0.971, Loss:  0.853
Epoch  12 Batch   99/153 - Train Accuracy:  0.979, Validation Accuracy:  0.970, Loss:  0.887
Epoch  12 Batch  100/153 - Train Accuracy:  0.975, Validation Accuracy:  0.971, Loss:  0.904
Epoch  12 Batch  101/153 - Train Accuracy:  0.978, Validation Accuracy:  0.973, Loss:  0.861
Epoch  12 Batch  102/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.880
Epoch  12 Batch  103/153 - Train Accuracy:  0.978, Validation Accuracy:  0.976, Loss:  0.878
Epoch  12 Batch  104/153 - Train Accuracy:  0.981, Validation Accuracy:  0.975, Loss:  0.887
Epoch  12 Batch  105/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.871
Epoch  12 Batch  106/153 - Train Accuracy:  0.981, Validation Accuracy:  0.976, Loss:  0.851
Epoch  12 Batch  107/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.874
Epoch  12 Batch  108/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.850
Epoch  12 Batch  109/153 - Train Accuracy:  0.980, Validation Accuracy:  0.975, Loss:  0.885
Epoch  12 Batch  110/153 - Train Accuracy:  0.978, Validation Accuracy:  0.977, Loss:  0.864
Epoch  12 Batch  111/153 - Train Accuracy:  0.980, Validation Accuracy:  0.976, Loss:  0.876
Epoch  12 Batch  112/153 - Train Accuracy:  0.979, Validation Accuracy:  0.974, Loss:  0.880
Epoch  12 Batch  113/153 - Train Accuracy:  0.983, Validation Accuracy:  0.975, Loss:  0.838
Epoch  12 Batch  114/153 - Train Accuracy:  0.981, Validation Accuracy:  0.974, Loss:  0.875
Epoch  12 Batch  115/153 - Train Accuracy:  0.981, Validation Accuracy:  0.973, Loss:  0.875
Epoch  12 Batch  116/153 - Train Accuracy:  0.983, Validation Accuracy:  0.973, Loss:  0.851
Epoch  12 Batch  117/153 - Train Accuracy:  0.978, Validation Accuracy:  0.973, Loss:  0.883
Epoch  12 Batch  118/153 - Train Accuracy:  0.975, Validation Accuracy:  0.974, Loss:  0.858
Epoch  12 Batch  119/153 - Train Accuracy:  0.982, Validation Accuracy:  0.974, Loss:  0.856
Epoch  12 Batch  120/153 - Train Accuracy:  0.977, Validation Accuracy:  0.974, Loss:  0.891
Epoch  12 Batch  121/153 - Train Accuracy:  0.980, Validation Accuracy:  0.971, Loss:  0.859
Epoch  12 Batch  122/153 - Train Accuracy:  0.976, Validation Accuracy:  0.972, Loss:  0.868
Epoch  12 Batch  123/153 - Train Accuracy:  0.972, Validation Accuracy:  0.974, Loss:  0.877
Epoch  12 Batch  124/153 - Train Accuracy:  0.983, Validation Accuracy:  0.972, Loss:  0.885
Epoch  12 Batch  125/153 - Train Accuracy:  0.978, Validation Accuracy:  0.975, Loss:  0.875
Epoch  12 Batch  126/153 - Train Accuracy:  0.978, Validation Accuracy:  0.974, Loss:  0.863
Epoch  12 Batch  127/153 - Train Accuracy:  0.978, Validation Accuracy:  0.975, Loss:  0.878
Epoch  12 Batch  128/153 - Train Accuracy:  0.973, Validation Accuracy:  0.972, Loss:  0.873
Epoch  12 Batch  129/153 - Train Accuracy:  0.977, Validation Accuracy:  0.972, Loss:  0.868
Epoch  12 Batch  130/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.865
Epoch  12 Batch  131/153 - Train Accuracy:  0.978, Validation Accuracy:  0.976, Loss:  0.859
Epoch  12 Batch  132/153 - Train Accuracy:  0.983, Validation Accuracy:  0.975, Loss:  0.880
Epoch  12 Batch  133/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.859
Epoch  12 Batch  134/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.892
Epoch  12 Batch  135/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.873
Epoch  12 Batch  136/153 - Train Accuracy:  0.983, Validation Accuracy:  0.974, Loss:  0.876
Epoch  12 Batch  137/153 - Train Accuracy:  0.979, Validation Accuracy:  0.972, Loss:  0.856
Epoch  12 Batch  138/153 - Train Accuracy:  0.983, Validation Accuracy:  0.974, Loss:  0.879
Epoch  12 Batch  139/153 - Train Accuracy:  0.977, Validation Accuracy:  0.975, Loss:  0.874
Epoch  12 Batch  140/153 - Train Accuracy:  0.975, Validation Accuracy:  0.977, Loss:  0.874
Epoch  12 Batch  141/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.851
Epoch  12 Batch  142/153 - Train Accuracy:  0.982, Validation Accuracy:  0.972, Loss:  0.881
Epoch  12 Batch  143/153 - Train Accuracy:  0.987, Validation Accuracy:  0.971, Loss:  0.861
Epoch  12 Batch  144/153 - Train Accuracy:  0.976, Validation Accuracy:  0.972, Loss:  0.867
Epoch  12 Batch  145/153 - Train Accuracy:  0.979, Validation Accuracy:  0.970, Loss:  0.879
Epoch  12 Batch  146/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.855
Epoch  12 Batch  147/153 - Train Accuracy:  0.978, Validation Accuracy:  0.974, Loss:  0.874
Epoch  12 Batch  148/153 - Train Accuracy:  0.978, Validation Accuracy:  0.977, Loss:  0.874
Epoch  12 Batch  149/153 - Train Accuracy:  0.977, Validation Accuracy:  0.978, Loss:  0.835
Epoch  12 Batch  150/153 - Train Accuracy:  0.978, Validation Accuracy:  0.981, Loss:  0.865
Epoch  12 Batch  151/153 - Train Accuracy:  0.981, Validation Accuracy:  0.979, Loss:  0.858
Epoch  13 Batch    0/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.880
Epoch  13 Batch    1/153 - Train Accuracy:  0.979, Validation Accuracy:  0.972, Loss:  0.853
Epoch  13 Batch    2/153 - Train Accuracy:  0.978, Validation Accuracy:  0.971, Loss:  0.861
Epoch  13 Batch    3/153 - Train Accuracy:  0.982, Validation Accuracy:  0.971, Loss:  0.874
Epoch  13 Batch    4/153 - Train Accuracy:  0.982, Validation Accuracy:  0.975, Loss:  0.880
Epoch  13 Batch    5/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.883
Epoch  13 Batch    6/153 - Train Accuracy:  0.979, Validation Accuracy:  0.975, Loss:  0.869
Epoch  13 Batch    7/153 - Train Accuracy:  0.982, Validation Accuracy:  0.976, Loss:  0.867
Epoch  13 Batch    8/153 - Train Accuracy:  0.981, Validation Accuracy:  0.976, Loss:  0.852
Epoch  13 Batch    9/153 - Train Accuracy:  0.981, Validation Accuracy:  0.975, Loss:  0.876
Epoch  13 Batch   10/153 - Train Accuracy:  0.985, Validation Accuracy:  0.976, Loss:  0.871
Epoch  13 Batch   11/153 - Train Accuracy:  0.983, Validation Accuracy:  0.976, Loss:  0.863
Epoch  13 Batch   12/153 - Train Accuracy:  0.980, Validation Accuracy:  0.974, Loss:  0.877
Epoch  13 Batch   13/153 - Train Accuracy:  0.979, Validation Accuracy:  0.975, Loss:  0.890
Epoch  13 Batch   14/153 - Train Accuracy:  0.976, Validation Accuracy:  0.976, Loss:  0.873
Epoch  13 Batch   15/153 - Train Accuracy:  0.973, Validation Accuracy:  0.976, Loss:  0.861
Epoch  13 Batch   16/153 - Train Accuracy:  0.981, Validation Accuracy:  0.974, Loss:  0.865
Epoch  13 Batch   17/153 - Train Accuracy:  0.979, Validation Accuracy:  0.975, Loss:  0.870
Epoch  13 Batch   18/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.865
Epoch  13 Batch   19/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.877
Epoch  13 Batch   20/153 - Train Accuracy:  0.980, Validation Accuracy:  0.977, Loss:  0.877
Epoch  13 Batch   21/153 - Train Accuracy:  0.978, Validation Accuracy:  0.976, Loss:  0.863
Epoch  13 Batch   22/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.871
Epoch  13 Batch   23/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.861
Epoch  13 Batch   24/153 - Train Accuracy:  0.982, Validation Accuracy:  0.971, Loss:  0.871
Epoch  13 Batch   25/153 - Train Accuracy:  0.977, Validation Accuracy:  0.970, Loss:  0.868
Epoch  13 Batch   26/153 - Train Accuracy:  0.979, Validation Accuracy:  0.970, Loss:  0.847
Epoch  13 Batch   27/153 - Train Accuracy:  0.983, Validation Accuracy:  0.973, Loss:  0.875
Epoch  13 Batch   28/153 - Train Accuracy:  0.977, Validation Accuracy:  0.975, Loss:  0.871
Epoch  13 Batch   29/153 - Train Accuracy:  0.978, Validation Accuracy:  0.977, Loss:  0.873
Epoch  13 Batch   30/153 - Train Accuracy:  0.984, Validation Accuracy:  0.980, Loss:  0.872
Epoch  13 Batch   31/153 - Train Accuracy:  0.976, Validation Accuracy:  0.977, Loss:  0.896
Epoch  13 Batch   32/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.886
Epoch  13 Batch   33/153 - Train Accuracy:  0.982, Validation Accuracy:  0.976, Loss:  0.843
Epoch  13 Batch   34/153 - Train Accuracy:  0.979, Validation Accuracy:  0.979, Loss:  0.872
Epoch  13 Batch   35/153 - Train Accuracy:  0.976, Validation Accuracy:  0.979, Loss:  0.867
Epoch  13 Batch   36/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.881
Epoch  13 Batch   37/153 - Train Accuracy:  0.976, Validation Accuracy:  0.977, Loss:  0.868
Epoch  13 Batch   38/153 - Train Accuracy:  0.981, Validation Accuracy:  0.974, Loss:  0.865
Epoch  13 Batch   39/153 - Train Accuracy:  0.974, Validation Accuracy:  0.972, Loss:  0.879
Epoch  13 Batch   40/153 - Train Accuracy:  0.981, Validation Accuracy:  0.976, Loss:  0.852
Epoch  13 Batch   41/153 - Train Accuracy:  0.982, Validation Accuracy:  0.978, Loss:  0.860
Epoch  13 Batch   42/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.869
Epoch  13 Batch   43/153 - Train Accuracy:  0.976, Validation Accuracy:  0.978, Loss:  0.871
Epoch  13 Batch   44/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.843
Epoch  13 Batch   45/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.866
Epoch  13 Batch   46/153 - Train Accuracy:  0.985, Validation Accuracy:  0.976, Loss:  0.878
Epoch  13 Batch   47/153 - Train Accuracy:  0.981, Validation Accuracy:  0.979, Loss:  0.871
Epoch  13 Batch   48/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.890
Epoch  13 Batch   49/153 - Train Accuracy:  0.981, Validation Accuracy:  0.976, Loss:  0.861
Epoch  13 Batch   50/153 - Train Accuracy:  0.981, Validation Accuracy:  0.976, Loss:  0.867
Epoch  13 Batch   51/153 - Train Accuracy:  0.980, Validation Accuracy:  0.974, Loss:  0.860
Epoch  13 Batch   52/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.856
Epoch  13 Batch   53/153 - Train Accuracy:  0.976, Validation Accuracy:  0.975, Loss:  0.858
Epoch  13 Batch   54/153 - Train Accuracy:  0.981, Validation Accuracy:  0.978, Loss:  0.878
Epoch  13 Batch   55/153 - Train Accuracy:  0.981, Validation Accuracy:  0.980, Loss:  0.857
Epoch  13 Batch   56/153 - Train Accuracy:  0.979, Validation Accuracy:  0.978, Loss:  0.873
Epoch  13 Batch   57/153 - Train Accuracy:  0.980, Validation Accuracy:  0.977, Loss:  0.873
Epoch  13 Batch   58/153 - Train Accuracy:  0.976, Validation Accuracy:  0.976, Loss:  0.888
Epoch  13 Batch   59/153 - Train Accuracy:  0.976, Validation Accuracy:  0.978, Loss:  0.867
Epoch  13 Batch   60/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.846
Epoch  13 Batch   61/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.885
Epoch  13 Batch   62/153 - Train Accuracy:  0.979, Validation Accuracy:  0.977, Loss:  0.855
Epoch  13 Batch   63/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.882
Epoch  13 Batch   64/153 - Train Accuracy:  0.983, Validation Accuracy:  0.975, Loss:  0.849
Epoch  13 Batch   65/153 - Train Accuracy:  0.983, Validation Accuracy:  0.972, Loss:  0.848
Epoch  13 Batch   66/153 - Train Accuracy:  0.981, Validation Accuracy:  0.973, Loss:  0.869
Epoch  13 Batch   67/153 - Train Accuracy:  0.979, Validation Accuracy:  0.977, Loss:  0.868
Epoch  13 Batch   68/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.891
Epoch  13 Batch   69/153 - Train Accuracy:  0.974, Validation Accuracy:  0.978, Loss:  0.875
Epoch  13 Batch   70/153 - Train Accuracy:  0.976, Validation Accuracy:  0.977, Loss:  0.890
Epoch  13 Batch   71/153 - Train Accuracy:  0.982, Validation Accuracy:  0.978, Loss:  0.868
Epoch  13 Batch   72/153 - Train Accuracy:  0.980, Validation Accuracy:  0.976, Loss:  0.872
Epoch  13 Batch   73/153 - Train Accuracy:  0.978, Validation Accuracy:  0.979, Loss:  0.884
Epoch  13 Batch   74/153 - Train Accuracy:  0.979, Validation Accuracy:  0.977, Loss:  0.862
Epoch  13 Batch   75/153 - Train Accuracy:  0.976, Validation Accuracy:  0.979, Loss:  0.873
Epoch  13 Batch   76/153 - Train Accuracy:  0.985, Validation Accuracy:  0.980, Loss:  0.868
Epoch  13 Batch   77/153 - Train Accuracy:  0.975, Validation Accuracy:  0.981, Loss:  0.876
Epoch  13 Batch   78/153 - Train Accuracy:  0.979, Validation Accuracy:  0.982, Loss:  0.862
Epoch  13 Batch   79/153 - Train Accuracy:  0.984, Validation Accuracy:  0.981, Loss:  0.865
Epoch  13 Batch   80/153 - Train Accuracy:  0.982, Validation Accuracy:  0.980, Loss:  0.867
Epoch  13 Batch   81/153 - Train Accuracy:  0.975, Validation Accuracy:  0.978, Loss:  0.872
Epoch  13 Batch   82/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.865
Epoch  13 Batch   83/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.863
Epoch  13 Batch   84/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.865
Epoch  13 Batch   85/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.862
Epoch  13 Batch   86/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.875
Epoch  13 Batch   87/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.898
Epoch  13 Batch   88/153 - Train Accuracy:  0.980, Validation Accuracy:  0.978, Loss:  0.863
Epoch  13 Batch   89/153 - Train Accuracy:  0.980, Validation Accuracy:  0.981, Loss:  0.846
Epoch  13 Batch   90/153 - Train Accuracy:  0.982, Validation Accuracy:  0.981, Loss:  0.868
Epoch  13 Batch   91/153 - Train Accuracy:  0.981, Validation Accuracy:  0.980, Loss:  0.864
Epoch  13 Batch   92/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.873
Epoch  13 Batch   93/153 - Train Accuracy:  0.985, Validation Accuracy:  0.976, Loss:  0.884
Epoch  13 Batch   94/153 - Train Accuracy:  0.983, Validation Accuracy:  0.974, Loss:  0.870
Epoch  13 Batch   95/153 - Train Accuracy:  0.978, Validation Accuracy:  0.974, Loss:  0.889
Epoch  13 Batch   96/153 - Train Accuracy:  0.984, Validation Accuracy:  0.973, Loss:  0.872
Epoch  13 Batch   97/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.860
Epoch  13 Batch   98/153 - Train Accuracy:  0.976, Validation Accuracy:  0.976, Loss:  0.869
Epoch  13 Batch   99/153 - Train Accuracy:  0.979, Validation Accuracy:  0.973, Loss:  0.863
Epoch  13 Batch  100/153 - Train Accuracy:  0.979, Validation Accuracy:  0.973, Loss:  0.875
Epoch  13 Batch  101/153 - Train Accuracy:  0.982, Validation Accuracy:  0.974, Loss:  0.863
Epoch  13 Batch  102/153 - Train Accuracy:  0.986, Validation Accuracy:  0.973, Loss:  0.856
Epoch  13 Batch  103/153 - Train Accuracy:  0.979, Validation Accuracy:  0.973, Loss:  0.878
Epoch  13 Batch  104/153 - Train Accuracy:  0.983, Validation Accuracy:  0.975, Loss:  0.876
Epoch  13 Batch  105/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.887
Epoch  13 Batch  106/153 - Train Accuracy:  0.979, Validation Accuracy:  0.975, Loss:  0.870
Epoch  13 Batch  107/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.872
Epoch  13 Batch  108/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.884
Epoch  13 Batch  109/153 - Train Accuracy:  0.980, Validation Accuracy:  0.979, Loss:  0.898
Epoch  13 Batch  110/153 - Train Accuracy:  0.978, Validation Accuracy:  0.978, Loss:  0.877
Epoch  13 Batch  111/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.868
Epoch  13 Batch  112/153 - Train Accuracy:  0.981, Validation Accuracy:  0.978, Loss:  0.860
Epoch  13 Batch  113/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.862
Epoch  13 Batch  114/153 - Train Accuracy:  0.981, Validation Accuracy:  0.975, Loss:  0.863
Epoch  13 Batch  115/153 - Train Accuracy:  0.982, Validation Accuracy:  0.976, Loss:  0.848
Epoch  13 Batch  116/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.858
Epoch  13 Batch  117/153 - Train Accuracy:  0.982, Validation Accuracy:  0.979, Loss:  0.851
Epoch  13 Batch  118/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.840
Epoch  13 Batch  119/153 - Train Accuracy:  0.983, Validation Accuracy:  0.979, Loss:  0.880
Epoch  13 Batch  120/153 - Train Accuracy:  0.979, Validation Accuracy:  0.978, Loss:  0.878
Epoch  13 Batch  121/153 - Train Accuracy:  0.983, Validation Accuracy:  0.979, Loss:  0.863
Epoch  13 Batch  122/153 - Train Accuracy:  0.981, Validation Accuracy:  0.978, Loss:  0.853
Epoch  13 Batch  123/153 - Train Accuracy:  0.979, Validation Accuracy:  0.977, Loss:  0.868
Epoch  13 Batch  124/153 - Train Accuracy:  0.981, Validation Accuracy:  0.978, Loss:  0.876
Epoch  13 Batch  125/153 - Train Accuracy:  0.980, Validation Accuracy:  0.976, Loss:  0.860
Epoch  13 Batch  126/153 - Train Accuracy:  0.975, Validation Accuracy:  0.978, Loss:  0.862
Epoch  13 Batch  127/153 - Train Accuracy:  0.982, Validation Accuracy:  0.976, Loss:  0.886
Epoch  13 Batch  128/153 - Train Accuracy:  0.978, Validation Accuracy:  0.974, Loss:  0.895
Epoch  13 Batch  129/153 - Train Accuracy:  0.977, Validation Accuracy:  0.973, Loss:  0.871
Epoch  13 Batch  130/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.869
Epoch  13 Batch  131/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.859
Epoch  13 Batch  132/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.859
Epoch  13 Batch  133/153 - Train Accuracy:  0.983, Validation Accuracy:  0.980, Loss:  0.861
Epoch  13 Batch  134/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.884
Epoch  13 Batch  135/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.878
Epoch  13 Batch  136/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.892
Epoch  13 Batch  137/153 - Train Accuracy:  0.976, Validation Accuracy:  0.975, Loss:  0.870
Epoch  13 Batch  138/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.882
Epoch  13 Batch  139/153 - Train Accuracy:  0.980, Validation Accuracy:  0.980, Loss:  0.876
Epoch  13 Batch  140/153 - Train Accuracy:  0.978, Validation Accuracy:  0.980, Loss:  0.865
Epoch  13 Batch  141/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.869
Epoch  13 Batch  142/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.842
Epoch  13 Batch  143/153 - Train Accuracy:  0.986, Validation Accuracy:  0.977, Loss:  0.884
Epoch  13 Batch  144/153 - Train Accuracy:  0.978, Validation Accuracy:  0.977, Loss:  0.866
Epoch  13 Batch  145/153 - Train Accuracy:  0.979, Validation Accuracy:  0.976, Loss:  0.870
Epoch  13 Batch  146/153 - Train Accuracy:  0.978, Validation Accuracy:  0.975, Loss:  0.868
Epoch  13 Batch  147/153 - Train Accuracy:  0.982, Validation Accuracy:  0.978, Loss:  0.878
Epoch  13 Batch  148/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.875
Epoch  13 Batch  149/153 - Train Accuracy:  0.978, Validation Accuracy:  0.978, Loss:  0.854
Epoch  13 Batch  150/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.865
Epoch  13 Batch  151/153 - Train Accuracy:  0.979, Validation Accuracy:  0.979, Loss:  0.857
Epoch  14 Batch    0/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.882
Epoch  14 Batch    1/153 - Train Accuracy:  0.982, Validation Accuracy:  0.979, Loss:  0.868
Epoch  14 Batch    2/153 - Train Accuracy:  0.982, Validation Accuracy:  0.978, Loss:  0.883
Epoch  14 Batch    3/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.839
Epoch  14 Batch    4/153 - Train Accuracy:  0.985, Validation Accuracy:  0.979, Loss:  0.888
Epoch  14 Batch    5/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.866
Epoch  14 Batch    6/153 - Train Accuracy:  0.982, Validation Accuracy:  0.974, Loss:  0.876
Epoch  14 Batch    7/153 - Train Accuracy:  0.984, Validation Accuracy:  0.972, Loss:  0.844
Epoch  14 Batch    8/153 - Train Accuracy:  0.982, Validation Accuracy:  0.975, Loss:  0.881
Epoch  14 Batch    9/153 - Train Accuracy:  0.982, Validation Accuracy:  0.973, Loss:  0.865
Epoch  14 Batch   10/153 - Train Accuracy:  0.985, Validation Accuracy:  0.975, Loss:  0.855
Epoch  14 Batch   11/153 - Train Accuracy:  0.983, Validation Accuracy:  0.976, Loss:  0.876
Epoch  14 Batch   12/153 - Train Accuracy:  0.984, Validation Accuracy:  0.974, Loss:  0.887
Epoch  14 Batch   13/153 - Train Accuracy:  0.975, Validation Accuracy:  0.974, Loss:  0.888
Epoch  14 Batch   14/153 - Train Accuracy:  0.981, Validation Accuracy:  0.975, Loss:  0.875
Epoch  14 Batch   15/153 - Train Accuracy:  0.976, Validation Accuracy:  0.970, Loss:  0.878
Epoch  14 Batch   16/153 - Train Accuracy:  0.978, Validation Accuracy:  0.969, Loss:  0.865
Epoch  14 Batch   17/153 - Train Accuracy:  0.980, Validation Accuracy:  0.971, Loss:  0.866
Epoch  14 Batch   18/153 - Train Accuracy:  0.985, Validation Accuracy:  0.973, Loss:  0.850
Epoch  14 Batch   19/153 - Train Accuracy:  0.980, Validation Accuracy:  0.978, Loss:  0.863
Epoch  14 Batch   20/153 - Train Accuracy:  0.976, Validation Accuracy:  0.977, Loss:  0.851
Epoch  14 Batch   21/153 - Train Accuracy:  0.981, Validation Accuracy:  0.978, Loss:  0.865
Epoch  14 Batch   22/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.873
Epoch  14 Batch   23/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.855
Epoch  14 Batch   24/153 - Train Accuracy:  0.981, Validation Accuracy:  0.976, Loss:  0.864
Epoch  14 Batch   25/153 - Train Accuracy:  0.973, Validation Accuracy:  0.975, Loss:  0.887
Epoch  14 Batch   26/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.863
Epoch  14 Batch   27/153 - Train Accuracy:  0.982, Validation Accuracy:  0.979, Loss:  0.896
Epoch  14 Batch   28/153 - Train Accuracy:  0.981, Validation Accuracy:  0.981, Loss:  0.881
Epoch  14 Batch   29/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.863
Epoch  14 Batch   30/153 - Train Accuracy:  0.984, Validation Accuracy:  0.980, Loss:  0.878
Epoch  14 Batch   31/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.878
Epoch  14 Batch   32/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.859
Epoch  14 Batch   33/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.864
Epoch  14 Batch   34/153 - Train Accuracy:  0.979, Validation Accuracy:  0.981, Loss:  0.874
Epoch  14 Batch   35/153 - Train Accuracy:  0.980, Validation Accuracy:  0.981, Loss:  0.848
Epoch  14 Batch   36/153 - Train Accuracy:  0.984, Validation Accuracy:  0.980, Loss:  0.856
Epoch  14 Batch   37/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.870
Epoch  14 Batch   38/153 - Train Accuracy:  0.982, Validation Accuracy:  0.979, Loss:  0.848
Epoch  14 Batch   39/153 - Train Accuracy:  0.980, Validation Accuracy:  0.979, Loss:  0.880
Epoch  14 Batch   40/153 - Train Accuracy:  0.982, Validation Accuracy:  0.983, Loss:  0.868
Epoch  14 Batch   41/153 - Train Accuracy:  0.978, Validation Accuracy:  0.983, Loss:  0.877
Epoch  14 Batch   42/153 - Train Accuracy:  0.983, Validation Accuracy:  0.980, Loss:  0.874
Epoch  14 Batch   43/153 - Train Accuracy:  0.980, Validation Accuracy:  0.978, Loss:  0.853
Epoch  14 Batch   44/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.885
Epoch  14 Batch   45/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.843
Epoch  14 Batch   46/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.857
Epoch  14 Batch   47/153 - Train Accuracy:  0.982, Validation Accuracy:  0.978, Loss:  0.861
Epoch  14 Batch   48/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.877
Epoch  14 Batch   49/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.869
Epoch  14 Batch   50/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.884
Epoch  14 Batch   51/153 - Train Accuracy:  0.982, Validation Accuracy:  0.978, Loss:  0.847
Epoch  14 Batch   52/153 - Train Accuracy:  0.982, Validation Accuracy:  0.973, Loss:  0.854
Epoch  14 Batch   53/153 - Train Accuracy:  0.981, Validation Accuracy:  0.971, Loss:  0.882
Epoch  14 Batch   54/153 - Train Accuracy:  0.982, Validation Accuracy:  0.974, Loss:  0.883
Epoch  14 Batch   55/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.876
Epoch  14 Batch   56/153 - Train Accuracy:  0.980, Validation Accuracy:  0.979, Loss:  0.883
Epoch  14 Batch   57/153 - Train Accuracy:  0.982, Validation Accuracy:  0.978, Loss:  0.862
Epoch  14 Batch   58/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.849
Epoch  14 Batch   59/153 - Train Accuracy:  0.983, Validation Accuracy:  0.974, Loss:  0.877
Epoch  14 Batch   60/153 - Train Accuracy:  0.986, Validation Accuracy:  0.974, Loss:  0.858
Epoch  14 Batch   61/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.868
Epoch  14 Batch   62/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.888
Epoch  14 Batch   63/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.865
Epoch  14 Batch   64/153 - Train Accuracy:  0.980, Validation Accuracy:  0.977, Loss:  0.886
Epoch  14 Batch   65/153 - Train Accuracy:  0.985, Validation Accuracy:  0.976, Loss:  0.852
Epoch  14 Batch   66/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.866
Epoch  14 Batch   67/153 - Train Accuracy:  0.981, Validation Accuracy:  0.978, Loss:  0.866
Epoch  14 Batch   68/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.864
Epoch  14 Batch   69/153 - Train Accuracy:  0.980, Validation Accuracy:  0.978, Loss:  0.870
Epoch  14 Batch   70/153 - Train Accuracy:  0.978, Validation Accuracy:  0.980, Loss:  0.868
Epoch  14 Batch   71/153 - Train Accuracy:  0.984, Validation Accuracy:  0.980, Loss:  0.850
Epoch  14 Batch   72/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.863
Epoch  14 Batch   73/153 - Train Accuracy:  0.979, Validation Accuracy:  0.976, Loss:  0.869
Epoch  14 Batch   74/153 - Train Accuracy:  0.980, Validation Accuracy:  0.977, Loss:  0.869
Epoch  14 Batch   75/153 - Train Accuracy:  0.980, Validation Accuracy:  0.978, Loss:  0.872
Epoch  14 Batch   76/153 - Train Accuracy:  0.983, Validation Accuracy:  0.979, Loss:  0.869
Epoch  14 Batch   77/153 - Train Accuracy:  0.979, Validation Accuracy:  0.980, Loss:  0.862
Epoch  14 Batch   78/153 - Train Accuracy:  0.985, Validation Accuracy:  0.981, Loss:  0.872
Epoch  14 Batch   79/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.867
Epoch  14 Batch   80/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.873
Epoch  14 Batch   81/153 - Train Accuracy:  0.982, Validation Accuracy:  0.981, Loss:  0.851
Epoch  14 Batch   82/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.855
Epoch  14 Batch   83/153 - Train Accuracy:  0.985, Validation Accuracy:  0.980, Loss:  0.874
Epoch  14 Batch   84/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.856
Epoch  14 Batch   85/153 - Train Accuracy:  0.984, Validation Accuracy:  0.981, Loss:  0.860
Epoch  14 Batch   86/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.862
Epoch  14 Batch   87/153 - Train Accuracy:  0.984, Validation Accuracy:  0.982, Loss:  0.862
Epoch  14 Batch   88/153 - Train Accuracy:  0.977, Validation Accuracy:  0.982, Loss:  0.873
Epoch  14 Batch   89/153 - Train Accuracy:  0.985, Validation Accuracy:  0.981, Loss:  0.884
Epoch  14 Batch   90/153 - Train Accuracy:  0.980, Validation Accuracy:  0.979, Loss:  0.863
Epoch  14 Batch   91/153 - Train Accuracy:  0.983, Validation Accuracy:  0.979, Loss:  0.855
Epoch  14 Batch   92/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.858
Epoch  14 Batch   93/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.869
Epoch  14 Batch   94/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.865
Epoch  14 Batch   95/153 - Train Accuracy:  0.981, Validation Accuracy:  0.982, Loss:  0.859
Epoch  14 Batch   96/153 - Train Accuracy:  0.984, Validation Accuracy:  0.981, Loss:  0.855
Epoch  14 Batch   97/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.863
Epoch  14 Batch   98/153 - Train Accuracy:  0.979, Validation Accuracy:  0.976, Loss:  0.876
Epoch  14 Batch   99/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.859
Epoch  14 Batch  100/153 - Train Accuracy:  0.982, Validation Accuracy:  0.976, Loss:  0.863
Epoch  14 Batch  101/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.854
Epoch  14 Batch  102/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.868
Epoch  14 Batch  103/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.860
Epoch  14 Batch  104/153 - Train Accuracy:  0.986, Validation Accuracy:  0.977, Loss:  0.868
Epoch  14 Batch  105/153 - Train Accuracy:  0.988, Validation Accuracy:  0.976, Loss:  0.846
Epoch  14 Batch  106/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.869
Epoch  14 Batch  107/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.878
Epoch  14 Batch  108/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.870
Epoch  14 Batch  109/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.861
Epoch  14 Batch  110/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.878
Epoch  14 Batch  111/153 - Train Accuracy:  0.981, Validation Accuracy:  0.980, Loss:  0.864
Epoch  14 Batch  112/153 - Train Accuracy:  0.984, Validation Accuracy:  0.981, Loss:  0.871
Epoch  14 Batch  113/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.878
Epoch  14 Batch  114/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.882
Epoch  14 Batch  115/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.866
Epoch  14 Batch  116/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.876
Epoch  14 Batch  117/153 - Train Accuracy:  0.981, Validation Accuracy:  0.980, Loss:  0.858
Epoch  14 Batch  118/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.855
Epoch  14 Batch  119/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.861
Epoch  14 Batch  120/153 - Train Accuracy:  0.980, Validation Accuracy:  0.980, Loss:  0.877
Epoch  14 Batch  121/153 - Train Accuracy:  0.983, Validation Accuracy:  0.976, Loss:  0.876
Epoch  14 Batch  122/153 - Train Accuracy:  0.981, Validation Accuracy:  0.978, Loss:  0.876
Epoch  14 Batch  123/153 - Train Accuracy:  0.979, Validation Accuracy:  0.980, Loss:  0.866
Epoch  14 Batch  124/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.853
Epoch  14 Batch  125/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.867
Epoch  14 Batch  126/153 - Train Accuracy:  0.979, Validation Accuracy:  0.978, Loss:  0.843
Epoch  14 Batch  127/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.880
Epoch  14 Batch  128/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.880
Epoch  14 Batch  129/153 - Train Accuracy:  0.981, Validation Accuracy:  0.976, Loss:  0.855
Epoch  14 Batch  130/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.882
Epoch  14 Batch  131/153 - Train Accuracy:  0.983, Validation Accuracy:  0.979, Loss:  0.865
Epoch  14 Batch  132/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.868
Epoch  14 Batch  133/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.845
Epoch  14 Batch  134/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.850
Epoch  14 Batch  135/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.867
Epoch  14 Batch  136/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.865
Epoch  14 Batch  137/153 - Train Accuracy:  0.983, Validation Accuracy:  0.975, Loss:  0.869
Epoch  14 Batch  138/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.876
Epoch  14 Batch  139/153 - Train Accuracy:  0.979, Validation Accuracy:  0.978, Loss:  0.856
Epoch  14 Batch  140/153 - Train Accuracy:  0.977, Validation Accuracy:  0.976, Loss:  0.860
Epoch  14 Batch  141/153 - Train Accuracy:  0.983, Validation Accuracy:  0.974, Loss:  0.867
Epoch  14 Batch  142/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.866
Epoch  14 Batch  143/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.851
Epoch  14 Batch  144/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.860
Epoch  14 Batch  145/153 - Train Accuracy:  0.982, Validation Accuracy:  0.973, Loss:  0.854
Epoch  14 Batch  146/153 - Train Accuracy:  0.982, Validation Accuracy:  0.975, Loss:  0.871
Epoch  14 Batch  147/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.860
Epoch  14 Batch  148/153 - Train Accuracy:  0.984, Validation Accuracy:  0.980, Loss:  0.871
Epoch  14 Batch  149/153 - Train Accuracy:  0.979, Validation Accuracy:  0.980, Loss:  0.881
Epoch  14 Batch  150/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.860
Epoch  14 Batch  151/153 - Train Accuracy:  0.977, Validation Accuracy:  0.975, Loss:  0.890
Epoch  15 Batch    0/153 - Train Accuracy:  0.985, Validation Accuracy:  0.974, Loss:  0.883
Epoch  15 Batch    1/153 - Train Accuracy:  0.986, Validation Accuracy:  0.975, Loss:  0.871
Epoch  15 Batch    2/153 - Train Accuracy:  0.982, Validation Accuracy:  0.978, Loss:  0.906
Epoch  15 Batch    3/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.850
Epoch  15 Batch    4/153 - Train Accuracy:  0.986, Validation Accuracy:  0.974, Loss:  0.873
Epoch  15 Batch    5/153 - Train Accuracy:  0.983, Validation Accuracy:  0.973, Loss:  0.872
Epoch  15 Batch    6/153 - Train Accuracy:  0.983, Validation Accuracy:  0.976, Loss:  0.872
Epoch  15 Batch    7/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.861
Epoch  15 Batch    8/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.867
Epoch  15 Batch    9/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.863
Epoch  15 Batch   10/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.868
Epoch  15 Batch   11/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.850
Epoch  15 Batch   12/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.884
Epoch  15 Batch   13/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.860
Epoch  15 Batch   14/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.882
Epoch  15 Batch   15/153 - Train Accuracy:  0.979, Validation Accuracy:  0.979, Loss:  0.844
Epoch  15 Batch   16/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.861
Epoch  15 Batch   17/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.864
Epoch  15 Batch   18/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.848
Epoch  15 Batch   19/153 - Train Accuracy:  0.985, Validation Accuracy:  0.979, Loss:  0.867
Epoch  15 Batch   20/153 - Train Accuracy:  0.979, Validation Accuracy:  0.978, Loss:  0.875
Epoch  15 Batch   21/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.871
Epoch  15 Batch   22/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.846
Epoch  15 Batch   23/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.863
Epoch  15 Batch   24/153 - Train Accuracy:  0.983, Validation Accuracy:  0.969, Loss:  0.844
Epoch  15 Batch   25/153 - Train Accuracy:  0.978, Validation Accuracy:  0.968, Loss:  0.864
Epoch  15 Batch   26/153 - Train Accuracy:  0.985, Validation Accuracy:  0.980, Loss:  0.898
Epoch  15 Batch   27/153 - Train Accuracy:  0.973, Validation Accuracy:  0.976, Loss:  0.869
Epoch  15 Batch   28/153 - Train Accuracy:  0.976, Validation Accuracy:  0.975, Loss:  0.870
Epoch  15 Batch   29/153 - Train Accuracy:  0.985, Validation Accuracy:  0.976, Loss:  0.854
Epoch  15 Batch   30/153 - Train Accuracy:  0.989, Validation Accuracy:  0.972, Loss:  0.859
Epoch  15 Batch   31/153 - Train Accuracy:  0.968, Validation Accuracy:  0.973, Loss:  0.863
Epoch  15 Batch   32/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.868
Epoch  15 Batch   33/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.846
Epoch  15 Batch   34/153 - Train Accuracy:  0.979, Validation Accuracy:  0.978, Loss:  0.854
Epoch  15 Batch   35/153 - Train Accuracy:  0.979, Validation Accuracy:  0.978, Loss:  0.880
Epoch  15 Batch   36/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.846
Epoch  15 Batch   37/153 - Train Accuracy:  0.979, Validation Accuracy:  0.978, Loss:  0.865
Epoch  15 Batch   38/153 - Train Accuracy:  0.986, Validation Accuracy:  0.973, Loss:  0.871
Epoch  15 Batch   39/153 - Train Accuracy:  0.980, Validation Accuracy:  0.972, Loss:  0.838
Epoch  15 Batch   40/153 - Train Accuracy:  0.980, Validation Accuracy:  0.979, Loss:  0.890
Epoch  15 Batch   41/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.882
Epoch  15 Batch   42/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.876
Epoch  15 Batch   43/153 - Train Accuracy:  0.979, Validation Accuracy:  0.976, Loss:  0.858
Epoch  15 Batch   44/153 - Train Accuracy:  0.985, Validation Accuracy:  0.975, Loss:  0.882
Epoch  15 Batch   45/153 - Train Accuracy:  0.985, Validation Accuracy:  0.976, Loss:  0.888
Epoch  15 Batch   46/153 - Train Accuracy:  0.986, Validation Accuracy:  0.977, Loss:  0.880
Epoch  15 Batch   47/153 - Train Accuracy:  0.971, Validation Accuracy:  0.971, Loss:  0.844
Epoch  15 Batch   48/153 - Train Accuracy:  0.950, Validation Accuracy:  0.950, Loss:  0.896
Epoch  15 Batch   49/153 - Train Accuracy:  0.956, Validation Accuracy:  0.949, Loss:  1.038
Epoch  15 Batch   50/153 - Train Accuracy:  0.964, Validation Accuracy:  0.963, Loss:  1.004
Epoch  15 Batch   51/153 - Train Accuracy:  0.952, Validation Accuracy:  0.951, Loss:  0.941
Epoch  15 Batch   52/153 - Train Accuracy:  0.963, Validation Accuracy:  0.956, Loss:  0.939
Epoch  15 Batch   53/153 - Train Accuracy:  0.956, Validation Accuracy:  0.947, Loss:  0.929
Epoch  15 Batch   54/153 - Train Accuracy:  0.948, Validation Accuracy:  0.948, Loss:  0.930
Epoch  15 Batch   55/153 - Train Accuracy:  0.957, Validation Accuracy:  0.951, Loss:  0.913
Epoch  15 Batch   56/153 - Train Accuracy:  0.949, Validation Accuracy:  0.951, Loss:  0.923
Epoch  15 Batch   57/153 - Train Accuracy:  0.945, Validation Accuracy:  0.947, Loss:  0.929
Epoch  15 Batch   58/153 - Train Accuracy:  0.951, Validation Accuracy:  0.949, Loss:  0.910
Epoch  15 Batch   59/153 - Train Accuracy:  0.948, Validation Accuracy:  0.939, Loss:  0.915
Epoch  15 Batch   60/153 - Train Accuracy:  0.947, Validation Accuracy:  0.944, Loss:  0.951
Epoch  15 Batch   61/153 - Train Accuracy:  0.942, Validation Accuracy:  0.946, Loss:  0.948
Epoch  15 Batch   62/153 - Train Accuracy:  0.949, Validation Accuracy:  0.952, Loss:  0.942
Epoch  15 Batch   63/153 - Train Accuracy:  0.946, Validation Accuracy:  0.954, Loss:  0.913
Epoch  15 Batch   64/153 - Train Accuracy:  0.951, Validation Accuracy:  0.954, Loss:  0.915
Epoch  15 Batch   65/153 - Train Accuracy:  0.960, Validation Accuracy:  0.950, Loss:  0.890
Epoch  15 Batch   66/153 - Train Accuracy:  0.959, Validation Accuracy:  0.949, Loss:  0.913
Epoch  15 Batch   67/153 - Train Accuracy:  0.963, Validation Accuracy:  0.956, Loss:  0.927
Epoch  15 Batch   68/153 - Train Accuracy:  0.965, Validation Accuracy:  0.961, Loss:  0.911
Epoch  15 Batch   69/153 - Train Accuracy:  0.960, Validation Accuracy:  0.957, Loss:  0.889
Epoch  15 Batch   70/153 - Train Accuracy:  0.966, Validation Accuracy:  0.960, Loss:  0.911
Epoch  15 Batch   71/153 - Train Accuracy:  0.964, Validation Accuracy:  0.966, Loss:  0.910
Epoch  15 Batch   72/153 - Train Accuracy:  0.971, Validation Accuracy:  0.965, Loss:  0.897
Epoch  15 Batch   73/153 - Train Accuracy:  0.975, Validation Accuracy:  0.963, Loss:  0.921
Epoch  15 Batch   74/153 - Train Accuracy:  0.968, Validation Accuracy:  0.970, Loss:  0.880
Epoch  15 Batch   75/153 - Train Accuracy:  0.969, Validation Accuracy:  0.966, Loss:  0.883
Epoch  15 Batch   76/153 - Train Accuracy:  0.976, Validation Accuracy:  0.965, Loss:  0.894
Epoch  15 Batch   77/153 - Train Accuracy:  0.966, Validation Accuracy:  0.968, Loss:  0.898
Epoch  15 Batch   78/153 - Train Accuracy:  0.970, Validation Accuracy:  0.969, Loss:  0.889
Epoch  15 Batch   79/153 - Train Accuracy:  0.975, Validation Accuracy:  0.967, Loss:  0.871
Epoch  15 Batch   80/153 - Train Accuracy:  0.974, Validation Accuracy:  0.964, Loss:  0.875
Epoch  15 Batch   81/153 - Train Accuracy:  0.974, Validation Accuracy:  0.964, Loss:  0.887
Epoch  15 Batch   82/153 - Train Accuracy:  0.986, Validation Accuracy:  0.968, Loss:  0.874
Epoch  15 Batch   83/153 - Train Accuracy:  0.970, Validation Accuracy:  0.965, Loss:  0.861
Epoch  15 Batch   84/153 - Train Accuracy:  0.977, Validation Accuracy:  0.971, Loss:  0.885
Epoch  15 Batch   85/153 - Train Accuracy:  0.975, Validation Accuracy:  0.973, Loss:  0.895
Epoch  15 Batch   86/153 - Train Accuracy:  0.976, Validation Accuracy:  0.972, Loss:  0.873
Epoch  15 Batch   87/153 - Train Accuracy:  0.974, Validation Accuracy:  0.971, Loss:  0.878
Epoch  15 Batch   88/153 - Train Accuracy:  0.969, Validation Accuracy:  0.970, Loss:  0.900
Epoch  15 Batch   89/153 - Train Accuracy:  0.980, Validation Accuracy:  0.972, Loss:  0.907
Epoch  15 Batch   90/153 - Train Accuracy:  0.974, Validation Accuracy:  0.973, Loss:  0.902
Epoch  15 Batch   91/153 - Train Accuracy:  0.975, Validation Accuracy:  0.973, Loss:  0.872
Epoch  15 Batch   92/153 - Train Accuracy:  0.980, Validation Accuracy:  0.975, Loss:  0.872
Epoch  15 Batch   93/153 - Train Accuracy:  0.980, Validation Accuracy:  0.974, Loss:  0.880
Epoch  15 Batch   94/153 - Train Accuracy:  0.988, Validation Accuracy:  0.974, Loss:  0.891
Epoch  15 Batch   95/153 - Train Accuracy:  0.978, Validation Accuracy:  0.977, Loss:  0.888
Epoch  15 Batch   96/153 - Train Accuracy:  0.980, Validation Accuracy:  0.977, Loss:  0.882
Epoch  15 Batch   97/153 - Train Accuracy:  0.981, Validation Accuracy:  0.976, Loss:  0.875
Epoch  15 Batch   98/153 - Train Accuracy:  0.973, Validation Accuracy:  0.976, Loss:  0.861
Epoch  15 Batch   99/153 - Train Accuracy:  0.978, Validation Accuracy:  0.976, Loss:  0.871
Epoch  15 Batch  100/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.874
Epoch  15 Batch  101/153 - Train Accuracy:  0.982, Validation Accuracy:  0.974, Loss:  0.868
Epoch  15 Batch  102/153 - Train Accuracy:  0.979, Validation Accuracy:  0.975, Loss:  0.863
Epoch  15 Batch  103/153 - Train Accuracy:  0.978, Validation Accuracy:  0.977, Loss:  0.872
Epoch  15 Batch  104/153 - Train Accuracy:  0.988, Validation Accuracy:  0.975, Loss:  0.867
Epoch  15 Batch  105/153 - Train Accuracy:  0.986, Validation Accuracy:  0.973, Loss:  0.857
Epoch  15 Batch  106/153 - Train Accuracy:  0.979, Validation Accuracy:  0.971, Loss:  0.902
Epoch  15 Batch  107/153 - Train Accuracy:  0.982, Validation Accuracy:  0.974, Loss:  0.879
Epoch  15 Batch  108/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.864
Epoch  15 Batch  109/153 - Train Accuracy:  0.982, Validation Accuracy:  0.978, Loss:  0.856
Epoch  15 Batch  110/153 - Train Accuracy:  0.979, Validation Accuracy:  0.979, Loss:  0.857
Epoch  15 Batch  111/153 - Train Accuracy:  0.978, Validation Accuracy:  0.979, Loss:  0.870
Epoch  15 Batch  112/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.847
Epoch  15 Batch  113/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.878
Epoch  15 Batch  114/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.863
Epoch  15 Batch  115/153 - Train Accuracy:  0.979, Validation Accuracy:  0.977, Loss:  0.869
Epoch  15 Batch  116/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.869
Epoch  15 Batch  117/153 - Train Accuracy:  0.982, Validation Accuracy:  0.976, Loss:  0.863
Epoch  15 Batch  118/153 - Train Accuracy:  0.981, Validation Accuracy:  0.976, Loss:  0.856
Epoch  15 Batch  119/153 - Train Accuracy:  0.985, Validation Accuracy:  0.974, Loss:  0.854
Epoch  15 Batch  120/153 - Train Accuracy:  0.980, Validation Accuracy:  0.975, Loss:  0.876
Epoch  15 Batch  121/153 - Train Accuracy:  0.982, Validation Accuracy:  0.975, Loss:  0.855
Epoch  15 Batch  122/153 - Train Accuracy:  0.979, Validation Accuracy:  0.977, Loss:  0.855
Epoch  15 Batch  123/153 - Train Accuracy:  0.982, Validation Accuracy:  0.980, Loss:  0.872
Epoch  15 Batch  124/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.860
Epoch  15 Batch  125/153 - Train Accuracy:  0.977, Validation Accuracy:  0.978, Loss:  0.884
Epoch  15 Batch  126/153 - Train Accuracy:  0.977, Validation Accuracy:  0.980, Loss:  0.865
Epoch  15 Batch  127/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.873
Epoch  15 Batch  128/153 - Train Accuracy:  0.979, Validation Accuracy:  0.977, Loss:  0.868
Epoch  15 Batch  129/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.876
Epoch  15 Batch  130/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.862
Epoch  15 Batch  131/153 - Train Accuracy:  0.982, Validation Accuracy:  0.979, Loss:  0.879
Epoch  15 Batch  132/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.863
Epoch  15 Batch  133/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.886
Epoch  15 Batch  134/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.872
Epoch  15 Batch  135/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.885
Epoch  15 Batch  136/153 - Train Accuracy:  0.983, Validation Accuracy:  0.973, Loss:  0.862
Epoch  15 Batch  137/153 - Train Accuracy:  0.977, Validation Accuracy:  0.969, Loss:  0.862
Epoch  15 Batch  138/153 - Train Accuracy:  0.986, Validation Accuracy:  0.973, Loss:  0.848
Epoch  15 Batch  139/153 - Train Accuracy:  0.979, Validation Accuracy:  0.977, Loss:  0.857
Epoch  15 Batch  140/153 - Train Accuracy:  0.975, Validation Accuracy:  0.976, Loss:  0.858
Epoch  15 Batch  141/153 - Train Accuracy:  0.985, Validation Accuracy:  0.976, Loss:  0.873
Epoch  15 Batch  142/153 - Train Accuracy:  0.985, Validation Accuracy:  0.976, Loss:  0.857
Epoch  15 Batch  143/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.840
Epoch  15 Batch  144/153 - Train Accuracy:  0.980, Validation Accuracy:  0.975, Loss:  0.867
Epoch  15 Batch  145/153 - Train Accuracy:  0.975, Validation Accuracy:  0.969, Loss:  0.864
Epoch  15 Batch  146/153 - Train Accuracy:  0.978, Validation Accuracy:  0.968, Loss:  0.861
Epoch  15 Batch  147/153 - Train Accuracy:  0.980, Validation Accuracy:  0.973, Loss:  0.858
Epoch  15 Batch  148/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.868
Epoch  15 Batch  149/153 - Train Accuracy:  0.978, Validation Accuracy:  0.981, Loss:  0.874
Epoch  15 Batch  150/153 - Train Accuracy:  0.983, Validation Accuracy:  0.979, Loss:  0.880
Epoch  15 Batch  151/153 - Train Accuracy:  0.978, Validation Accuracy:  0.981, Loss:  0.887
Epoch  16 Batch    0/153 - Train Accuracy:  0.985, Validation Accuracy:  0.982, Loss:  0.867
Epoch  16 Batch    1/153 - Train Accuracy:  0.983, Validation Accuracy:  0.982, Loss:  0.859
Epoch  16 Batch    2/153 - Train Accuracy:  0.978, Validation Accuracy:  0.978, Loss:  0.886
Epoch  16 Batch    3/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.884
Epoch  16 Batch    4/153 - Train Accuracy:  0.985, Validation Accuracy:  0.974, Loss:  0.867
Epoch  16 Batch    5/153 - Train Accuracy:  0.982, Validation Accuracy:  0.975, Loss:  0.864
Epoch  16 Batch    6/153 - Train Accuracy:  0.978, Validation Accuracy:  0.977, Loss:  0.860
Epoch  16 Batch    7/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.863
Epoch  16 Batch    8/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.870
Epoch  16 Batch    9/153 - Train Accuracy:  0.980, Validation Accuracy:  0.981, Loss:  0.858
Epoch  16 Batch   10/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.894
Epoch  16 Batch   11/153 - Train Accuracy:  0.981, Validation Accuracy:  0.976, Loss:  0.857
Epoch  16 Batch   12/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.860
Epoch  16 Batch   13/153 - Train Accuracy:  0.981, Validation Accuracy:  0.978, Loss:  0.838
Epoch  16 Batch   14/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.877
Epoch  16 Batch   15/153 - Train Accuracy:  0.975, Validation Accuracy:  0.978, Loss:  0.864
Epoch  16 Batch   16/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.876
Epoch  16 Batch   17/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.892
Epoch  16 Batch   18/153 - Train Accuracy:  0.988, Validation Accuracy:  0.974, Loss:  0.860
Epoch  16 Batch   19/153 - Train Accuracy:  0.981, Validation Accuracy:  0.974, Loss:  0.846
Epoch  16 Batch   20/153 - Train Accuracy:  0.982, Validation Accuracy:  0.975, Loss:  0.880
Epoch  16 Batch   21/153 - Train Accuracy:  0.983, Validation Accuracy:  0.976, Loss:  0.858
Epoch  16 Batch   22/153 - Train Accuracy:  0.989, Validation Accuracy:  0.976, Loss:  0.862
Epoch  16 Batch   23/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.880
Epoch  16 Batch   24/153 - Train Accuracy:  0.982, Validation Accuracy:  0.974, Loss:  0.859
Epoch  16 Batch   25/153 - Train Accuracy:  0.979, Validation Accuracy:  0.975, Loss:  0.859
Epoch  16 Batch   26/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.886
Epoch  16 Batch   27/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.855
Epoch  16 Batch   28/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.886
Epoch  16 Batch   29/153 - Train Accuracy:  0.981, Validation Accuracy:  0.978, Loss:  0.862
Epoch  16 Batch   30/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.836
Epoch  16 Batch   31/153 - Train Accuracy:  0.982, Validation Accuracy:  0.979, Loss:  0.840
Epoch  16 Batch   32/153 - Train Accuracy:  0.983, Validation Accuracy:  0.982, Loss:  0.883
Epoch  16 Batch   33/153 - Train Accuracy:  0.983, Validation Accuracy:  0.980, Loss:  0.860
Epoch  16 Batch   34/153 - Train Accuracy:  0.982, Validation Accuracy:  0.979, Loss:  0.904
Epoch  16 Batch   35/153 - Train Accuracy:  0.979, Validation Accuracy:  0.977, Loss:  0.860
Epoch  16 Batch   36/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.862
Epoch  16 Batch   37/153 - Train Accuracy:  0.985, Validation Accuracy:  0.981, Loss:  0.868
Epoch  16 Batch   38/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.863
Epoch  16 Batch   39/153 - Train Accuracy:  0.979, Validation Accuracy:  0.980, Loss:  0.871
Epoch  16 Batch   40/153 - Train Accuracy:  0.981, Validation Accuracy:  0.981, Loss:  0.862
Epoch  16 Batch   41/153 - Train Accuracy:  0.984, Validation Accuracy:  0.980, Loss:  0.881
Epoch  16 Batch   42/153 - Train Accuracy:  0.982, Validation Accuracy:  0.981, Loss:  0.874
Epoch  16 Batch   43/153 - Train Accuracy:  0.983, Validation Accuracy:  0.980, Loss:  0.882
Epoch  16 Batch   44/153 - Train Accuracy:  0.986, Validation Accuracy:  0.981, Loss:  0.857
Epoch  16 Batch   45/153 - Train Accuracy:  0.986, Validation Accuracy:  0.981, Loss:  0.853
Epoch  16 Batch   46/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.867
Epoch  16 Batch   47/153 - Train Accuracy:  0.983, Validation Accuracy:  0.981, Loss:  0.868
Epoch  16 Batch   48/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.870
Epoch  16 Batch   49/153 - Train Accuracy:  0.989, Validation Accuracy:  0.974, Loss:  0.852
Epoch  16 Batch   50/153 - Train Accuracy:  0.986, Validation Accuracy:  0.975, Loss:  0.887
Epoch  16 Batch   51/153 - Train Accuracy:  0.981, Validation Accuracy:  0.978, Loss:  0.881
Epoch  16 Batch   52/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.846
Epoch  16 Batch   53/153 - Train Accuracy:  0.978, Validation Accuracy:  0.980, Loss:  0.874
Epoch  16 Batch   54/153 - Train Accuracy:  0.982, Validation Accuracy:  0.980, Loss:  0.862
Epoch  16 Batch   55/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.845
Epoch  16 Batch   56/153 - Train Accuracy:  0.978, Validation Accuracy:  0.977, Loss:  0.866
Epoch  16 Batch   57/153 - Train Accuracy:  0.983, Validation Accuracy:  0.975, Loss:  0.866
Epoch  16 Batch   58/153 - Train Accuracy:  0.985, Validation Accuracy:  0.976, Loss:  0.887
Epoch  16 Batch   59/153 - Train Accuracy:  0.982, Validation Accuracy:  0.975, Loss:  0.879
Epoch  16 Batch   60/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.865
Epoch  16 Batch   61/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.871
Epoch  16 Batch   62/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.861
Epoch  16 Batch   63/153 - Train Accuracy:  0.985, Validation Accuracy:  0.982, Loss:  0.869
Epoch  16 Batch   64/153 - Train Accuracy:  0.982, Validation Accuracy:  0.981, Loss:  0.859
Epoch  16 Batch   65/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.886
Epoch  16 Batch   66/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.852
Epoch  16 Batch   67/153 - Train Accuracy:  0.982, Validation Accuracy:  0.978, Loss:  0.870
Epoch  16 Batch   68/153 - Train Accuracy:  0.985, Validation Accuracy:  0.980, Loss:  0.872
Epoch  16 Batch   69/153 - Train Accuracy:  0.981, Validation Accuracy:  0.981, Loss:  0.863
Epoch  16 Batch   70/153 - Train Accuracy:  0.982, Validation Accuracy:  0.981, Loss:  0.875
Epoch  16 Batch   71/153 - Train Accuracy:  0.983, Validation Accuracy:  0.981, Loss:  0.845
Epoch  16 Batch   72/153 - Train Accuracy:  0.985, Validation Accuracy:  0.982, Loss:  0.861
Epoch  16 Batch   73/153 - Train Accuracy:  0.981, Validation Accuracy:  0.983, Loss:  0.851
Epoch  16 Batch   74/153 - Train Accuracy:  0.981, Validation Accuracy:  0.983, Loss:  0.882
Epoch  16 Batch   75/153 - Train Accuracy:  0.984, Validation Accuracy:  0.983, Loss:  0.865
Epoch  16 Batch   76/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.853
Epoch  16 Batch   77/153 - Train Accuracy:  0.986, Validation Accuracy:  0.983, Loss:  0.860
Epoch  16 Batch   78/153 - Train Accuracy:  0.985, Validation Accuracy:  0.984, Loss:  0.858
Epoch  16 Batch   79/153 - Train Accuracy:  0.987, Validation Accuracy:  0.984, Loss:  0.880
Epoch  16 Batch   80/153 - Train Accuracy:  0.989, Validation Accuracy:  0.985, Loss:  0.854
Epoch  16 Batch   81/153 - Train Accuracy:  0.981, Validation Accuracy:  0.984, Loss:  0.866
Epoch  16 Batch   82/153 - Train Accuracy:  0.986, Validation Accuracy:  0.982, Loss:  0.888
Epoch  16 Batch   83/153 - Train Accuracy:  0.986, Validation Accuracy:  0.983, Loss:  0.864
Epoch  16 Batch   84/153 - Train Accuracy:  0.988, Validation Accuracy:  0.982, Loss:  0.870
Epoch  16 Batch   85/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.851
Epoch  16 Batch   86/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.843
Epoch  16 Batch   87/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.896
Epoch  16 Batch   88/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.860
Epoch  16 Batch   89/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.891
Epoch  16 Batch   90/153 - Train Accuracy:  0.983, Validation Accuracy:  0.979, Loss:  0.850
Epoch  16 Batch   91/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.871
Epoch  16 Batch   92/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.866
Epoch  16 Batch   93/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.868
Epoch  16 Batch   94/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.869
Epoch  16 Batch   95/153 - Train Accuracy:  0.983, Validation Accuracy:  0.980, Loss:  0.845
Epoch  16 Batch   96/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.870
Epoch  16 Batch   97/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.862
Epoch  16 Batch   98/153 - Train Accuracy:  0.984, Validation Accuracy:  0.982, Loss:  0.862
Epoch  16 Batch   99/153 - Train Accuracy:  0.982, Validation Accuracy:  0.980, Loss:  0.855
Epoch  16 Batch  100/153 - Train Accuracy:  0.982, Validation Accuracy:  0.979, Loss:  0.865
Epoch  16 Batch  101/153 - Train Accuracy:  0.988, Validation Accuracy:  0.977, Loss:  0.875
Epoch  16 Batch  102/153 - Train Accuracy:  0.991, Validation Accuracy:  0.976, Loss:  0.863
Epoch  16 Batch  103/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.827
Epoch  16 Batch  104/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.850
Epoch  16 Batch  105/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.867
Epoch  16 Batch  106/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.882
Epoch  16 Batch  107/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.862
Epoch  16 Batch  108/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.898
Epoch  16 Batch  109/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.863
Epoch  16 Batch  110/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.848
Epoch  16 Batch  111/153 - Train Accuracy:  0.987, Validation Accuracy:  0.975, Loss:  0.863
Epoch  16 Batch  112/153 - Train Accuracy:  0.987, Validation Accuracy:  0.975, Loss:  0.876
Epoch  16 Batch  113/153 - Train Accuracy:  0.988, Validation Accuracy:  0.974, Loss:  0.842
Epoch  16 Batch  114/153 - Train Accuracy:  0.989, Validation Accuracy:  0.975, Loss:  0.857
Epoch  16 Batch  115/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.884
Epoch  16 Batch  116/153 - Train Accuracy:  0.988, Validation Accuracy:  0.977, Loss:  0.863
Epoch  16 Batch  117/153 - Train Accuracy:  0.983, Validation Accuracy:  0.979, Loss:  0.851
Epoch  16 Batch  118/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.875
Epoch  16 Batch  119/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.851
Epoch  16 Batch  120/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.856
Epoch  16 Batch  121/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.876
Epoch  16 Batch  122/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.864
Epoch  16 Batch  123/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.846
Epoch  16 Batch  124/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.859
Epoch  16 Batch  125/153 - Train Accuracy:  0.982, Validation Accuracy:  0.976, Loss:  0.882
Epoch  16 Batch  126/153 - Train Accuracy:  0.985, Validation Accuracy:  0.974, Loss:  0.861
Epoch  16 Batch  127/153 - Train Accuracy:  0.983, Validation Accuracy:  0.976, Loss:  0.856
Epoch  16 Batch  128/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.864
Epoch  16 Batch  129/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.876
Epoch  16 Batch  130/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.864
Epoch  16 Batch  131/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.869
Epoch  16 Batch  132/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.866
Epoch  16 Batch  133/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.857
Epoch  16 Batch  134/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.889
Epoch  16 Batch  135/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.875
Epoch  16 Batch  136/153 - Train Accuracy:  0.986, Validation Accuracy:  0.975, Loss:  0.880
Epoch  16 Batch  137/153 - Train Accuracy:  0.983, Validation Accuracy:  0.975, Loss:  0.853
Epoch  16 Batch  138/153 - Train Accuracy:  0.987, Validation Accuracy:  0.973, Loss:  0.852
Epoch  16 Batch  139/153 - Train Accuracy:  0.983, Validation Accuracy:  0.976, Loss:  0.872
Epoch  16 Batch  140/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.874
Epoch  16 Batch  141/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.871
Epoch  16 Batch  142/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.879
Epoch  16 Batch  143/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.874
Epoch  16 Batch  144/153 - Train Accuracy:  0.982, Validation Accuracy:  0.980, Loss:  0.892
Epoch  16 Batch  145/153 - Train Accuracy:  0.984, Validation Accuracy:  0.980, Loss:  0.866
Epoch  16 Batch  146/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.872
Epoch  16 Batch  147/153 - Train Accuracy:  0.982, Validation Accuracy:  0.974, Loss:  0.867
Epoch  16 Batch  148/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.845
Epoch  16 Batch  149/153 - Train Accuracy:  0.979, Validation Accuracy:  0.981, Loss:  0.872
Epoch  16 Batch  150/153 - Train Accuracy:  0.985, Validation Accuracy:  0.981, Loss:  0.879
Epoch  16 Batch  151/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.878
Epoch  17 Batch    0/153 - Train Accuracy:  0.982, Validation Accuracy:  0.978, Loss:  0.848
Epoch  17 Batch    1/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.869
Epoch  17 Batch    2/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.853
Epoch  17 Batch    3/153 - Train Accuracy:  0.983, Validation Accuracy:  0.974, Loss:  0.874
Epoch  17 Batch    4/153 - Train Accuracy:  0.988, Validation Accuracy:  0.971, Loss:  0.856
Epoch  17 Batch    5/153 - Train Accuracy:  0.986, Validation Accuracy:  0.973, Loss:  0.870
Epoch  17 Batch    6/153 - Train Accuracy:  0.981, Validation Accuracy:  0.974, Loss:  0.864
Epoch  17 Batch    7/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.884
Epoch  17 Batch    8/153 - Train Accuracy:  0.982, Validation Accuracy:  0.975, Loss:  0.852
Epoch  17 Batch    9/153 - Train Accuracy:  0.979, Validation Accuracy:  0.975, Loss:  0.864
Epoch  17 Batch   10/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.862
Epoch  17 Batch   11/153 - Train Accuracy:  0.983, Validation Accuracy:  0.974, Loss:  0.878
Epoch  17 Batch   12/153 - Train Accuracy:  0.984, Validation Accuracy:  0.970, Loss:  0.860
Epoch  17 Batch   13/153 - Train Accuracy:  0.977, Validation Accuracy:  0.972, Loss:  0.841
Epoch  17 Batch   14/153 - Train Accuracy:  0.984, Validation Accuracy:  0.974, Loss:  0.875
Epoch  17 Batch   15/153 - Train Accuracy:  0.976, Validation Accuracy:  0.977, Loss:  0.866
Epoch  17 Batch   16/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.882
Epoch  17 Batch   17/153 - Train Accuracy:  0.985, Validation Accuracy:  0.979, Loss:  0.873
Epoch  17 Batch   18/153 - Train Accuracy:  0.988, Validation Accuracy:  0.976, Loss:  0.877
Epoch  17 Batch   19/153 - Train Accuracy:  0.990, Validation Accuracy:  0.973, Loss:  0.855
Epoch  17 Batch   20/153 - Train Accuracy:  0.983, Validation Accuracy:  0.973, Loss:  0.856
Epoch  17 Batch   21/153 - Train Accuracy:  0.982, Validation Accuracy:  0.974, Loss:  0.881
Epoch  17 Batch   22/153 - Train Accuracy:  0.988, Validation Accuracy:  0.975, Loss:  0.892
Epoch  17 Batch   23/153 - Train Accuracy:  0.986, Validation Accuracy:  0.977, Loss:  0.857
Epoch  17 Batch   24/153 - Train Accuracy:  0.988, Validation Accuracy:  0.976, Loss:  0.871
Epoch  17 Batch   25/153 - Train Accuracy:  0.983, Validation Accuracy:  0.976, Loss:  0.862
Epoch  17 Batch   26/153 - Train Accuracy:  0.986, Validation Accuracy:  0.977, Loss:  0.851
Epoch  17 Batch   27/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.863
Epoch  17 Batch   28/153 - Train Accuracy:  0.987, Validation Accuracy:  0.975, Loss:  0.872
Epoch  17 Batch   29/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.858
Epoch  17 Batch   30/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.866
Epoch  17 Batch   31/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.876
Epoch  17 Batch   32/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.850
Epoch  17 Batch   33/153 - Train Accuracy:  0.986, Validation Accuracy:  0.974, Loss:  0.868
Epoch  17 Batch   34/153 - Train Accuracy:  0.980, Validation Accuracy:  0.975, Loss:  0.853
Epoch  17 Batch   35/153 - Train Accuracy:  0.980, Validation Accuracy:  0.977, Loss:  0.871
Epoch  17 Batch   36/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.863
Epoch  17 Batch   37/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.867
Epoch  17 Batch   38/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.850
Epoch  17 Batch   39/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.865
Epoch  17 Batch   40/153 - Train Accuracy:  0.985, Validation Accuracy:  0.979, Loss:  0.877
Epoch  17 Batch   41/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.844
Epoch  17 Batch   42/153 - Train Accuracy:  0.980, Validation Accuracy:  0.978, Loss:  0.842
Epoch  17 Batch   43/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.873
Epoch  17 Batch   44/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.844
Epoch  17 Batch   45/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.862
Epoch  17 Batch   46/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.869
Epoch  17 Batch   47/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.870
Epoch  17 Batch   48/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.862
Epoch  17 Batch   49/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.852
Epoch  17 Batch   50/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.879
Epoch  17 Batch   51/153 - Train Accuracy:  0.982, Validation Accuracy:  0.974, Loss:  0.854
Epoch  17 Batch   52/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.850
Epoch  17 Batch   53/153 - Train Accuracy:  0.983, Validation Accuracy:  0.976, Loss:  0.866
Epoch  17 Batch   54/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.872
Epoch  17 Batch   55/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.869
Epoch  17 Batch   56/153 - Train Accuracy:  0.983, Validation Accuracy:  0.981, Loss:  0.873
Epoch  17 Batch   57/153 - Train Accuracy:  0.985, Validation Accuracy:  0.982, Loss:  0.850
Epoch  17 Batch   58/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.872
Epoch  17 Batch   59/153 - Train Accuracy:  0.983, Validation Accuracy:  0.979, Loss:  0.890
Epoch  17 Batch   60/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.873
Epoch  17 Batch   61/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.852
Epoch  17 Batch   62/153 - Train Accuracy:  0.986, Validation Accuracy:  0.975, Loss:  0.865
Epoch  17 Batch   63/153 - Train Accuracy:  0.990, Validation Accuracy:  0.974, Loss:  0.858
Epoch  17 Batch   64/153 - Train Accuracy:  0.983, Validation Accuracy:  0.976, Loss:  0.866
Epoch  17 Batch   65/153 - Train Accuracy:  0.985, Validation Accuracy:  0.976, Loss:  0.873
Epoch  17 Batch   66/153 - Train Accuracy:  0.988, Validation Accuracy:  0.977, Loss:  0.862
Epoch  17 Batch   67/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.873
Epoch  17 Batch   68/153 - Train Accuracy:  0.986, Validation Accuracy:  0.977, Loss:  0.861
Epoch  17 Batch   69/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.863
Epoch  17 Batch   70/153 - Train Accuracy:  0.982, Validation Accuracy:  0.976, Loss:  0.847
Epoch  17 Batch   71/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.844
Epoch  17 Batch   72/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.879
Epoch  17 Batch   73/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.850
Epoch  17 Batch   74/153 - Train Accuracy:  0.984, Validation Accuracy:  0.980, Loss:  0.850
Epoch  17 Batch   75/153 - Train Accuracy:  0.981, Validation Accuracy:  0.980, Loss:  0.868
Epoch  17 Batch   76/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.849
Epoch  17 Batch   77/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.878
Epoch  17 Batch   78/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.844
Epoch  17 Batch   79/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.867
Epoch  17 Batch   80/153 - Train Accuracy:  0.988, Validation Accuracy:  0.984, Loss:  0.854
Epoch  17 Batch   81/153 - Train Accuracy:  0.984, Validation Accuracy:  0.986, Loss:  0.887
Epoch  17 Batch   82/153 - Train Accuracy:  0.992, Validation Accuracy:  0.985, Loss:  0.866
Epoch  17 Batch   83/153 - Train Accuracy:  0.989, Validation Accuracy:  0.983, Loss:  0.861
Epoch  17 Batch   84/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.850
Epoch  17 Batch   85/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.862
Epoch  17 Batch   86/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.864
Epoch  17 Batch   87/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.887
Epoch  17 Batch   88/153 - Train Accuracy:  0.983, Validation Accuracy:  0.979, Loss:  0.860
Epoch  17 Batch   89/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.870
Epoch  17 Batch   90/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.861
Epoch  17 Batch   91/153 - Train Accuracy:  0.986, Validation Accuracy:  0.981, Loss:  0.844
Epoch  17 Batch   92/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.867
Epoch  17 Batch   93/153 - Train Accuracy:  0.992, Validation Accuracy:  0.983, Loss:  0.863
Epoch  17 Batch   94/153 - Train Accuracy:  0.988, Validation Accuracy:  0.982, Loss:  0.857
Epoch  17 Batch   95/153 - Train Accuracy:  0.986, Validation Accuracy:  0.981, Loss:  0.866
Epoch  17 Batch   96/153 - Train Accuracy:  0.983, Validation Accuracy:  0.982, Loss:  0.875
Epoch  17 Batch   97/153 - Train Accuracy:  0.988, Validation Accuracy:  0.984, Loss:  0.859
Epoch  17 Batch   98/153 - Train Accuracy:  0.986, Validation Accuracy:  0.982, Loss:  0.850
Epoch  17 Batch   99/153 - Train Accuracy:  0.986, Validation Accuracy:  0.982, Loss:  0.870
Epoch  17 Batch  100/153 - Train Accuracy:  0.986, Validation Accuracy:  0.983, Loss:  0.862
Epoch  17 Batch  101/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.861
Epoch  17 Batch  102/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.862
Epoch  17 Batch  103/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.853
Epoch  17 Batch  104/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.865
Epoch  17 Batch  105/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.842
Epoch  17 Batch  106/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.854
Epoch  17 Batch  107/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.876
Epoch  17 Batch  108/153 - Train Accuracy:  0.989, Validation Accuracy:  0.976, Loss:  0.866
Epoch  17 Batch  109/153 - Train Accuracy:  0.989, Validation Accuracy:  0.976, Loss:  0.856
Epoch  17 Batch  110/153 - Train Accuracy:  0.988, Validation Accuracy:  0.976, Loss:  0.880
Epoch  17 Batch  111/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.848
Epoch  17 Batch  112/153 - Train Accuracy:  0.988, Validation Accuracy:  0.977, Loss:  0.883
Epoch  17 Batch  113/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.847
Epoch  17 Batch  114/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.869
Epoch  17 Batch  115/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.880
Epoch  17 Batch  116/153 - Train Accuracy:  0.985, Validation Accuracy:  0.975, Loss:  0.875
Epoch  17 Batch  117/153 - Train Accuracy:  0.988, Validation Accuracy:  0.977, Loss:  0.873
Epoch  17 Batch  118/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.856
Epoch  17 Batch  119/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.871
Epoch  17 Batch  120/153 - Train Accuracy:  0.982, Validation Accuracy:  0.979, Loss:  0.850
Epoch  17 Batch  121/153 - Train Accuracy:  0.986, Validation Accuracy:  0.981, Loss:  0.874
Epoch  17 Batch  122/153 - Train Accuracy:  0.986, Validation Accuracy:  0.981, Loss:  0.859
Epoch  17 Batch  123/153 - Train Accuracy:  0.985, Validation Accuracy:  0.980, Loss:  0.854
Epoch  17 Batch  124/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.863
Epoch  17 Batch  125/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.874
Epoch  17 Batch  126/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.852
Epoch  17 Batch  127/153 - Train Accuracy:  0.986, Validation Accuracy:  0.975, Loss:  0.850
Epoch  17 Batch  128/153 - Train Accuracy:  0.989, Validation Accuracy:  0.974, Loss:  0.853
Epoch  17 Batch  129/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.866
Epoch  17 Batch  130/153 - Train Accuracy:  0.990, Validation Accuracy:  0.976, Loss:  0.865
Epoch  17 Batch  131/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.861
Epoch  17 Batch  132/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.859
Epoch  17 Batch  133/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.873
Epoch  17 Batch  134/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.885
Epoch  17 Batch  135/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.849
Epoch  17 Batch  136/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.866
Epoch  17 Batch  137/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.863
Epoch  17 Batch  138/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.872
Epoch  17 Batch  139/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.861
Epoch  17 Batch  140/153 - Train Accuracy:  0.985, Validation Accuracy:  0.982, Loss:  0.872
Epoch  17 Batch  141/153 - Train Accuracy:  0.988, Validation Accuracy:  0.984, Loss:  0.866
Epoch  17 Batch  142/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.851
Epoch  17 Batch  143/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.870
Epoch  17 Batch  144/153 - Train Accuracy:  0.987, Validation Accuracy:  0.983, Loss:  0.863
Epoch  17 Batch  145/153 - Train Accuracy:  0.985, Validation Accuracy:  0.982, Loss:  0.877
Epoch  17 Batch  146/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.881
Epoch  17 Batch  147/153 - Train Accuracy:  0.983, Validation Accuracy:  0.980, Loss:  0.864
Epoch  17 Batch  148/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.853
Epoch  17 Batch  149/153 - Train Accuracy:  0.982, Validation Accuracy:  0.980, Loss:  0.873
Epoch  17 Batch  150/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.858
Epoch  17 Batch  151/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.878
Epoch  18 Batch    0/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.856
Epoch  18 Batch    1/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.850
Epoch  18 Batch    2/153 - Train Accuracy:  0.983, Validation Accuracy:  0.975, Loss:  0.877
Epoch  18 Batch    3/153 - Train Accuracy:  0.985, Validation Accuracy:  0.974, Loss:  0.866
Epoch  18 Batch    4/153 - Train Accuracy:  0.985, Validation Accuracy:  0.971, Loss:  0.863
Epoch  18 Batch    5/153 - Train Accuracy:  0.985, Validation Accuracy:  0.973, Loss:  0.878
Epoch  18 Batch    6/153 - Train Accuracy:  0.988, Validation Accuracy:  0.975, Loss:  0.860
Epoch  18 Batch    7/153 - Train Accuracy:  0.990, Validation Accuracy:  0.976, Loss:  0.872
Epoch  18 Batch    8/153 - Train Accuracy:  0.988, Validation Accuracy:  0.976, Loss:  0.868
Epoch  18 Batch    9/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.856
Epoch  18 Batch   10/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.863
Epoch  18 Batch   11/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.865
Epoch  18 Batch   12/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.843
Epoch  18 Batch   13/153 - Train Accuracy:  0.986, Validation Accuracy:  0.974, Loss:  0.870
Epoch  18 Batch   14/153 - Train Accuracy:  0.982, Validation Accuracy:  0.972, Loss:  0.835
Epoch  18 Batch   15/153 - Train Accuracy:  0.984, Validation Accuracy:  0.972, Loss:  0.888
Epoch  18 Batch   16/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.881
Epoch  18 Batch   17/153 - Train Accuracy:  0.983, Validation Accuracy:  0.982, Loss:  0.869
Epoch  18 Batch   18/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.856
Epoch  18 Batch   19/153 - Train Accuracy:  0.985, Validation Accuracy:  0.979, Loss:  0.841
Epoch  18 Batch   20/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.856
Epoch  18 Batch   21/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.882
Epoch  18 Batch   22/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.869
Epoch  18 Batch   23/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.889
Epoch  18 Batch   24/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.841
Epoch  18 Batch   25/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.860
Epoch  18 Batch   26/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.867
Epoch  18 Batch   27/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.865
Epoch  18 Batch   28/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.873
Epoch  18 Batch   29/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.865
Epoch  18 Batch   30/153 - Train Accuracy:  0.989, Validation Accuracy:  0.975, Loss:  0.868
Epoch  18 Batch   31/153 - Train Accuracy:  0.982, Validation Accuracy:  0.975, Loss:  0.860
Epoch  18 Batch   32/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.855
Epoch  18 Batch   33/153 - Train Accuracy:  0.986, Validation Accuracy:  0.977, Loss:  0.871
Epoch  18 Batch   34/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.857
Epoch  18 Batch   35/153 - Train Accuracy:  0.983, Validation Accuracy:  0.980, Loss:  0.835
Epoch  18 Batch   36/153 - Train Accuracy:  0.988, Validation Accuracy:  0.982, Loss:  0.852
Epoch  18 Batch   37/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.877
Epoch  18 Batch   38/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.854
Epoch  18 Batch   39/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.860
Epoch  18 Batch   40/153 - Train Accuracy:  0.984, Validation Accuracy:  0.982, Loss:  0.868
Epoch  18 Batch   41/153 - Train Accuracy:  0.985, Validation Accuracy:  0.980, Loss:  0.848
Epoch  18 Batch   42/153 - Train Accuracy:  0.981, Validation Accuracy:  0.978, Loss:  0.869
Epoch  18 Batch   43/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.853
Epoch  18 Batch   44/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.874
Epoch  18 Batch   45/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.872
Epoch  18 Batch   46/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.888
Epoch  18 Batch   47/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.878
Epoch  18 Batch   48/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.861
Epoch  18 Batch   49/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.866
Epoch  18 Batch   50/153 - Train Accuracy:  0.985, Validation Accuracy:  0.980, Loss:  0.853
Epoch  18 Batch   51/153 - Train Accuracy:  0.985, Validation Accuracy:  0.980, Loss:  0.868
Epoch  18 Batch   52/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.853
Epoch  18 Batch   53/153 - Train Accuracy:  0.985, Validation Accuracy:  0.979, Loss:  0.858
Epoch  18 Batch   54/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.857
Epoch  18 Batch   55/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.849
Epoch  18 Batch   56/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.892
Epoch  18 Batch   57/153 - Train Accuracy:  0.985, Validation Accuracy:  0.979, Loss:  0.877
Epoch  18 Batch   58/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.858
Epoch  18 Batch   59/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.857
Epoch  18 Batch   60/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.849
Epoch  18 Batch   61/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.859
Epoch  18 Batch   62/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.870
Epoch  18 Batch   63/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.873
Epoch  18 Batch   64/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.844
Epoch  18 Batch   65/153 - Train Accuracy:  0.989, Validation Accuracy:  0.976, Loss:  0.861
Epoch  18 Batch   66/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.863
Epoch  18 Batch   67/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.856
Epoch  18 Batch   68/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.850
Epoch  18 Batch   69/153 - Train Accuracy:  0.984, Validation Accuracy:  0.980, Loss:  0.887
Epoch  18 Batch   70/153 - Train Accuracy:  0.985, Validation Accuracy:  0.980, Loss:  0.871
Epoch  18 Batch   71/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.870
Epoch  18 Batch   72/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.851
Epoch  18 Batch   73/153 - Train Accuracy:  0.986, Validation Accuracy:  0.982, Loss:  0.867
Epoch  18 Batch   74/153 - Train Accuracy:  0.983, Validation Accuracy:  0.984, Loss:  0.855
Epoch  18 Batch   75/153 - Train Accuracy:  0.980, Validation Accuracy:  0.985, Loss:  0.867
Epoch  18 Batch   76/153 - Train Accuracy:  0.987, Validation Accuracy:  0.984, Loss:  0.860
Epoch  18 Batch   77/153 - Train Accuracy:  0.988, Validation Accuracy:  0.984, Loss:  0.850
Epoch  18 Batch   78/153 - Train Accuracy:  0.988, Validation Accuracy:  0.983, Loss:  0.858
Epoch  18 Batch   79/153 - Train Accuracy:  0.988, Validation Accuracy:  0.983, Loss:  0.853
Epoch  18 Batch   80/153 - Train Accuracy:  0.990, Validation Accuracy:  0.985, Loss:  0.866
Epoch  18 Batch   81/153 - Train Accuracy:  0.987, Validation Accuracy:  0.984, Loss:  0.866
Epoch  18 Batch   82/153 - Train Accuracy:  0.991, Validation Accuracy:  0.984, Loss:  0.860
Epoch  18 Batch   83/153 - Train Accuracy:  0.988, Validation Accuracy:  0.983, Loss:  0.877
Epoch  18 Batch   84/153 - Train Accuracy:  0.986, Validation Accuracy:  0.982, Loss:  0.850
Epoch  18 Batch   85/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.850
Epoch  18 Batch   86/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.860
Epoch  18 Batch   87/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.869
Epoch  18 Batch   88/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.878
Epoch  18 Batch   89/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.844
Epoch  18 Batch   90/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.852
Epoch  18 Batch   91/153 - Train Accuracy:  0.986, Validation Accuracy:  0.981, Loss:  0.873
Epoch  18 Batch   92/153 - Train Accuracy:  0.988, Validation Accuracy:  0.982, Loss:  0.854
Epoch  18 Batch   93/153 - Train Accuracy:  0.988, Validation Accuracy:  0.982, Loss:  0.846
Epoch  18 Batch   94/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.869
Epoch  18 Batch   95/153 - Train Accuracy:  0.989, Validation Accuracy:  0.985, Loss:  0.856
Epoch  18 Batch   96/153 - Train Accuracy:  0.985, Validation Accuracy:  0.984, Loss:  0.851
Epoch  18 Batch   97/153 - Train Accuracy:  0.990, Validation Accuracy:  0.983, Loss:  0.870
Epoch  18 Batch   98/153 - Train Accuracy:  0.987, Validation Accuracy:  0.983, Loss:  0.886
Epoch  18 Batch   99/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.851
Epoch  18 Batch  100/153 - Train Accuracy:  0.986, Validation Accuracy:  0.982, Loss:  0.881
Epoch  18 Batch  101/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.863
Epoch  18 Batch  102/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.866
Epoch  18 Batch  103/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.865
Epoch  18 Batch  104/153 - Train Accuracy:  0.987, Validation Accuracy:  0.975, Loss:  0.849
Epoch  18 Batch  105/153 - Train Accuracy:  0.988, Validation Accuracy:  0.974, Loss:  0.850
Epoch  18 Batch  106/153 - Train Accuracy:  0.985, Validation Accuracy:  0.974, Loss:  0.865
Epoch  18 Batch  107/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.874
Epoch  18 Batch  108/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.859
Epoch  18 Batch  109/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.852
Epoch  18 Batch  110/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.858
Epoch  18 Batch  111/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.857
Epoch  18 Batch  112/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.854
Epoch  18 Batch  113/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.854
Epoch  18 Batch  114/153 - Train Accuracy:  0.992, Validation Accuracy:  0.977, Loss:  0.873
Epoch  18 Batch  115/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.874
Epoch  18 Batch  116/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.853
Epoch  18 Batch  117/153 - Train Accuracy:  0.991, Validation Accuracy:  0.977, Loss:  0.855
Epoch  18 Batch  118/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.880
Epoch  18 Batch  119/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.860
Epoch  18 Batch  120/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.859
Epoch  18 Batch  121/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.911
Epoch  18 Batch  122/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.850
Epoch  18 Batch  123/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.892
Epoch  18 Batch  124/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.853
Epoch  18 Batch  125/153 - Train Accuracy:  0.983, Validation Accuracy:  0.980, Loss:  0.882
Epoch  18 Batch  126/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.839
Epoch  18 Batch  127/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.853
Epoch  18 Batch  128/153 - Train Accuracy:  0.992, Validation Accuracy:  0.976, Loss:  0.872
Epoch  18 Batch  129/153 - Train Accuracy:  0.986, Validation Accuracy:  0.975, Loss:  0.874
Epoch  18 Batch  130/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.863
Epoch  18 Batch  131/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.877
Epoch  18 Batch  132/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.858
Epoch  18 Batch  133/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.885
Epoch  18 Batch  134/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.879
Epoch  18 Batch  135/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.867
Epoch  18 Batch  136/153 - Train Accuracy:  0.984, Validation Accuracy:  0.980, Loss:  0.869
Epoch  18 Batch  137/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.860
Epoch  18 Batch  138/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.871
Epoch  18 Batch  139/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.855
Epoch  18 Batch  140/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.873
Epoch  18 Batch  141/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.867
Epoch  18 Batch  142/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.867
Epoch  18 Batch  143/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.869
Epoch  18 Batch  144/153 - Train Accuracy:  0.985, Validation Accuracy:  0.979, Loss:  0.869
Epoch  18 Batch  145/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.864
Epoch  18 Batch  146/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.871
Epoch  18 Batch  147/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.855
Epoch  18 Batch  148/153 - Train Accuracy:  0.984, Validation Accuracy:  0.976, Loss:  0.871
Epoch  18 Batch  149/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.888
Epoch  18 Batch  150/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.873
Epoch  18 Batch  151/153 - Train Accuracy:  0.986, Validation Accuracy:  0.982, Loss:  0.886
Epoch  19 Batch    0/153 - Train Accuracy:  0.985, Validation Accuracy:  0.981, Loss:  0.892
Epoch  19 Batch    1/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.885
Epoch  19 Batch    2/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.841
Epoch  19 Batch    3/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.871
Epoch  19 Batch    4/153 - Train Accuracy:  0.987, Validation Accuracy:  0.974, Loss:  0.867
Epoch  19 Batch    5/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.864
Epoch  19 Batch    6/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.870
Epoch  19 Batch    7/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.866
Epoch  19 Batch    8/153 - Train Accuracy:  0.985, Validation Accuracy:  0.981, Loss:  0.860
Epoch  19 Batch    9/153 - Train Accuracy:  0.984, Validation Accuracy:  0.980, Loss:  0.858
Epoch  19 Batch   10/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.846
Epoch  19 Batch   11/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.859
Epoch  19 Batch   12/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.882
Epoch  19 Batch   13/153 - Train Accuracy:  0.986, Validation Accuracy:  0.977, Loss:  0.873
Epoch  19 Batch   14/153 - Train Accuracy:  0.989, Validation Accuracy:  0.975, Loss:  0.849
Epoch  19 Batch   15/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.875
Epoch  19 Batch   16/153 - Train Accuracy:  0.984, Validation Accuracy:  0.977, Loss:  0.867
Epoch  19 Batch   17/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.873
Epoch  19 Batch   18/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.852
Epoch  19 Batch   19/153 - Train Accuracy:  0.992, Validation Accuracy:  0.977, Loss:  0.860
Epoch  19 Batch   20/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.895
Epoch  19 Batch   21/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.858
Epoch  19 Batch   22/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.870
Epoch  19 Batch   23/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.857
Epoch  19 Batch   24/153 - Train Accuracy:  0.989, Validation Accuracy:  0.975, Loss:  0.882
Epoch  19 Batch   25/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.863
Epoch  19 Batch   26/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.887
Epoch  19 Batch   27/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.864
Epoch  19 Batch   28/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.861
Epoch  19 Batch   29/153 - Train Accuracy:  0.981, Validation Accuracy:  0.976, Loss:  0.864
Epoch  19 Batch   30/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.857
Epoch  19 Batch   31/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.847
Epoch  19 Batch   32/153 - Train Accuracy:  0.985, Validation Accuracy:  0.975, Loss:  0.855
Epoch  19 Batch   33/153 - Train Accuracy:  0.985, Validation Accuracy:  0.974, Loss:  0.847
Epoch  19 Batch   34/153 - Train Accuracy:  0.986, Validation Accuracy:  0.975, Loss:  0.883
Epoch  19 Batch   35/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.877
Epoch  19 Batch   36/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.867
Epoch  19 Batch   37/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.868
Epoch  19 Batch   38/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.865
Epoch  19 Batch   39/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.878
Epoch  19 Batch   40/153 - Train Accuracy:  0.985, Validation Accuracy:  0.980, Loss:  0.857
Epoch  19 Batch   41/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.847
Epoch  19 Batch   42/153 - Train Accuracy:  0.985, Validation Accuracy:  0.974, Loss:  0.847
Epoch  19 Batch   43/153 - Train Accuracy:  0.990, Validation Accuracy:  0.973, Loss:  0.861
Epoch  19 Batch   44/153 - Train Accuracy:  0.984, Validation Accuracy:  0.975, Loss:  0.858
Epoch  19 Batch   45/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.878
Epoch  19 Batch   46/153 - Train Accuracy:  0.991, Validation Accuracy:  0.977, Loss:  0.849
Epoch  19 Batch   47/153 - Train Accuracy:  0.988, Validation Accuracy:  0.977, Loss:  0.882
Epoch  19 Batch   48/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.850
Epoch  19 Batch   49/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.879
Epoch  19 Batch   50/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.874
Epoch  19 Batch   51/153 - Train Accuracy:  0.985, Validation Accuracy:  0.979, Loss:  0.831
Epoch  19 Batch   52/153 - Train Accuracy:  0.989, Validation Accuracy:  0.975, Loss:  0.863
Epoch  19 Batch   53/153 - Train Accuracy:  0.987, Validation Accuracy:  0.971, Loss:  0.867
Epoch  19 Batch   54/153 - Train Accuracy:  0.984, Validation Accuracy:  0.972, Loss:  0.871
Epoch  19 Batch   55/153 - Train Accuracy:  0.986, Validation Accuracy:  0.974, Loss:  0.875
Epoch  19 Batch   56/153 - Train Accuracy:  0.988, Validation Accuracy:  0.976, Loss:  0.875
Epoch  19 Batch   57/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.858
Epoch  19 Batch   58/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.865
Epoch  19 Batch   59/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.868
Epoch  19 Batch   60/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.862
Epoch  19 Batch   61/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.837
Epoch  19 Batch   62/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.860
Epoch  19 Batch   63/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.858
Epoch  19 Batch   64/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.859
Epoch  19 Batch   65/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.877
Epoch  19 Batch   66/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.865
Epoch  19 Batch   67/153 - Train Accuracy:  0.983, Validation Accuracy:  0.976, Loss:  0.865
Epoch  19 Batch   68/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.875
Epoch  19 Batch   69/153 - Train Accuracy:  0.986, Validation Accuracy:  0.981, Loss:  0.867
Epoch  19 Batch   70/153 - Train Accuracy:  0.988, Validation Accuracy:  0.982, Loss:  0.835
Epoch  19 Batch   71/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.862
Epoch  19 Batch   72/153 - Train Accuracy:  0.988, Validation Accuracy:  0.982, Loss:  0.878
Epoch  19 Batch   73/153 - Train Accuracy:  0.986, Validation Accuracy:  0.982, Loss:  0.875
Epoch  19 Batch   74/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.867
Epoch  19 Batch   75/153 - Train Accuracy:  0.984, Validation Accuracy:  0.982, Loss:  0.848
Epoch  19 Batch   76/153 - Train Accuracy:  0.988, Validation Accuracy:  0.982, Loss:  0.840
Epoch  19 Batch   77/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.862
Epoch  19 Batch   78/153 - Train Accuracy:  0.988, Validation Accuracy:  0.982, Loss:  0.859
Epoch  19 Batch   79/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.849
Epoch  19 Batch   80/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.891
Epoch  19 Batch   81/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.852
Epoch  19 Batch   82/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.847
Epoch  19 Batch   83/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.874
Epoch  19 Batch   84/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.870
Epoch  19 Batch   85/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.879
Epoch  19 Batch   86/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.848
Epoch  19 Batch   87/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.848
Epoch  19 Batch   88/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.857
Epoch  19 Batch   89/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.856
Epoch  19 Batch   90/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.871
Epoch  19 Batch   91/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.854
Epoch  19 Batch   92/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.874
Epoch  19 Batch   93/153 - Train Accuracy:  0.992, Validation Accuracy:  0.981, Loss:  0.874
Epoch  19 Batch   94/153 - Train Accuracy:  0.992, Validation Accuracy:  0.979, Loss:  0.874
Epoch  19 Batch   95/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.882
Epoch  19 Batch   96/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.868
Epoch  19 Batch   97/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.878
Epoch  19 Batch   98/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.854
Epoch  19 Batch   99/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.881
Epoch  19 Batch  100/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.892
Epoch  19 Batch  101/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.866
Epoch  19 Batch  102/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.860
Epoch  19 Batch  103/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.853
Epoch  19 Batch  104/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.859
Epoch  19 Batch  105/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.863
Epoch  19 Batch  106/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.881
Epoch  19 Batch  107/153 - Train Accuracy:  0.993, Validation Accuracy:  0.978, Loss:  0.880
Epoch  19 Batch  108/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.873
Epoch  19 Batch  109/153 - Train Accuracy:  0.991, Validation Accuracy:  0.977, Loss:  0.852
Epoch  19 Batch  110/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.853
Epoch  19 Batch  111/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.891
Epoch  19 Batch  112/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.878
Epoch  19 Batch  113/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.881
Epoch  19 Batch  114/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.863
Epoch  19 Batch  115/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.871
Epoch  19 Batch  116/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.858
Epoch  19 Batch  117/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.857
Epoch  19 Batch  118/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.876
Epoch  19 Batch  119/153 - Train Accuracy:  0.992, Validation Accuracy:  0.981, Loss:  0.858
Epoch  19 Batch  120/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.865
Epoch  19 Batch  121/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.845
Epoch  19 Batch  122/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.858
Epoch  19 Batch  123/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.832
Epoch  19 Batch  124/153 - Train Accuracy:  0.988, Validation Accuracy:  0.976, Loss:  0.873
Epoch  19 Batch  125/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.850
Epoch  19 Batch  126/153 - Train Accuracy:  0.992, Validation Accuracy:  0.977, Loss:  0.847
Epoch  19 Batch  127/153 - Train Accuracy:  0.992, Validation Accuracy:  0.979, Loss:  0.883
Epoch  19 Batch  128/153 - Train Accuracy:  0.991, Validation Accuracy:  0.977, Loss:  0.855
Epoch  19 Batch  129/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.874
Epoch  19 Batch  130/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.871
Epoch  19 Batch  131/153 - Train Accuracy:  0.988, Validation Accuracy:  0.977, Loss:  0.873
Epoch  19 Batch  132/153 - Train Accuracy:  0.992, Validation Accuracy:  0.979, Loss:  0.863
Epoch  19 Batch  133/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.858
Epoch  19 Batch  134/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.853
Epoch  19 Batch  135/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.866
Epoch  19 Batch  136/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.861
Epoch  19 Batch  137/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.868
Epoch  19 Batch  138/153 - Train Accuracy:  0.992, Validation Accuracy:  0.977, Loss:  0.857
Epoch  19 Batch  139/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.851
Epoch  19 Batch  140/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.883
Epoch  19 Batch  141/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.866
Epoch  19 Batch  142/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.882
Epoch  19 Batch  143/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.873
Epoch  19 Batch  144/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.857
Epoch  19 Batch  145/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.859
Epoch  19 Batch  146/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.868
Epoch  19 Batch  147/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.836
Epoch  19 Batch  148/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.840
Epoch  19 Batch  149/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.872
Epoch  19 Batch  150/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.857
Epoch  19 Batch  151/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.878
Epoch  20 Batch    0/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.862
Epoch  20 Batch    1/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.861
Epoch  20 Batch    2/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.873
Epoch  20 Batch    3/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.870
Epoch  20 Batch    4/153 - Train Accuracy:  0.993, Validation Accuracy:  0.977, Loss:  0.850
Epoch  20 Batch    5/153 - Train Accuracy:  0.989, Validation Accuracy:  0.976, Loss:  0.848
Epoch  20 Batch    6/153 - Train Accuracy:  0.988, Validation Accuracy:  0.973, Loss:  0.880
Epoch  20 Batch    7/153 - Train Accuracy:  0.991, Validation Accuracy:  0.974, Loss:  0.873
Epoch  20 Batch    8/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.890
Epoch  20 Batch    9/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.877
Epoch  20 Batch   10/153 - Train Accuracy:  0.988, Validation Accuracy:  0.974, Loss:  0.871
Epoch  20 Batch   11/153 - Train Accuracy:  0.990, Validation Accuracy:  0.973, Loss:  0.864
Epoch  20 Batch   12/153 - Train Accuracy:  0.989, Validation Accuracy:  0.975, Loss:  0.857
Epoch  20 Batch   13/153 - Train Accuracy:  0.983, Validation Accuracy:  0.978, Loss:  0.856
Epoch  20 Batch   14/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.851
Epoch  20 Batch   15/153 - Train Accuracy:  0.983, Validation Accuracy:  0.977, Loss:  0.879
Epoch  20 Batch   16/153 - Train Accuracy:  0.985, Validation Accuracy:  0.971, Loss:  0.879
Epoch  20 Batch   17/153 - Train Accuracy:  0.986, Validation Accuracy:  0.971, Loss:  0.862
Epoch  20 Batch   18/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.833
Epoch  20 Batch   19/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.856
Epoch  20 Batch   20/153 - Train Accuracy:  0.981, Validation Accuracy:  0.977, Loss:  0.887
Epoch  20 Batch   21/153 - Train Accuracy:  0.982, Validation Accuracy:  0.975, Loss:  0.859
Epoch  20 Batch   22/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.860
Epoch  20 Batch   23/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.877
Epoch  20 Batch   24/153 - Train Accuracy:  0.988, Validation Accuracy:  0.977, Loss:  0.882
Epoch  20 Batch   25/153 - Train Accuracy:  0.983, Validation Accuracy:  0.969, Loss:  0.866
Epoch  20 Batch   26/153 - Train Accuracy:  0.982, Validation Accuracy:  0.972, Loss:  0.854
Epoch  20 Batch   27/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.847
Epoch  20 Batch   28/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.866
Epoch  20 Batch   29/153 - Train Accuracy:  0.982, Validation Accuracy:  0.977, Loss:  0.870
Epoch  20 Batch   30/153 - Train Accuracy:  0.986, Validation Accuracy:  0.974, Loss:  0.861
Epoch  20 Batch   31/153 - Train Accuracy:  0.981, Validation Accuracy:  0.975, Loss:  0.852
Epoch  20 Batch   32/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.855
Epoch  20 Batch   33/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.867
Epoch  20 Batch   34/153 - Train Accuracy:  0.984, Validation Accuracy:  0.980, Loss:  0.854
Epoch  20 Batch   35/153 - Train Accuracy:  0.983, Validation Accuracy:  0.976, Loss:  0.875
Epoch  20 Batch   36/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.839
Epoch  20 Batch   37/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.868
Epoch  20 Batch   38/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.855
Epoch  20 Batch   39/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.873
Epoch  20 Batch   40/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.860
Epoch  20 Batch   41/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.853
Epoch  20 Batch   42/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.857
Epoch  20 Batch   43/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.861
Epoch  20 Batch   44/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.869
Epoch  20 Batch   45/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.860
Epoch  20 Batch   46/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.856
Epoch  20 Batch   47/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.879
Epoch  20 Batch   48/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.841
Epoch  20 Batch   49/153 - Train Accuracy:  0.991, Validation Accuracy:  0.977, Loss:  0.847
Epoch  20 Batch   50/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.883
Epoch  20 Batch   51/153 - Train Accuracy:  0.982, Validation Accuracy:  0.974, Loss:  0.865
Epoch  20 Batch   52/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.863
Epoch  20 Batch   53/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.878
Epoch  20 Batch   54/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.851
Epoch  20 Batch   55/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.870
Epoch  20 Batch   56/153 - Train Accuracy:  0.985, Validation Accuracy:  0.974, Loss:  0.862
Epoch  20 Batch   57/153 - Train Accuracy:  0.989, Validation Accuracy:  0.976, Loss:  0.881
Epoch  20 Batch   58/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.883
Epoch  20 Batch   59/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.873
Epoch  20 Batch   60/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.851
Epoch  20 Batch   61/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.863
Epoch  20 Batch   62/153 - Train Accuracy:  0.984, Validation Accuracy:  0.978, Loss:  0.874
Epoch  20 Batch   63/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.864
Epoch  20 Batch   64/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.882
Epoch  20 Batch   65/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.859
Epoch  20 Batch   66/153 - Train Accuracy:  0.991, Validation Accuracy:  0.975, Loss:  0.881
Epoch  20 Batch   67/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.824
Epoch  20 Batch   68/153 - Train Accuracy:  0.987, Validation Accuracy:  0.975, Loss:  0.885
Epoch  20 Batch   69/153 - Train Accuracy:  0.986, Validation Accuracy:  0.976, Loss:  0.869
Epoch  20 Batch   70/153 - Train Accuracy:  0.987, Validation Accuracy:  0.976, Loss:  0.882
Epoch  20 Batch   71/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.874
Epoch  20 Batch   72/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.848
Epoch  20 Batch   73/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.847
Epoch  20 Batch   74/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.849
Epoch  20 Batch   75/153 - Train Accuracy:  0.985, Validation Accuracy:  0.977, Loss:  0.882
Epoch  20 Batch   76/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.861
Epoch  20 Batch   77/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.859
Epoch  20 Batch   78/153 - Train Accuracy:  0.989, Validation Accuracy:  0.983, Loss:  0.874
Epoch  20 Batch   79/153 - Train Accuracy:  0.988, Validation Accuracy:  0.984, Loss:  0.868
Epoch  20 Batch   80/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.857
Epoch  20 Batch   81/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.880
Epoch  20 Batch   82/153 - Train Accuracy:  0.995, Validation Accuracy:  0.981, Loss:  0.855
Epoch  20 Batch   83/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.862
Epoch  20 Batch   84/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.846
Epoch  20 Batch   85/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.856
Epoch  20 Batch   86/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.876
Epoch  20 Batch   87/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.871
Epoch  20 Batch   88/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.846
Epoch  20 Batch   89/153 - Train Accuracy:  0.990, Validation Accuracy:  0.983, Loss:  0.848
Epoch  20 Batch   90/153 - Train Accuracy:  0.989, Validation Accuracy:  0.986, Loss:  0.855
Epoch  20 Batch   91/153 - Train Accuracy:  0.991, Validation Accuracy:  0.984, Loss:  0.864
Epoch  20 Batch   92/153 - Train Accuracy:  0.992, Validation Accuracy:  0.982, Loss:  0.861
Epoch  20 Batch   93/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.869
Epoch  20 Batch   94/153 - Train Accuracy:  0.992, Validation Accuracy:  0.979, Loss:  0.848
Epoch  20 Batch   95/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.855
Epoch  20 Batch   96/153 - Train Accuracy:  0.993, Validation Accuracy:  0.976, Loss:  0.865
Epoch  20 Batch   97/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.856
Epoch  20 Batch   98/153 - Train Accuracy:  0.990, Validation Accuracy:  0.975, Loss:  0.845
Epoch  20 Batch   99/153 - Train Accuracy:  0.990, Validation Accuracy:  0.974, Loss:  0.854
Epoch  20 Batch  100/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.865
Epoch  20 Batch  101/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.857
Epoch  20 Batch  102/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.852
Epoch  20 Batch  103/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.871
Epoch  20 Batch  104/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.880
Epoch  20 Batch  105/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.867
Epoch  20 Batch  106/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.866
Epoch  20 Batch  107/153 - Train Accuracy:  0.993, Validation Accuracy:  0.976, Loss:  0.852
Epoch  20 Batch  108/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.873
Epoch  20 Batch  109/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.867
Epoch  20 Batch  110/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.847
Epoch  20 Batch  111/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.854
Epoch  20 Batch  112/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.882
Epoch  20 Batch  113/153 - Train Accuracy:  0.992, Validation Accuracy:  0.981, Loss:  0.853
Epoch  20 Batch  114/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.847
Epoch  20 Batch  115/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.854
Epoch  20 Batch  116/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.888
Epoch  20 Batch  117/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.858
Epoch  20 Batch  118/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.874
Epoch  20 Batch  119/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.877
Epoch  20 Batch  120/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.845
Epoch  20 Batch  121/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.848
Epoch  20 Batch  122/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.874
Epoch  20 Batch  123/153 - Train Accuracy:  0.989, Validation Accuracy:  0.976, Loss:  0.876
Epoch  20 Batch  124/153 - Train Accuracy:  0.990, Validation Accuracy:  0.975, Loss:  0.861
Epoch  20 Batch  125/153 - Train Accuracy:  0.987, Validation Accuracy:  0.973, Loss:  0.853
Epoch  20 Batch  126/153 - Train Accuracy:  0.989, Validation Accuracy:  0.972, Loss:  0.853
Epoch  20 Batch  127/153 - Train Accuracy:  0.988, Validation Accuracy:  0.973, Loss:  0.860
Epoch  20 Batch  128/153 - Train Accuracy:  0.988, Validation Accuracy:  0.971, Loss:  0.860
Epoch  20 Batch  129/153 - Train Accuracy:  0.989, Validation Accuracy:  0.969, Loss:  0.861
Epoch  20 Batch  130/153 - Train Accuracy:  0.988, Validation Accuracy:  0.969, Loss:  0.861
Epoch  20 Batch  131/153 - Train Accuracy:  0.987, Validation Accuracy:  0.974, Loss:  0.861
Epoch  20 Batch  132/153 - Train Accuracy:  0.991, Validation Accuracy:  0.977, Loss:  0.849
Epoch  20 Batch  133/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.875
Epoch  20 Batch  134/153 - Train Accuracy:  0.993, Validation Accuracy:  0.977, Loss:  0.864
Epoch  20 Batch  135/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.844
Epoch  20 Batch  136/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.884
Epoch  20 Batch  137/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.853
Epoch  20 Batch  138/153 - Train Accuracy:  0.991, Validation Accuracy:  0.976, Loss:  0.853
Epoch  20 Batch  139/153 - Train Accuracy:  0.987, Validation Accuracy:  0.975, Loss:  0.873
Epoch  20 Batch  140/153 - Train Accuracy:  0.988, Validation Accuracy:  0.975, Loss:  0.867
Epoch  20 Batch  141/153 - Train Accuracy:  0.993, Validation Accuracy:  0.976, Loss:  0.835
Epoch  20 Batch  142/153 - Train Accuracy:  0.991, Validation Accuracy:  0.977, Loss:  0.843
Epoch  20 Batch  143/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.843
Epoch  20 Batch  144/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.856
Epoch  20 Batch  145/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.844
Epoch  20 Batch  146/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.862
Epoch  20 Batch  147/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.844
Epoch  20 Batch  148/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.849
Epoch  20 Batch  149/153 - Train Accuracy:  0.984, Validation Accuracy:  0.979, Loss:  0.845
Epoch  20 Batch  150/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.837
Epoch  20 Batch  151/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.857
Epoch  21 Batch    0/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.868
Epoch  21 Batch    1/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.876
Epoch  21 Batch    2/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.871
Epoch  21 Batch    3/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.851
Epoch  21 Batch    4/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.857
Epoch  21 Batch    5/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.856
Epoch  21 Batch    6/153 - Train Accuracy:  0.987, Validation Accuracy:  0.974, Loss:  0.863
Epoch  21 Batch    7/153 - Train Accuracy:  0.989, Validation Accuracy:  0.971, Loss:  0.852
Epoch  21 Batch    8/153 - Train Accuracy:  0.990, Validation Accuracy:  0.976, Loss:  0.858
Epoch  21 Batch    9/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.872
Epoch  21 Batch   10/153 - Train Accuracy:  0.992, Validation Accuracy:  0.979, Loss:  0.861
Epoch  21 Batch   11/153 - Train Accuracy:  0.991, Validation Accuracy:  0.976, Loss:  0.857
Epoch  21 Batch   12/153 - Train Accuracy:  0.988, Validation Accuracy:  0.972, Loss:  0.851
Epoch  21 Batch   13/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.871
Epoch  21 Batch   14/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.872
Epoch  21 Batch   15/153 - Train Accuracy:  0.989, Validation Accuracy:  0.975, Loss:  0.872
Epoch  21 Batch   16/153 - Train Accuracy:  0.981, Validation Accuracy:  0.972, Loss:  0.851
Epoch  21 Batch   17/153 - Train Accuracy:  0.984, Validation Accuracy:  0.974, Loss:  0.854
Epoch  21 Batch   18/153 - Train Accuracy:  0.989, Validation Accuracy:  0.974, Loss:  0.870
Epoch  21 Batch   19/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.853
Epoch  21 Batch   20/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.857
Epoch  21 Batch   21/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.839
Epoch  21 Batch   22/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.849
Epoch  21 Batch   23/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.868
Epoch  21 Batch   24/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.863
Epoch  21 Batch   25/153 - Train Accuracy:  0.986, Validation Accuracy:  0.972, Loss:  0.866
Epoch  21 Batch   26/153 - Train Accuracy:  0.985, Validation Accuracy:  0.973, Loss:  0.874
Epoch  21 Batch   27/153 - Train Accuracy:  0.988, Validation Accuracy:  0.976, Loss:  0.843
Epoch  21 Batch   28/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.846
Epoch  21 Batch   29/153 - Train Accuracy:  0.989, Validation Accuracy:  0.983, Loss:  0.851
Epoch  21 Batch   30/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.900
Epoch  21 Batch   31/153 - Train Accuracy:  0.985, Validation Accuracy:  0.980, Loss:  0.851
Epoch  21 Batch   32/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.852
Epoch  21 Batch   33/153 - Train Accuracy:  0.990, Validation Accuracy:  0.984, Loss:  0.860
Epoch  21 Batch   34/153 - Train Accuracy:  0.985, Validation Accuracy:  0.982, Loss:  0.862
Epoch  21 Batch   35/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.864
Epoch  21 Batch   36/153 - Train Accuracy:  0.989, Validation Accuracy:  0.976, Loss:  0.862
Epoch  21 Batch   37/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.868
Epoch  21 Batch   38/153 - Train Accuracy:  0.988, Validation Accuracy:  0.977, Loss:  0.860
Epoch  21 Batch   39/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.837
Epoch  21 Batch   40/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.845
Epoch  21 Batch   41/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.879
Epoch  21 Batch   42/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.866
Epoch  21 Batch   43/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.861
Epoch  21 Batch   44/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.883
Epoch  21 Batch   45/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.880
Epoch  21 Batch   46/153 - Train Accuracy:  0.992, Validation Accuracy:  0.977, Loss:  0.847
Epoch  21 Batch   47/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.848
Epoch  21 Batch   48/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.878
Epoch  21 Batch   49/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.870
Epoch  21 Batch   50/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.840
Epoch  21 Batch   51/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.854
Epoch  21 Batch   52/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.859
Epoch  21 Batch   53/153 - Train Accuracy:  0.986, Validation Accuracy:  0.979, Loss:  0.876
Epoch  21 Batch   54/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.853
Epoch  21 Batch   55/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.862
Epoch  21 Batch   56/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.854
Epoch  21 Batch   57/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.862
Epoch  21 Batch   58/153 - Train Accuracy:  0.988, Validation Accuracy:  0.976, Loss:  0.839
Epoch  21 Batch   59/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.863
Epoch  21 Batch   60/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.834
Epoch  21 Batch   61/153 - Train Accuracy:  0.985, Validation Accuracy:  0.979, Loss:  0.873
Epoch  21 Batch   62/153 - Train Accuracy:  0.991, Validation Accuracy:  0.977, Loss:  0.876
Epoch  21 Batch   63/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.847
Epoch  21 Batch   64/153 - Train Accuracy:  0.989, Validation Accuracy:  0.976, Loss:  0.876
Epoch  21 Batch   65/153 - Train Accuracy:  0.987, Validation Accuracy:  0.977, Loss:  0.853
Epoch  21 Batch   66/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.870
Epoch  21 Batch   67/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.864
Epoch  21 Batch   68/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.841
Epoch  21 Batch   69/153 - Train Accuracy:  0.985, Validation Accuracy:  0.978, Loss:  0.868
Epoch  21 Batch   70/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.858
Epoch  21 Batch   71/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.859
Epoch  21 Batch   72/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.875
Epoch  21 Batch   73/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.853
Epoch  21 Batch   74/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.865
Epoch  21 Batch   75/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.892
Epoch  21 Batch   76/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.858
Epoch  21 Batch   77/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.882
Epoch  21 Batch   78/153 - Train Accuracy:  0.988, Validation Accuracy:  0.977, Loss:  0.859
Epoch  21 Batch   79/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.853
Epoch  21 Batch   80/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.860
Epoch  21 Batch   81/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.868
Epoch  21 Batch   82/153 - Train Accuracy:  0.994, Validation Accuracy:  0.980, Loss:  0.873
Epoch  21 Batch   83/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.884
Epoch  21 Batch   84/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.873
Epoch  21 Batch   85/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.871
Epoch  21 Batch   86/153 - Train Accuracy:  0.992, Validation Accuracy:  0.984, Loss:  0.855
Epoch  21 Batch   87/153 - Train Accuracy:  0.992, Validation Accuracy:  0.984, Loss:  0.868
Epoch  21 Batch   88/153 - Train Accuracy:  0.985, Validation Accuracy:  0.984, Loss:  0.873
Epoch  21 Batch   89/153 - Train Accuracy:  0.989, Validation Accuracy:  0.984, Loss:  0.863
Epoch  21 Batch   90/153 - Train Accuracy:  0.989, Validation Accuracy:  0.984, Loss:  0.852
Epoch  21 Batch   91/153 - Train Accuracy:  0.991, Validation Accuracy:  0.984, Loss:  0.878
Epoch  21 Batch   92/153 - Train Accuracy:  0.994, Validation Accuracy:  0.984, Loss:  0.858
Epoch  21 Batch   93/153 - Train Accuracy:  0.993, Validation Accuracy:  0.983, Loss:  0.863
Epoch  21 Batch   94/153 - Train Accuracy:  0.990, Validation Accuracy:  0.984, Loss:  0.844
Epoch  21 Batch   95/153 - Train Accuracy:  0.990, Validation Accuracy:  0.984, Loss:  0.881
Epoch  21 Batch   96/153 - Train Accuracy:  0.991, Validation Accuracy:  0.984, Loss:  0.876
Epoch  21 Batch   97/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.870
Epoch  21 Batch   98/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.871
Epoch  21 Batch   99/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.863
Epoch  21 Batch  100/153 - Train Accuracy:  0.992, Validation Accuracy:  0.981, Loss:  0.868
Epoch  21 Batch  101/153 - Train Accuracy:  0.992, Validation Accuracy:  0.981, Loss:  0.879
Epoch  21 Batch  102/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.870
Epoch  21 Batch  103/153 - Train Accuracy:  0.992, Validation Accuracy:  0.981, Loss:  0.857
Epoch  21 Batch  104/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.849
Epoch  21 Batch  105/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.869
Epoch  21 Batch  106/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.852
Epoch  21 Batch  107/153 - Train Accuracy:  0.994, Validation Accuracy:  0.976, Loss:  0.864
Epoch  21 Batch  108/153 - Train Accuracy:  0.993, Validation Accuracy:  0.977, Loss:  0.873
Epoch  21 Batch  109/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.858
Epoch  21 Batch  110/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.870
Epoch  21 Batch  111/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.852
Epoch  21 Batch  112/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.861
Epoch  21 Batch  113/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.869
Epoch  21 Batch  114/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.855
Epoch  21 Batch  115/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.882
Epoch  21 Batch  116/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.858
Epoch  21 Batch  117/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.862
Epoch  21 Batch  118/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.868
Epoch  21 Batch  119/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.864
Epoch  21 Batch  120/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.876
Epoch  21 Batch  121/153 - Train Accuracy:  0.992, Validation Accuracy:  0.979, Loss:  0.880
Epoch  21 Batch  122/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.865
Epoch  21 Batch  123/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.869
Epoch  21 Batch  124/153 - Train Accuracy:  0.991, Validation Accuracy:  0.977, Loss:  0.866
Epoch  21 Batch  125/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.869
Epoch  21 Batch  126/153 - Train Accuracy:  0.988, Validation Accuracy:  0.976, Loss:  0.828
Epoch  21 Batch  127/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.860
Epoch  21 Batch  128/153 - Train Accuracy:  0.995, Validation Accuracy:  0.979, Loss:  0.855
Epoch  21 Batch  129/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.868
Epoch  21 Batch  130/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.872
Epoch  21 Batch  131/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.859
Epoch  21 Batch  132/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.852
Epoch  21 Batch  133/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.851
Epoch  21 Batch  134/153 - Train Accuracy:  0.992, Validation Accuracy:  0.982, Loss:  0.857
Epoch  21 Batch  135/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.866
Epoch  21 Batch  136/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.861
Epoch  21 Batch  137/153 - Train Accuracy:  0.988, Validation Accuracy:  0.983, Loss:  0.858
Epoch  21 Batch  138/153 - Train Accuracy:  0.992, Validation Accuracy:  0.982, Loss:  0.880
Epoch  21 Batch  139/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.875
Epoch  21 Batch  140/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.869
Epoch  21 Batch  141/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.860
Epoch  21 Batch  142/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.862
Epoch  21 Batch  143/153 - Train Accuracy:  0.992, Validation Accuracy:  0.979, Loss:  0.827
Epoch  21 Batch  144/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.847
Epoch  21 Batch  145/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.872
Epoch  21 Batch  146/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.875
Epoch  21 Batch  147/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.849
Epoch  21 Batch  148/153 - Train Accuracy:  0.991, Validation Accuracy:  0.983, Loss:  0.851
Epoch  21 Batch  149/153 - Train Accuracy:  0.986, Validation Accuracy:  0.978, Loss:  0.873
Epoch  21 Batch  150/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.852
Epoch  21 Batch  151/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.878
Epoch  22 Batch    0/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.849
Epoch  22 Batch    1/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.871
Epoch  22 Batch    2/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.867
Epoch  22 Batch    3/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.883
Epoch  22 Batch    4/153 - Train Accuracy:  0.992, Validation Accuracy:  0.981, Loss:  0.867
Epoch  22 Batch    5/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.865
Epoch  22 Batch    6/153 - Train Accuracy:  0.986, Validation Accuracy:  0.983, Loss:  0.876
Epoch  22 Batch    7/153 - Train Accuracy:  0.993, Validation Accuracy:  0.979, Loss:  0.871
Epoch  22 Batch    8/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.845
Epoch  22 Batch    9/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.857
Epoch  22 Batch   10/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.851
Epoch  22 Batch   11/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.869
Epoch  22 Batch   12/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.887
Epoch  22 Batch   13/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.850
Epoch  22 Batch   14/153 - Train Accuracy:  0.986, Validation Accuracy:  0.981, Loss:  0.874
Epoch  22 Batch   15/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.864
Epoch  22 Batch   16/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.859
Epoch  22 Batch   17/153 - Train Accuracy:  0.988, Validation Accuracy:  0.976, Loss:  0.857
Epoch  22 Batch   18/153 - Train Accuracy:  0.989, Validation Accuracy:  0.976, Loss:  0.843
Epoch  22 Batch   19/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.855
Epoch  22 Batch   20/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.862
Epoch  22 Batch   21/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.851
Epoch  22 Batch   22/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.879
Epoch  22 Batch   23/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.845
Epoch  22 Batch   24/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.864
Epoch  22 Batch   25/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.861
Epoch  22 Batch   26/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.850
Epoch  22 Batch   27/153 - Train Accuracy:  0.992, Validation Accuracy:  0.976, Loss:  0.881
Epoch  22 Batch   28/153 - Train Accuracy:  0.988, Validation Accuracy:  0.974, Loss:  0.837
Epoch  22 Batch   29/153 - Train Accuracy:  0.990, Validation Accuracy:  0.976, Loss:  0.853
Epoch  22 Batch   30/153 - Train Accuracy:  0.992, Validation Accuracy:  0.978, Loss:  0.855
Epoch  22 Batch   31/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.885
Epoch  22 Batch   32/153 - Train Accuracy:  0.985, Validation Accuracy:  0.980, Loss:  0.854
Epoch  22 Batch   33/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.890
Epoch  22 Batch   34/153 - Train Accuracy:  0.985, Validation Accuracy:  0.982, Loss:  0.849
Epoch  22 Batch   35/153 - Train Accuracy:  0.986, Validation Accuracy:  0.980, Loss:  0.872
Epoch  22 Batch   36/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.890
Epoch  22 Batch   37/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.875
Epoch  22 Batch   38/153 - Train Accuracy:  0.988, Validation Accuracy:  0.973, Loss:  0.842
Epoch  22 Batch   39/153 - Train Accuracy:  0.990, Validation Accuracy:  0.974, Loss:  0.864
Epoch  22 Batch   40/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.868
Epoch  22 Batch   41/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.883
Epoch  22 Batch   42/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.888
Epoch  22 Batch   43/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.866
Epoch  22 Batch   44/153 - Train Accuracy:  0.988, Validation Accuracy:  0.982, Loss:  0.861
Epoch  22 Batch   45/153 - Train Accuracy:  0.985, Validation Accuracy:  0.982, Loss:  0.862
Epoch  22 Batch   46/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.884
Epoch  22 Batch   47/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.877
Epoch  22 Batch   48/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.852
Epoch  22 Batch   49/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.868
Epoch  22 Batch   50/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.871
Epoch  22 Batch   51/153 - Train Accuracy:  0.983, Validation Accuracy:  0.983, Loss:  0.878
Epoch  22 Batch   52/153 - Train Accuracy:  0.992, Validation Accuracy:  0.984, Loss:  0.859
Epoch  22 Batch   53/153 - Train Accuracy:  0.984, Validation Accuracy:  0.985, Loss:  0.867
Epoch  22 Batch   54/153 - Train Accuracy:  0.992, Validation Accuracy:  0.985, Loss:  0.864
Epoch  22 Batch   55/153 - Train Accuracy:  0.992, Validation Accuracy:  0.983, Loss:  0.883
Epoch  22 Batch   56/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.854
Epoch  22 Batch   57/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.863
Epoch  22 Batch   58/153 - Train Accuracy:  0.989, Validation Accuracy:  0.975, Loss:  0.853
Epoch  22 Batch   59/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.845
Epoch  22 Batch   60/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.853
Epoch  22 Batch   61/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.845
Epoch  22 Batch   62/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.877
Epoch  22 Batch   63/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.867
Epoch  22 Batch   64/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.881
Epoch  22 Batch   65/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.844
Epoch  22 Batch   66/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.867
Epoch  22 Batch   67/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.843
Epoch  22 Batch   68/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.870
Epoch  22 Batch   69/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.858
Epoch  22 Batch   70/153 - Train Accuracy:  0.991, Validation Accuracy:  0.983, Loss:  0.843
Epoch  22 Batch   71/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.834
Epoch  22 Batch   72/153 - Train Accuracy:  0.992, Validation Accuracy:  0.982, Loss:  0.826
Epoch  22 Batch   73/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.870
Epoch  22 Batch   74/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.862
Epoch  22 Batch   75/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.870
Epoch  22 Batch   76/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.849
Epoch  22 Batch   77/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.891
Epoch  22 Batch   78/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.864
Epoch  22 Batch   79/153 - Train Accuracy:  0.991, Validation Accuracy:  0.983, Loss:  0.857
Epoch  22 Batch   80/153 - Train Accuracy:  0.988, Validation Accuracy:  0.984, Loss:  0.846
Epoch  22 Batch   81/153 - Train Accuracy:  0.990, Validation Accuracy:  0.983, Loss:  0.873
Epoch  22 Batch   82/153 - Train Accuracy:  0.992, Validation Accuracy:  0.983, Loss:  0.871
Epoch  22 Batch   83/153 - Train Accuracy:  0.990, Validation Accuracy:  0.983, Loss:  0.873
Epoch  22 Batch   84/153 - Train Accuracy:  0.994, Validation Accuracy:  0.984, Loss:  0.862
Epoch  22 Batch   85/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.862
Epoch  22 Batch   86/153 - Train Accuracy:  0.987, Validation Accuracy:  0.980, Loss:  0.861
Epoch  22 Batch   87/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.860
Epoch  22 Batch   88/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.865
Epoch  22 Batch   89/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.855
Epoch  22 Batch   90/153 - Train Accuracy:  0.991, Validation Accuracy:  0.983, Loss:  0.858
Epoch  22 Batch   91/153 - Train Accuracy:  0.990, Validation Accuracy:  0.983, Loss:  0.849
Epoch  22 Batch   92/153 - Train Accuracy:  0.991, Validation Accuracy:  0.984, Loss:  0.862
Epoch  22 Batch   93/153 - Train Accuracy:  0.992, Validation Accuracy:  0.982, Loss:  0.861
Epoch  22 Batch   94/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.873
Epoch  22 Batch   95/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.870
Epoch  22 Batch   96/153 - Train Accuracy:  0.992, Validation Accuracy:  0.981, Loss:  0.870
Epoch  22 Batch   97/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.864
Epoch  22 Batch   98/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.853
Epoch  22 Batch   99/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.820
Epoch  22 Batch  100/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.859
Epoch  22 Batch  101/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.852
Epoch  22 Batch  102/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.884
Epoch  22 Batch  103/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.858
Epoch  22 Batch  104/153 - Train Accuracy:  0.993, Validation Accuracy:  0.982, Loss:  0.873
Epoch  22 Batch  105/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.869
Epoch  22 Batch  106/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.872
Epoch  22 Batch  107/153 - Train Accuracy:  0.994, Validation Accuracy:  0.980, Loss:  0.838
Epoch  22 Batch  108/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.878
Epoch  22 Batch  109/153 - Train Accuracy:  0.992, Validation Accuracy:  0.979, Loss:  0.848
Epoch  22 Batch  110/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.839
Epoch  22 Batch  111/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.861
Epoch  22 Batch  112/153 - Train Accuracy:  0.991, Validation Accuracy:  0.983, Loss:  0.876
Epoch  22 Batch  113/153 - Train Accuracy:  0.992, Validation Accuracy:  0.984, Loss:  0.879
Epoch  22 Batch  114/153 - Train Accuracy:  0.993, Validation Accuracy:  0.983, Loss:  0.841
Epoch  22 Batch  115/153 - Train Accuracy:  0.990, Validation Accuracy:  0.983, Loss:  0.871
Epoch  22 Batch  116/153 - Train Accuracy:  0.990, Validation Accuracy:  0.983, Loss:  0.862
Epoch  22 Batch  117/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.864
Epoch  22 Batch  118/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.869
Epoch  22 Batch  119/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.858
Epoch  22 Batch  120/153 - Train Accuracy:  0.985, Validation Accuracy:  0.980, Loss:  0.867
Epoch  22 Batch  121/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.868
Epoch  22 Batch  122/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.868
Epoch  22 Batch  123/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.865
Epoch  22 Batch  124/153 - Train Accuracy:  0.993, Validation Accuracy:  0.978, Loss:  0.846
Epoch  22 Batch  125/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.889
Epoch  22 Batch  126/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.864
Epoch  22 Batch  127/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.863
Epoch  22 Batch  128/153 - Train Accuracy:  0.995, Validation Accuracy:  0.979, Loss:  0.871
Epoch  22 Batch  129/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.864
Epoch  22 Batch  130/153 - Train Accuracy:  0.992, Validation Accuracy:  0.976, Loss:  0.830
Epoch  22 Batch  131/153 - Train Accuracy:  0.989, Validation Accuracy:  0.974, Loss:  0.871
Epoch  22 Batch  132/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.853
Epoch  22 Batch  133/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.860
Epoch  22 Batch  134/153 - Train Accuracy:  0.994, Validation Accuracy:  0.982, Loss:  0.870
Epoch  22 Batch  135/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.873
Epoch  22 Batch  136/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.858
Epoch  22 Batch  137/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.884
Epoch  22 Batch  138/153 - Train Accuracy:  0.994, Validation Accuracy:  0.982, Loss:  0.844
Epoch  22 Batch  139/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.860
Epoch  22 Batch  140/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.857
Epoch  22 Batch  141/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.893
Epoch  22 Batch  142/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.851
Epoch  22 Batch  143/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.857
Epoch  22 Batch  144/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.855
Epoch  22 Batch  145/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.847
Epoch  22 Batch  146/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.859
Epoch  22 Batch  147/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.861
Epoch  22 Batch  148/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.871
Epoch  22 Batch  149/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.847
Epoch  22 Batch  150/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.854
Epoch  22 Batch  151/153 - Train Accuracy:  0.989, Validation Accuracy:  0.977, Loss:  0.861
Epoch  23 Batch    0/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.857
Epoch  23 Batch    1/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.863
Epoch  23 Batch    2/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.845
Epoch  23 Batch    3/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.866
Epoch  23 Batch    4/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.842
Epoch  23 Batch    5/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.862
Epoch  23 Batch    6/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.883
Epoch  23 Batch    7/153 - Train Accuracy:  0.995, Validation Accuracy:  0.977, Loss:  0.829
Epoch  23 Batch    8/153 - Train Accuracy:  0.986, Validation Accuracy:  0.975, Loss:  0.864
Epoch  23 Batch    9/153 - Train Accuracy:  0.988, Validation Accuracy:  0.972, Loss:  0.894
Epoch  23 Batch   10/153 - Train Accuracy:  0.991, Validation Accuracy:  0.972, Loss:  0.871
Epoch  23 Batch   11/153 - Train Accuracy:  0.993, Validation Accuracy:  0.977, Loss:  0.860
Epoch  23 Batch   12/153 - Train Accuracy:  0.993, Validation Accuracy:  0.978, Loss:  0.868
Epoch  23 Batch   13/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.881
Epoch  23 Batch   14/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.857
Epoch  23 Batch   15/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.841
Epoch  23 Batch   16/153 - Train Accuracy:  0.990, Validation Accuracy:  0.976, Loss:  0.875
Epoch  23 Batch   17/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.863
Epoch  23 Batch   18/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.871
Epoch  23 Batch   19/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.862
Epoch  23 Batch   20/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.883
Epoch  23 Batch   21/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.864
Epoch  23 Batch   22/153 - Train Accuracy:  0.992, Validation Accuracy:  0.976, Loss:  0.859
Epoch  23 Batch   23/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.862
Epoch  23 Batch   24/153 - Train Accuracy:  0.991, Validation Accuracy:  0.976, Loss:  0.850
Epoch  23 Batch   25/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.861
Epoch  23 Batch   26/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.890
Epoch  23 Batch   27/153 - Train Accuracy:  0.992, Validation Accuracy:  0.979, Loss:  0.844
Epoch  23 Batch   28/153 - Train Accuracy:  0.993, Validation Accuracy:  0.977, Loss:  0.879
Epoch  23 Batch   29/153 - Train Accuracy:  0.991, Validation Accuracy:  0.975, Loss:  0.858
Epoch  23 Batch   30/153 - Train Accuracy:  0.991, Validation Accuracy:  0.975, Loss:  0.861
Epoch  23 Batch   31/153 - Train Accuracy:  0.986, Validation Accuracy:  0.977, Loss:  0.859
Epoch  23 Batch   32/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.874
Epoch  23 Batch   33/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.873
Epoch  23 Batch   34/153 - Train Accuracy:  0.987, Validation Accuracy:  0.979, Loss:  0.855
Epoch  23 Batch   35/153 - Train Accuracy:  0.985, Validation Accuracy:  0.979, Loss:  0.878
Epoch  23 Batch   36/153 - Train Accuracy:  0.992, Validation Accuracy:  0.979, Loss:  0.862
Epoch  23 Batch   37/153 - Train Accuracy:  0.988, Validation Accuracy:  0.983, Loss:  0.853
Epoch  23 Batch   38/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.857
Epoch  23 Batch   39/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.862
Epoch  23 Batch   40/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.851
Epoch  23 Batch   41/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.844
Epoch  23 Batch   42/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.863
Epoch  23 Batch   43/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.874
Epoch  23 Batch   44/153 - Train Accuracy:  0.993, Validation Accuracy:  0.977, Loss:  0.836
Epoch  23 Batch   45/153 - Train Accuracy:  0.991, Validation Accuracy:  0.975, Loss:  0.879
Epoch  23 Batch   46/153 - Train Accuracy:  0.990, Validation Accuracy:  0.976, Loss:  0.861
Epoch  23 Batch   47/153 - Train Accuracy:  0.991, Validation Accuracy:  0.976, Loss:  0.853
Epoch  23 Batch   48/153 - Train Accuracy:  0.989, Validation Accuracy:  0.976, Loss:  0.872
Epoch  23 Batch   49/153 - Train Accuracy:  0.994, Validation Accuracy:  0.975, Loss:  0.833
Epoch  23 Batch   50/153 - Train Accuracy:  0.993, Validation Accuracy:  0.975, Loss:  0.877
Epoch  23 Batch   51/153 - Train Accuracy:  0.989, Validation Accuracy:  0.974, Loss:  0.874
Epoch  23 Batch   52/153 - Train Accuracy:  0.992, Validation Accuracy:  0.974, Loss:  0.860
Epoch  23 Batch   53/153 - Train Accuracy:  0.991, Validation Accuracy:  0.975, Loss:  0.870
Epoch  23 Batch   54/153 - Train Accuracy:  0.992, Validation Accuracy:  0.976, Loss:  0.873
Epoch  23 Batch   55/153 - Train Accuracy:  0.988, Validation Accuracy:  0.975, Loss:  0.867
Epoch  23 Batch   56/153 - Train Accuracy:  0.987, Validation Accuracy:  0.978, Loss:  0.860
Epoch  23 Batch   57/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.884
Epoch  23 Batch   58/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.876
Epoch  23 Batch   59/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.856
Epoch  23 Batch   60/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.893
Epoch  23 Batch   61/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.847
Epoch  23 Batch   62/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.862
Epoch  23 Batch   63/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.838
Epoch  23 Batch   64/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.877
Epoch  23 Batch   65/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.849
Epoch  23 Batch   66/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.885
Epoch  23 Batch   67/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.851
Epoch  23 Batch   68/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.876
Epoch  23 Batch   69/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.844
Epoch  23 Batch   70/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.848
Epoch  23 Batch   71/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.857
Epoch  23 Batch   72/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.854
Epoch  23 Batch   73/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.871
Epoch  23 Batch   74/153 - Train Accuracy:  0.992, Validation Accuracy:  0.982, Loss:  0.847
Epoch  23 Batch   75/153 - Train Accuracy:  0.987, Validation Accuracy:  0.984, Loss:  0.865
Epoch  23 Batch   76/153 - Train Accuracy:  0.990, Validation Accuracy:  0.984, Loss:  0.870
Epoch  23 Batch   77/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.877
Epoch  23 Batch   78/153 - Train Accuracy:  0.992, Validation Accuracy:  0.984, Loss:  0.860
Epoch  23 Batch   79/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.861
Epoch  23 Batch   80/153 - Train Accuracy:  0.991, Validation Accuracy:  0.983, Loss:  0.863
Epoch  23 Batch   81/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.881
Epoch  23 Batch   82/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.889
Epoch  23 Batch   83/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.852
Epoch  23 Batch   84/153 - Train Accuracy:  0.992, Validation Accuracy:  0.981, Loss:  0.866
Epoch  23 Batch   85/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.858
Epoch  23 Batch   86/153 - Train Accuracy:  0.994, Validation Accuracy:  0.980, Loss:  0.866
Epoch  23 Batch   87/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.867
Epoch  23 Batch   88/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.890
Epoch  23 Batch   89/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.843
Epoch  23 Batch   90/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.857
Epoch  23 Batch   91/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.869
Epoch  23 Batch   92/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.875
Epoch  23 Batch   93/153 - Train Accuracy:  0.991, Validation Accuracy:  0.983, Loss:  0.875
Epoch  23 Batch   94/153 - Train Accuracy:  0.993, Validation Accuracy:  0.982, Loss:  0.853
Epoch  23 Batch   95/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.872
Epoch  23 Batch   96/153 - Train Accuracy:  0.994, Validation Accuracy:  0.982, Loss:  0.854
Epoch  23 Batch   97/153 - Train Accuracy:  0.995, Validation Accuracy:  0.982, Loss:  0.871
Epoch  23 Batch   98/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.857
Epoch  23 Batch   99/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.859
Epoch  23 Batch  100/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.847
Epoch  23 Batch  101/153 - Train Accuracy:  0.992, Validation Accuracy:  0.979, Loss:  0.858
Epoch  23 Batch  102/153 - Train Accuracy:  0.993, Validation Accuracy:  0.977, Loss:  0.843
Epoch  23 Batch  103/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.878
Epoch  23 Batch  104/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.859
Epoch  23 Batch  105/153 - Train Accuracy:  0.992, Validation Accuracy:  0.977, Loss:  0.851
Epoch  23 Batch  106/153 - Train Accuracy:  0.992, Validation Accuracy:  0.977, Loss:  0.854
Epoch  23 Batch  107/153 - Train Accuracy:  0.994, Validation Accuracy:  0.976, Loss:  0.858
Epoch  23 Batch  108/153 - Train Accuracy:  0.993, Validation Accuracy:  0.978, Loss:  0.872
Epoch  23 Batch  109/153 - Train Accuracy:  0.994, Validation Accuracy:  0.979, Loss:  0.847
Epoch  23 Batch  110/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.856
Epoch  23 Batch  111/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.852
Epoch  23 Batch  112/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.845
Epoch  23 Batch  113/153 - Train Accuracy:  0.991, Validation Accuracy:  0.983, Loss:  0.862
Epoch  23 Batch  114/153 - Train Accuracy:  0.993, Validation Accuracy:  0.982, Loss:  0.868
Epoch  23 Batch  115/153 - Train Accuracy:  0.988, Validation Accuracy:  0.982, Loss:  0.834
Epoch  23 Batch  116/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.866
Epoch  23 Batch  117/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.861
Epoch  23 Batch  118/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.858
Epoch  23 Batch  119/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.867
Epoch  23 Batch  120/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.864
Epoch  23 Batch  121/153 - Train Accuracy:  0.992, Validation Accuracy:  0.981, Loss:  0.860
Epoch  23 Batch  122/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.852
Epoch  23 Batch  123/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.837
Epoch  23 Batch  124/153 - Train Accuracy:  0.994, Validation Accuracy:  0.978, Loss:  0.852
Epoch  23 Batch  125/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.875
Epoch  23 Batch  126/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.865
Epoch  23 Batch  127/153 - Train Accuracy:  0.992, Validation Accuracy:  0.975, Loss:  0.873
Epoch  23 Batch  128/153 - Train Accuracy:  0.994, Validation Accuracy:  0.974, Loss:  0.871
Epoch  23 Batch  129/153 - Train Accuracy:  0.992, Validation Accuracy:  0.975, Loss:  0.842
Epoch  23 Batch  130/153 - Train Accuracy:  0.991, Validation Accuracy:  0.977, Loss:  0.873
Epoch  23 Batch  131/153 - Train Accuracy:  0.992, Validation Accuracy:  0.976, Loss:  0.844
Epoch  23 Batch  132/153 - Train Accuracy:  0.994, Validation Accuracy:  0.979, Loss:  0.866
Epoch  23 Batch  133/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.857
Epoch  23 Batch  134/153 - Train Accuracy:  0.992, Validation Accuracy:  0.981, Loss:  0.860
Epoch  23 Batch  135/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.856
Epoch  23 Batch  136/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.847
Epoch  23 Batch  137/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.891
Epoch  23 Batch  138/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.865
Epoch  23 Batch  139/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.856
Epoch  23 Batch  140/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.859
Epoch  23 Batch  141/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.886
Epoch  23 Batch  142/153 - Train Accuracy:  0.993, Validation Accuracy:  0.978, Loss:  0.868
Epoch  23 Batch  143/153 - Train Accuracy:  0.992, Validation Accuracy:  0.979, Loss:  0.835
Epoch  23 Batch  144/153 - Train Accuracy:  0.987, Validation Accuracy:  0.981, Loss:  0.870
Epoch  23 Batch  145/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.857
Epoch  23 Batch  146/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.851
Epoch  23 Batch  147/153 - Train Accuracy:  0.988, Validation Accuracy:  0.983, Loss:  0.863
Epoch  23 Batch  148/153 - Train Accuracy:  0.991, Validation Accuracy:  0.983, Loss:  0.873
Epoch  23 Batch  149/153 - Train Accuracy:  0.988, Validation Accuracy:  0.982, Loss:  0.846
Epoch  23 Batch  150/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.856
Epoch  23 Batch  151/153 - Train Accuracy:  0.992, Validation Accuracy:  0.982, Loss:  0.855
Epoch  24 Batch    0/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.848
Epoch  24 Batch    1/153 - Train Accuracy:  0.994, Validation Accuracy:  0.980, Loss:  0.866
Epoch  24 Batch    2/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.846
Epoch  24 Batch    3/153 - Train Accuracy:  0.992, Validation Accuracy:  0.982, Loss:  0.870
Epoch  24 Batch    4/153 - Train Accuracy:  0.992, Validation Accuracy:  0.985, Loss:  0.859
Epoch  24 Batch    5/153 - Train Accuracy:  0.993, Validation Accuracy:  0.985, Loss:  0.860
Epoch  24 Batch    6/153 - Train Accuracy:  0.990, Validation Accuracy:  0.985, Loss:  0.873
Epoch  24 Batch    7/153 - Train Accuracy:  0.992, Validation Accuracy:  0.983, Loss:  0.856
Epoch  24 Batch    8/153 - Train Accuracy:  0.991, Validation Accuracy:  0.984, Loss:  0.882
Epoch  24 Batch    9/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.873
Epoch  24 Batch   10/153 - Train Accuracy:  0.994, Validation Accuracy:  0.979, Loss:  0.874
Epoch  24 Batch   11/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.860
Epoch  24 Batch   12/153 - Train Accuracy:  0.993, Validation Accuracy:  0.982, Loss:  0.867
Epoch  24 Batch   13/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.849
Epoch  24 Batch   14/153 - Train Accuracy:  0.990, Validation Accuracy:  0.981, Loss:  0.871
Epoch  24 Batch   15/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.862
Epoch  24 Batch   16/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.874
Epoch  24 Batch   17/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.872
Epoch  24 Batch   18/153 - Train Accuracy:  0.993, Validation Accuracy:  0.983, Loss:  0.864
Epoch  24 Batch   19/153 - Train Accuracy:  0.994, Validation Accuracy:  0.982, Loss:  0.868
Epoch  24 Batch   20/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.872
Epoch  24 Batch   21/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.873
Epoch  24 Batch   22/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.869
Epoch  24 Batch   23/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.888
Epoch  24 Batch   24/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.869
Epoch  24 Batch   25/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.854
Epoch  24 Batch   26/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.879
Epoch  24 Batch   27/153 - Train Accuracy:  0.992, Validation Accuracy:  0.981, Loss:  0.870
Epoch  24 Batch   28/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.873
Epoch  24 Batch   29/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.851
Epoch  24 Batch   30/153 - Train Accuracy:  0.993, Validation Accuracy:  0.979, Loss:  0.849
Epoch  24 Batch   31/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.872
Epoch  24 Batch   32/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.845
Epoch  24 Batch   33/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.884
Epoch  24 Batch   34/153 - Train Accuracy:  0.987, Validation Accuracy:  0.982, Loss:  0.845
Epoch  24 Batch   35/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.859
Epoch  24 Batch   36/153 - Train Accuracy:  0.992, Validation Accuracy:  0.982, Loss:  0.861
Epoch  24 Batch   37/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.858
Epoch  24 Batch   38/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.842
Epoch  24 Batch   39/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.855
Epoch  24 Batch   40/153 - Train Accuracy:  0.988, Validation Accuracy:  0.981, Loss:  0.877
Epoch  24 Batch   41/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.877
Epoch  24 Batch   42/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.858
Epoch  24 Batch   43/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.852
Epoch  24 Batch   44/153 - Train Accuracy:  0.993, Validation Accuracy:  0.979, Loss:  0.832
Epoch  24 Batch   45/153 - Train Accuracy:  0.989, Validation Accuracy:  0.978, Loss:  0.863
Epoch  24 Batch   46/153 - Train Accuracy:  0.992, Validation Accuracy:  0.978, Loss:  0.864
Epoch  24 Batch   47/153 - Train Accuracy:  0.988, Validation Accuracy:  0.979, Loss:  0.866
Epoch  24 Batch   48/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.859
Epoch  24 Batch   49/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.888
Epoch  24 Batch   50/153 - Train Accuracy:  0.994, Validation Accuracy:  0.982, Loss:  0.854
Epoch  24 Batch   51/153 - Train Accuracy:  0.989, Validation Accuracy:  0.981, Loss:  0.870
Epoch  24 Batch   52/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.866
Epoch  24 Batch   53/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.862
Epoch  24 Batch   54/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.871
Epoch  24 Batch   55/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.866
Epoch  24 Batch   56/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.870
Epoch  24 Batch   57/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.865
Epoch  24 Batch   58/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.868
Epoch  24 Batch   59/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.858
Epoch  24 Batch   60/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.866
Epoch  24 Batch   61/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.870
Epoch  24 Batch   62/153 - Train Accuracy:  0.992, Validation Accuracy:  0.978, Loss:  0.872
Epoch  24 Batch   63/153 - Train Accuracy:  0.992, Validation Accuracy:  0.977, Loss:  0.869
Epoch  24 Batch   64/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.866
Epoch  24 Batch   65/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.851
Epoch  24 Batch   66/153 - Train Accuracy:  0.990, Validation Accuracy:  0.977, Loss:  0.863
Epoch  24 Batch   67/153 - Train Accuracy:  0.990, Validation Accuracy:  0.976, Loss:  0.868
Epoch  24 Batch   68/153 - Train Accuracy:  0.994, Validation Accuracy:  0.976, Loss:  0.855
Epoch  24 Batch   69/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.866
Epoch  24 Batch   70/153 - Train Accuracy:  0.991, Validation Accuracy:  0.979, Loss:  0.876
Epoch  24 Batch   71/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.855
Epoch  24 Batch   72/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.877
Epoch  24 Batch   73/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.866
Epoch  24 Batch   74/153 - Train Accuracy:  0.990, Validation Accuracy:  0.983, Loss:  0.867
Epoch  24 Batch   75/153 - Train Accuracy:  0.990, Validation Accuracy:  0.985, Loss:  0.868
Epoch  24 Batch   76/153 - Train Accuracy:  0.990, Validation Accuracy:  0.984, Loss:  0.859
Epoch  24 Batch   77/153 - Train Accuracy:  0.991, Validation Accuracy:  0.984, Loss:  0.845
Epoch  24 Batch   78/153 - Train Accuracy:  0.988, Validation Accuracy:  0.984, Loss:  0.886
Epoch  24 Batch   79/153 - Train Accuracy:  0.991, Validation Accuracy:  0.983, Loss:  0.853
Epoch  24 Batch   80/153 - Train Accuracy:  0.991, Validation Accuracy:  0.982, Loss:  0.834
Epoch  24 Batch   81/153 - Train Accuracy:  0.988, Validation Accuracy:  0.984, Loss:  0.872
Epoch  24 Batch   82/153 - Train Accuracy:  0.996, Validation Accuracy:  0.984, Loss:  0.839
Epoch  24 Batch   83/153 - Train Accuracy:  0.989, Validation Accuracy:  0.986, Loss:  0.853
Epoch  24 Batch   84/153 - Train Accuracy:  0.991, Validation Accuracy:  0.987, Loss:  0.853
Epoch  24 Batch   85/153 - Train Accuracy:  0.989, Validation Accuracy:  0.985, Loss:  0.867
Epoch  24 Batch   86/153 - Train Accuracy:  0.992, Validation Accuracy:  0.986, Loss:  0.856
Epoch  24 Batch   87/153 - Train Accuracy:  0.989, Validation Accuracy:  0.986, Loss:  0.881
Epoch  24 Batch   88/153 - Train Accuracy:  0.992, Validation Accuracy:  0.986, Loss:  0.865
Epoch  24 Batch   89/153 - Train Accuracy:  0.993, Validation Accuracy:  0.985, Loss:  0.881
Epoch  24 Batch   90/153 - Train Accuracy:  0.991, Validation Accuracy:  0.984, Loss:  0.863
Epoch  24 Batch   91/153 - Train Accuracy:  0.991, Validation Accuracy:  0.983, Loss:  0.867
Epoch  24 Batch   92/153 - Train Accuracy:  0.994, Validation Accuracy:  0.982, Loss:  0.869
Epoch  24 Batch   93/153 - Train Accuracy:  0.992, Validation Accuracy:  0.981, Loss:  0.891
Epoch  24 Batch   94/153 - Train Accuracy:  0.992, Validation Accuracy:  0.984, Loss:  0.879
Epoch  24 Batch   95/153 - Train Accuracy:  0.993, Validation Accuracy:  0.982, Loss:  0.860
Epoch  24 Batch   96/153 - Train Accuracy:  0.989, Validation Accuracy:  0.982, Loss:  0.854
Epoch  24 Batch   97/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.864
Epoch  24 Batch   98/153 - Train Accuracy:  0.990, Validation Accuracy:  0.982, Loss:  0.857
Epoch  24 Batch   99/153 - Train Accuracy:  0.990, Validation Accuracy:  0.984, Loss:  0.864
Epoch  24 Batch  100/153 - Train Accuracy:  0.993, Validation Accuracy:  0.982, Loss:  0.871
Epoch  24 Batch  101/153 - Train Accuracy:  0.994, Validation Accuracy:  0.983, Loss:  0.860
Epoch  24 Batch  102/153 - Train Accuracy:  0.993, Validation Accuracy:  0.985, Loss:  0.868
Epoch  24 Batch  103/153 - Train Accuracy:  0.990, Validation Accuracy:  0.984, Loss:  0.868
Epoch  24 Batch  104/153 - Train Accuracy:  0.992, Validation Accuracy:  0.983, Loss:  0.848
Epoch  24 Batch  105/153 - Train Accuracy:  0.990, Validation Accuracy:  0.983, Loss:  0.851
Epoch  24 Batch  106/153 - Train Accuracy:  0.992, Validation Accuracy:  0.982, Loss:  0.875
Epoch  24 Batch  107/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.858
Epoch  24 Batch  108/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.871
Epoch  24 Batch  109/153 - Train Accuracy:  0.993, Validation Accuracy:  0.980, Loss:  0.848
Epoch  24 Batch  110/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.883
Epoch  24 Batch  111/153 - Train Accuracy:  0.989, Validation Accuracy:  0.979, Loss:  0.871
Epoch  24 Batch  112/153 - Train Accuracy:  0.993, Validation Accuracy:  0.979, Loss:  0.873
Epoch  24 Batch  113/153 - Train Accuracy:  0.992, Validation Accuracy:  0.978, Loss:  0.871
Epoch  24 Batch  114/153 - Train Accuracy:  0.992, Validation Accuracy:  0.978, Loss:  0.860
Epoch  24 Batch  115/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.876
Epoch  24 Batch  116/153 - Train Accuracy:  0.993, Validation Accuracy:  0.978, Loss:  0.860
Epoch  24 Batch  117/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.859
Epoch  24 Batch  118/153 - Train Accuracy:  0.993, Validation Accuracy:  0.981, Loss:  0.846
Epoch  24 Batch  119/153 - Train Accuracy:  0.988, Validation Accuracy:  0.980, Loss:  0.882
Epoch  24 Batch  120/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.853
Epoch  24 Batch  121/153 - Train Accuracy:  0.992, Validation Accuracy:  0.982, Loss:  0.857
Epoch  24 Batch  122/153 - Train Accuracy:  0.989, Validation Accuracy:  0.980, Loss:  0.874
Epoch  24 Batch  123/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.861
Epoch  24 Batch  124/153 - Train Accuracy:  0.992, Validation Accuracy:  0.978, Loss:  0.859
Epoch  24 Batch  125/153 - Train Accuracy:  0.989, Validation Accuracy:  0.976, Loss:  0.853
Epoch  24 Batch  126/153 - Train Accuracy:  0.988, Validation Accuracy:  0.975, Loss:  0.854
Epoch  24 Batch  127/153 - Train Accuracy:  0.992, Validation Accuracy:  0.975, Loss:  0.862
Epoch  24 Batch  128/153 - Train Accuracy:  0.991, Validation Accuracy:  0.976, Loss:  0.852
Epoch  24 Batch  129/153 - Train Accuracy:  0.991, Validation Accuracy:  0.977, Loss:  0.855
Epoch  24 Batch  130/153 - Train Accuracy:  0.996, Validation Accuracy:  0.976, Loss:  0.846
Epoch  24 Batch  131/153 - Train Accuracy:  0.992, Validation Accuracy:  0.978, Loss:  0.854
Epoch  24 Batch  132/153 - Train Accuracy:  0.994, Validation Accuracy:  0.978, Loss:  0.859
Epoch  24 Batch  133/153 - Train Accuracy:  0.992, Validation Accuracy:  0.977, Loss:  0.885
Epoch  24 Batch  134/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.881
Epoch  24 Batch  135/153 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.887
Epoch  24 Batch  136/153 - Train Accuracy:  0.995, Validation Accuracy:  0.981, Loss:  0.837
Epoch  24 Batch  137/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.893
Epoch  24 Batch  138/153 - Train Accuracy:  0.994, Validation Accuracy:  0.980, Loss:  0.890
Epoch  24 Batch  139/153 - Train Accuracy:  0.992, Validation Accuracy:  0.980, Loss:  0.841
Epoch  24 Batch  140/153 - Train Accuracy:  0.990, Validation Accuracy:  0.979, Loss:  0.866
Epoch  24 Batch  141/153 - Train Accuracy:  0.994, Validation Accuracy:  0.978, Loss:  0.860
Epoch  24 Batch  142/153 - Train Accuracy:  0.993, Validation Accuracy:  0.976, Loss:  0.871
Epoch  24 Batch  143/153 - Train Accuracy:  0.991, Validation Accuracy:  0.974, Loss:  0.877
Epoch  24 Batch  144/153 - Train Accuracy:  0.990, Validation Accuracy:  0.974, Loss:  0.842
Epoch  24 Batch  145/153 - Train Accuracy:  0.991, Validation Accuracy:  0.976, Loss:  0.868
Epoch  24 Batch  146/153 - Train Accuracy:  0.990, Validation Accuracy:  0.978, Loss:  0.852
Epoch  24 Batch  147/153 - Train Accuracy:  0.991, Validation Accuracy:  0.978, Loss:  0.885
Epoch  24 Batch  148/153 - Train Accuracy:  0.994, Validation Accuracy:  0.978, Loss:  0.854
Epoch  24 Batch  149/153 - Train Accuracy:  0.988, Validation Accuracy:  0.978, Loss:  0.868
Epoch  24 Batch  150/153 - Train Accuracy:  0.991, Validation Accuracy:  0.981, Loss:  0.866
Epoch  24 Batch  151/153 - Train Accuracy:  0.991, Validation Accuracy:  0.980, Loss:  0.849
Model Trained and Saved
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 46px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 18px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Save Parameters</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">Save the <span class="cm-comment">`batch_size`</span> and <span class="cm-comment">`save_path`</span> parameters for inference.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 46px;"></div><div class="CodeMirror-gutters" style="display: none; height: 61px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Save-Parameters">Save Parameters<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Save-Parameters"></a></h3>
<p>Save the <code>batch_size</code> and <code>save_path</code> parameters for inference.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[20]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 275px; margin-bottom: -15px; border-right-width: 15px; min-height: 96px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-comment"># Save parameters for checkpoint</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">helper</span>.<span class="cm-property">save_params</span>(<span class="cm-variable">save_path</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 96px;"></div><div class="CodeMirror-gutters" style="display: none; height: 111px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 32px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 21px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-1"># Checkpoint</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 32px;"></div><div class="CodeMirror-gutters" style="display: none; height: 47px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Checkpoint"></a></h1>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[2]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 931px; margin-bottom: -15px; border-right-width: 15px; min-height: 181px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">tensorflow</span> <span class="cm-keyword">as</span> <span class="cm-variable">tf</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">numpy</span> <span class="cm-keyword">as</span> <span class="cm-variable">np</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">helper</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">problem_unittests</span> <span class="cm-keyword">as</span> <span class="cm-variable">tests</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">_</span>, (<span class="cm-variable">source_vocab_to_int</span>, <span class="cm-variable">target_vocab_to_int</span>), (<span class="cm-variable">source_int_to_vocab</span>, <span class="cm-variable">target_int_to_vocab</span>) = <span class="cm-variable">helper</span>.<span class="cm-property">load_preprocess</span>()</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">load_path</span> = <span class="cm-variable">helper</span>.<span class="cm-property">load_params</span>()</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 181px;"></div><div class="CodeMirror-gutters" style="display: none; height: 196px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 133px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Sentence to Sequence</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">To feed a sentence into the model for translation, you first need to preprocess it.  Implement the function <span class="cm-comment">`sentence_to_seq()`</span> to preprocess new sentences.</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Convert the sentence to lowercase</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Convert words into ids using </span><span class="cm-comment cm-variable-2">`vocab_to_int`</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"> <span class="cm-variable-2">- Convert words not in the vocabulary, to the </span><span class="cm-comment cm-variable-2">`&lt;UNK&gt;`</span><span class="cm-variable-2"> word id.</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 133px;"></div><div class="CodeMirror-gutters" style="display: none; height: 148px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Sentence-to-Sequence">Sentence to Sequence<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Sentence-to-Sequence"></a></h2>
<p>To feed a sentence into the model for translation, you first need to preprocess it.  Implement the function <code>sentence_to_seq()</code> to preprocess new sentences.</p>
<ul>
<li>Convert the sentence to lowercase</li>
<li>Convert words into ids using <code>vocab_to_int</code><ul>
<li>Convert words not in the vocabulary, to the <code>&lt;UNK&gt;</code> word id.</li>
</ul>
</li>
</ul>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[23]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 523px; margin-bottom: -15px; border-right-width: 15px; min-height: 419px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">sentence_to_seq</span>(<span class="cm-variable">sentence</span>, <span class="cm-variable">vocab_to_int</span>):</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    Convert a sentence to a sequence of ids</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param sentence: String</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :param vocab_to_int: Dictionary to go from the words to an id</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    :return: List of word ids</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">    """</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># TODO: Implement Function</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-builtin">print</span>(<span class="cm-variable">sentence</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">word_ids</span> = []</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">for</span> <span class="cm-variable">word</span> <span class="cm-keyword">in</span> <span class="cm-variable">sentence</span>.<span class="cm-property">split</span>():</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-keyword">if</span> <span class="cm-variable">vocab_to_int</span>.<span class="cm-property">get</span>(<span class="cm-variable">word</span>)==<span class="cm-keyword">None</span>:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">word_ids</span>.<span class="cm-property">append</span>(<span class="cm-variable">vocab_to_int</span>[<span class="cm-string">'&lt;UNK&gt;'</span>])</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">        <span class="cm-keyword">else</span>:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">            <span class="cm-variable">word_ids</span>.<span class="cm-property">append</span>(<span class="cm-variable">vocab_to_int</span>[<span class="cm-variable">word</span>])</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    </span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-keyword">return</span> <span class="cm-variable">word_ids</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">tests</span>.<span class="cm-property">test_sentence_to_seq</span>(<span class="cm-variable">sentence_to_seq</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 419px;"></div><div class="CodeMirror-gutters" style="display: none; height: 434px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""><div class="output_area"><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>this is a test sentence
Tests Passed
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 48px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Translate</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">This will translate <span class="cm-comment">`translate_sentence`</span> from English to French.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 48px;"></div><div class="CodeMirror-gutters" style="display: none; height: 63px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Translate">Translate<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Translate"></a></h2>
<p>This will translate <code>translate_sentence</code> from English to French.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[24]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 803px; margin-bottom: -15px; border-right-width: 15px; min-height: 470px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">translate_sentence</span> = <span class="cm-string">'he saw a old yellow truck .'</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">DON'T MODIFY ANYTHING IN THIS CELL</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-string">"""</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">translate_sentence</span> = <span class="cm-variable">sentence_to_seq</span>(<span class="cm-variable">translate_sentence</span>, <span class="cm-variable">source_vocab_to_int</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-variable">loaded_graph</span> = <span class="cm-variable">tf</span>.<span class="cm-property">Graph</span>()</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-keyword">with</span> <span class="cm-variable">tf</span>.<span class="cm-property">Session</span>(<span class="cm-variable">graph</span>=<span class="cm-variable">loaded_graph</span>) <span class="cm-keyword">as</span> <span class="cm-variable">sess</span>:</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-comment"># Load saved model</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">loader</span> = <span class="cm-variable">tf</span>.<span class="cm-property">train</span>.<span class="cm-property">import_meta_graph</span>(<span class="cm-variable">load_path</span> <span class="cm-operator">+</span> <span class="cm-string">'.meta'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">loader</span>.<span class="cm-property">restore</span>(<span class="cm-variable">sess</span>, <span class="cm-variable">load_path</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">input_data</span> = <span class="cm-variable">loaded_graph</span>.<span class="cm-property">get_tensor_by_name</span>(<span class="cm-string">'input:0'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">logits</span> = <span class="cm-variable">loaded_graph</span>.<span class="cm-property">get_tensor_by_name</span>(<span class="cm-string">'logits:0'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">keep_prob</span> = <span class="cm-variable">loaded_graph</span>.<span class="cm-property">get_tensor_by_name</span>(<span class="cm-string">'keep_prob:0'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    <span class="cm-variable">translate_logits</span> = <span class="cm-variable">sess</span>.<span class="cm-property">run</span>(<span class="cm-variable">logits</span>, {<span class="cm-variable">input_data</span>: [<span class="cm-variable">translate_sentence</span>], <span class="cm-variable">keep_prob</span>: <span class="cm-number">1.0</span>})[<span class="cm-number">0</span>]</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'Input'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'  Word Ids:      {}'</span>.<span class="cm-property">format</span>([<span class="cm-variable">i</span> <span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-variable">translate_sentence</span>]))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'  English Words: {}'</span>.<span class="cm-property">format</span>([<span class="cm-variable">source_int_to_vocab</span>[<span class="cm-variable">i</span>] <span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-variable">translate_sentence</span>]))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'\nPrediction'</span>)</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'  Word Ids:      {}'</span>.<span class="cm-property">format</span>([<span class="cm-variable">i</span> <span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-variable">np</span>.<span class="cm-property">argmax</span>(<span class="cm-variable">translate_logits</span>, <span class="cm-number">1</span>)]))</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'  French Words: {}'</span>.<span class="cm-property">format</span>([<span class="cm-variable">target_int_to_vocab</span>[<span class="cm-variable">i</span>] <span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-variable">np</span>.<span class="cm-property">argmax</span>(<span class="cm-variable">translate_logits</span>, <span class="cm-number">1</span>)]))</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 470px;"></div><div class="CodeMirror-gutters" style="display: none; height: 485px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style=""></div><div class="output" style=""><div class="output_area"><div class="prompt"></div><div class="output_subarea output_text output_stream output_stdout"><pre>he saw a old yellow truck .
Input
  Word Ids:      [221, 197, 146, 127, 163, 207, 142]
  English Words: ['he', 'saw', 'a', 'old', 'yellow', 'truck', '.']

Prediction
  Word Ids:      [70, 145, 197, 245, 294, 240, 184, 236, 1]
  French Words: ['il', 'a', 'vu', 'un', 'vieux', 'camion', 'jaune', '.', '&lt;EOS&gt;']
</pre></div></div></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 255px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Imperfect Translation</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">You might notice that some sentences translate better than others.  Since the dataset you're using only has a vocabulary of 227 English words of the thousands that you use, you're only going to see good results using these words.  For this project, you don't need a perfect translation. However, if you want to create a better translation model, you'll need better data.</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">You can train on the <span class="cm-link">[WMT10 French-English corpus]</span><span class="cm-string cm-url">(http://www.statmt.org/wmt10/training-giga-fren.tar)</span>.  This dataset has more vocabulary and richer in topics discussed.  However, this will take you days to train, so make sure you've a GPU and the neural network is performing well on dataset we provided.  Just make sure you play with the WMT10 corpus after you've submitted this project.</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Submitting This Project</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_language_translation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 255px;"></div><div class="CodeMirror-gutters" style="display: none; height: 270px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Imperfect-Translation">Imperfect Translation<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Imperfect-Translation"></a></h2>
<p>You might notice that some sentences translate better than others.  Since the dataset you're using only has a vocabulary of 227 English words of the thousands that you use, you're only going to see good results using these words.  For this project, you don't need a perfect translation. However, if you want to create a better translation model, you'll need better data.</p>
<p>You can train on the <a href="http://www.statmt.org/wmt10/training-giga-fren.tar" target="_blank">WMT10 French-English corpus</a>.  This dataset has more vocabulary and richer in topics discussed.  However, this will take you days to train, so make sure you've a GPU and the neural network is performing well on dataset we provided.  Just make sure you play with the WMT10 corpus after you've submitted this project.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#Submitting-This-Project"></a></h2>
<p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_language_translation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 3px; margin-bottom: -15px; border-right-width: 15px; min-height: 28px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text=""></span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; border-bottom: 0px solid transparent; top: 28px;"></div><div class="CodeMirror-gutters" style="display: none; height: 43px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close"></button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" style="display: none;"></div><div class="output" style="display: none;"></div><div class="btn btn-default output_collapsed" title="click to expand output" style="display: none;">. . .</div></div></div></div><div class="end_space"></div></div>
        <div id="tooltip" class="ipython_tooltip" style="display:none"><div class="tooltipbuttons"><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#" role="button" class="ui-button"><span class="ui-icon ui-icon-close">Close</span></a><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#" class="ui-corner-all" role="button" id="expanbutton" title="Grow the tooltip vertically (press shift-tab twice)"><span class="ui-icon ui-icon-plus">Expand</span></a><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#" role="button" class="ui-button" title="show the current docstring in pager (press shift-tab 4 times)"><span class="ui-icon ui-icon-arrowstop-l-n">Open in Pager</span></a><a href="http://35.158.40.136:8888/notebooks/dlnd_language_translation.ipynb#" role="button" class="ui-button" title="Tooltip will linger for 10 seconds while you type" style="display: none;"><span class="ui-icon ui-icon-clock">Close</span></a></div><div class="pretooltiparrow"></div><div class="tooltiptext smalltooltip"></div></div>
    </div>
</div>



</div>



<div id="pager" class="ui-resizable">
    <div id="pager-contents">
        <div id="pager-container" class="container"></div>
    </div>
    <div id="pager-button-area"><a role="button" title="Open the pager in an external window" class="ui-button"><span class="ui-icon ui-icon-extlink"></span></a><a role="button" title="Close the pager" class="ui-button"><span class="ui-icon ui-icon-close"></span></a></div>
<div class="ui-resizable-handle ui-resizable-n" style="z-index: 90;"></div></div>






<script type="text/javascript">
    sys_info = {"os_name": "posix", "commit_hash": "", "sys_version": "3.5.2 | packaged by conda-forge | (default, Jan 19 2017, 15:28:33) \n[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]", "commit_source": "", "sys_executable": "/home/carnd/anaconda3/envs/dl/bin/python", "platform": "Linux-4.4.0-72-generic-x86_64-with-debian-stretch-sid", "default_encoding": "UTF-8", "sys_platform": "linux", "notebook_version": "4.4.1", "notebook_path": "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/notebook"};
</script>

<script src="./dlnd_language_translation_files/encoding.js" charset="utf-8"></script>


    <script src="./dlnd_language_translation_files/main.min.js" type="text/javascript" charset="utf-8"></script>






<div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal;"></div></div><div class="widget-modal-backdrop widget-modal-hidden"><div class="widget-modal-text"><i class="fa fa-cog fa-spin"></i><div>Rendering widgets...</div></div><div class="progress widget-modal-progress"><div class="progress-bar" role="progressbar" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100" style="width: 0%;"></div></div></div></body></html>